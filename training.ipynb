{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"TPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14322899,"sourceType":"datasetVersion","datasetId":9143557}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  CogniVue: Training\n\n** FULLY COMPATIBLE with your preprocessing notebook!**\n\nThis notebook:\n-  Loads data from single `.pkl` files per split\n-  Handles variable channel count (typically 58 channels)\n-  Correctly transposes X from `(n_ch, 256)` to `(256, n_ch)`\n-  Robust checkpointing and error handling\n-  Resume training from interruptions\n-  \n\n","metadata":{}},{"cell_type":"markdown","source":"##  1. Install Dependencies","metadata":{}},{"cell_type":"markdown","source":"##  2. Configuration","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport json\nimport time\nimport shutil\nimport numpy as np\nimport tensorflow as tf\nimport pickle\nfrom datetime import datetime\n\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"Python version: {sys.version}\")\n\n# =====================================================\n# PATHS CONFIGURATION\n# =====================================================\n\n# UPDATE THIS to match your dataset name!\nDATASET_NAME = \"preprocessed-cog-eeg-dataset\"  \n\n# Input paths\nDATA_INPUT_DIR = f\"/kaggle/input/{DATASET_NAME}/processed\"\n\n# Output paths\nWORKING_DIR = \"/kaggle/working\"\nCHECKPOINT_DIR = os.path.join(WORKING_DIR, \"checkpoints\")\nRESULTS_DIR = os.path.join(WORKING_DIR, \"results\")\nLOGS_DIR = os.path.join(WORKING_DIR, \"logs\")\n\nfor d in [CHECKPOINT_DIR, RESULTS_DIR, LOGS_DIR]:\n    os.makedirs(d, exist_ok=True)\n\nprint(f\"\\n Paths configured:\")\nprint(f\"  Input: {DATA_INPUT_DIR}\")\nprint(f\"  Checkpoints: {CHECKPOINT_DIR}\")\nprint(f\"  Results: {RESULTS_DIR}\")\n\n# =====================================================\n# DATA CONSTANTS (from preprocessing)\n# =====================================================\n\nWINDOW_SIZE_SAMPLES = 256\nNUM_BANDS = 5  # delta, theta, alpha, beta, gamma\nNUM_TASKS = 4  # N-back, MATB-II, PVT, Flanker\n\n# Output classes\nNUM_OUTPUT_REGIONS = 7\nNUM_OUTPUT_BANDS = 5\nNUM_OUTPUT_STATES = 4\n\n# Note: NUM_CHANNELS and NUM_OUTPUT_CHANNELS will be determined from data!\n\n# =====================================================\n# MODEL HYPERPARAMETERS\n# =====================================================\n\nD_MODEL = 256\nNUM_LAYERS = 6\nNUM_HEADS = 8\nFF_DIM = 1024\nDROPOUT = 0.15\n\nBANDPOWER_HIDDEN_DIM = 128\nBANDPOWER_OUTPUT_DIM = 128\nTASK_EMBEDDING_DIM = 16\n\n# =====================================================\n# TRAINING HYPERPARAMETERS\n# =====================================================\n\nEPOCHS = 100\nINITIAL_LR = 1e-4\nWARMUP_EPOCHS = 10\nWEIGHT_DECAY = 0.01\nGRADIENT_CLIP_NORM = 1.0\n\nSAVE_CHECKPOINT_EVERY = 2\nEARLY_STOPPING_PATIENCE = 15\n\nprint(f\"\\nüîß Configuration:\")\nprint(f\"  Model: {NUM_LAYERS} layers, {NUM_HEADS} heads, D_MODEL={D_MODEL}\")\nprint(f\"  Training: {EPOCHS} epochs, LR={INITIAL_LR}\")\nprint(f\"  Checkpointing: every {SAVE_CHECKPOINT_EVERY} epochs\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T21:08:19.466074Z","iopub.execute_input":"2025-12-29T21:08:19.466340Z","iopub.status.idle":"2025-12-29T21:08:40.476153Z","shell.execute_reply.started":"2025-12-29T21:08:19.466317Z","shell.execute_reply":"2025-12-29T21:08:40.475514Z"}},"outputs":[{"name":"stderr","text":"2025-12-29 21:08:22.789675: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767042503.226127      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767042503.340154      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767042504.351330      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767042504.351365      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767042504.351367      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767042504.351369      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"TensorFlow version: 2.19.0\nPython version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n\n Paths configured:\n  Input: /kaggle/input/preprocessed-cog-eeg-dataset/processed\n  Checkpoints: /kaggle/working/checkpoints\n  Results: /kaggle/working/results\n\nüîß Configuration:\n  Model: 6 layers, 8 heads, D_MODEL=256\n  Training: 100 epochs, LR=0.0001\n  Checkpointing: every 2 epochs\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"##  3. TPU Initialization","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nprint(\"=\" * 70)\nprint(\"üöÄ GPU T4 x2 INITIALIZATION\")\nprint(\"=\" * 70)\n\nprint(f\"\\nTensorFlow version: {tf.__version__}\")\n\n# Create GPU strategy\nprint(\"\\nüìä Creating GPU strategy...\")\nstrategy = tf.distribute.MirroredStrategy()\n\nnum_replicas = strategy.num_replicas_in_sync\nprint(f\"‚úÖ Strategy: {strategy.__class__.__name__}\")\nprint(f\"   GPUs detected: {num_replicas}\")\n\n# List GPUs\ngpus = tf.config.list_physical_devices('GPU')\nprint(f\"\\nüéÆ GPU devices:\")\nfor i, gpu in enumerate(gpus):\n    print(f\"   {i+1}. {gpu.name}\")\n\n# Batch size configuration\nBATCH_SIZE_PER_REPLICA = 32  # Reduce to 16 if you get OOM errors\nBATCH_SIZE = BATCH_SIZE_PER_REPLICA * num_replicas\n\nprint(f\"\\nüì¶ Batch Configuration:\")\nprint(f\"   Per-GPU batch: {BATCH_SIZE_PER_REPLICA}\")\nprint(f\"   Global batch: {BATCH_SIZE}\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"‚úÖ GPU READY FOR TRAINING\")\nprint(\"=\" * 70)\n\n# Make variables global\nglobals()['strategy'] = strategy\nglobals()['BATCH_SIZE'] = BATCH_SIZE\n\nprint(\"\\nüí° Next: Create model in strategy scope\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T21:08:40.477867Z","iopub.execute_input":"2025-12-29T21:08:40.478393Z","iopub.status.idle":"2025-12-29T21:08:42.005928Z","shell.execute_reply.started":"2025-12-29T21:08:40.478368Z","shell.execute_reply":"2025-12-29T21:08:42.005161Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nüöÄ GPU T4 x2 INITIALIZATION\n======================================================================\n\nTensorFlow version: 2.19.0\n\nüìä Creating GPU strategy...\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n‚úÖ Strategy: MirroredStrategy\n   GPUs detected: 2\n\nüéÆ GPU devices:\n   1. /physical_device:GPU:0\n   2. /physical_device:GPU:1\n\nüì¶ Batch Configuration:\n   Per-GPU batch: 32\n   Global batch: 64\n\n======================================================================\n‚úÖ GPU READY FOR TRAINING\n======================================================================\n\nüí° Next: Create model in strategy scope\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1767042521.961217      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1767042521.965193      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================================\n# AUTO-SAVE CALLBACK (Add this BEFORE training section)\n# ============================================================\n\nclass AutoSaveCallback(tf.keras.callbacks.Callback):\n    \"\"\"Custom callback to create marker files for auto-committing\"\"\"\n    \n    def on_epoch_end(self, epoch, logs=None):\n        # Create a marker file every epoch\n        # Kaggle auto-commits when new files appear\n        marker_path = f\"/kaggle/working/progress_epoch_{epoch+1}.txt\"\n        with open(marker_path, 'w') as f:\n            f.write(f\"Completed epoch {epoch+1}/{EPOCHS}\\n\")\n            f.write(f\"Loss: {logs.get('loss', 0):.4f}\\n\")\n            f.write(f\"Val Loss: {logs.get('val_loss', 0):.4f}\\n\")\n            f.write(f\"Timestamp: {datetime.now()}\\n\")\n        \n        print(f\"   Progress saved: progress_epoch_{epoch+1}.txt\")\n\nprint(\" Auto-save callback ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T21:08:42.006878Z","iopub.execute_input":"2025-12-29T21:08:42.007132Z","iopub.status.idle":"2025-12-29T21:08:42.020008Z","shell.execute_reply.started":"2025-12-29T21:08:42.007084Z","shell.execute_reply":"2025-12-29T21:08:42.019496Z"}},"outputs":[{"name":"stdout","text":" Auto-save callback ready!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"##  4. Data Loading (Compatible with Preprocessing)","metadata":{}},{"cell_type":"code","source":"def load_preprocessed_data(split='train'):\n    \"\"\"\n    Load preprocessed .pkl file (matches preprocessing output format).\n    \n    Returns:\n        Tuple of (X, y, metadata) where:\n        X = (X_eeg, X_bp, X_task)\n        y = (y_channel, y_region, y_band, y_state)\n        metadata = dict with num_channels, etc.\n    \"\"\"\n    pkl_path = os.path.join(DATA_INPUT_DIR, split, f\"{split}_data.pkl\")\n    \n    print(f\"\\n Loading {split} data from: {pkl_path}\")\n    \n    if not os.path.exists(pkl_path):\n        print(f\"   File not found!\")\n        print(f\"   Check that dataset is attached and DATASET_NAME is correct\")\n        return None\n    \n    # Load pickle file\n    try:\n        with open(pkl_path, 'rb') as f:\n            samples = pickle.load(f)\n        \n        print(f\"   Loaded {len(samples):,} samples\")\n        \n        if len(samples) == 0:\n            print(f\"   No samples in file!\")\n            return None\n        \n        # Inspect first sample to get dimensions\n        sample = samples[0]\n        X_shape = sample['X'].shape  # Should be (n_channels, 256)\n        bp_shape = sample['bp'].shape  # Should be (n_channels, 5)\n        \n        num_channels = X_shape[0]\n        \n        print(f\"\\n  Data format:\")\n        print(f\"     X shape: {X_shape} (channels, time)\")\n        print(f\"     bp shape: {bp_shape} (channels, bands)\")\n        print(f\"     Channels: {num_channels}\")\n        \n        # Extract arrays\n        print(f\"\\n   Converting to arrays...\")\n        \n        # X: Transpose from (n_channels, 256) to (256, n_channels)\n        X_eeg = np.array([s['X'].T for s in samples], dtype=np.float32)\n        \n        # bp: Flatten from (n_channels, 5) to (n_channels*5,)\n        X_bp = np.array([s['bp'].flatten() for s in samples], dtype=np.float32)\n        \n        # task_idx\n        X_task = np.array([s['task_idx'] for s in samples], dtype=np.int32)\n        \n        # Labels\n        y_channel = np.array([s['y_channel'] for s in samples], dtype=np.int32)\n        y_region = np.array([s['y_region'] for s in samples], dtype=np.int32)\n        y_band = np.array([s['y_band'] for s in samples], dtype=np.int32)\n        y_state = np.array([s['y_state'] for s in samples], dtype=np.int32)\n        \n        print(f\"   Final shapes:\")\n        print(f\"     X_eeg: {X_eeg.shape} (N, time, channels)\")\n        print(f\"     X_bp: {X_bp.shape} (N, features)\")\n        print(f\"     X_task: {X_task.shape}\")\n        print(f\"     Labels: {y_channel.shape} each\")\n        \n        metadata = {\n            'num_channels': num_channels,\n            'num_samples': len(samples),\n            'bandpower_dim': X_bp.shape[1]\n        }\n        \n        return (X_eeg, X_bp, X_task), (y_channel, y_region, y_band, y_state), metadata\n        \n    except Exception as e:\n        print(f\"  ‚ùå Error loading data: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None\n\nprint(\" Data loading function defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T21:08:42.021049Z","iopub.execute_input":"2025-12-29T21:08:42.021327Z","iopub.status.idle":"2025-12-29T21:08:42.048761Z","shell.execute_reply.started":"2025-12-29T21:08:42.021300Z","shell.execute_reply":"2025-12-29T21:08:42.048044Z"}},"outputs":[{"name":"stdout","text":" Data loading function defined\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"##  5. Model Architecture (Flexible Channels)","metadata":{}},{"cell_type":"code","source":"def create_model(num_channels, bandpower_input_dim, num_output_channels):\n    \"\"\"\n    Create EEG Transformer with flexible channel dimensions.\n    \n    Args:\n        num_channels: Number of EEG channels (e.g., 58)\n        bandpower_input_dim: Bandpower feature dimension (num_channels * 5)\n        num_output_channels: Number of output classes for channel prediction\n    \"\"\"\n    # Inputs\n    eeg_input = tf.keras.Input(shape=(WINDOW_SIZE_SAMPLES, num_channels), name='eeg')\n    bp_input = tf.keras.Input(shape=(bandpower_input_dim,), name='bp')\n    task_input = tf.keras.Input(shape=(1,), dtype='int32', name='task')\n    \n    # ==================== EEG STREAM ====================\n    x = tf.keras.layers.Dense(D_MODEL, name='eeg_projection')(eeg_input)\n    \n    # Positional encoding\n    positions = tf.range(start=0, limit=WINDOW_SIZE_SAMPLES, delta=1)\n    pos_emb = tf.keras.layers.Embedding(\n        input_dim=WINDOW_SIZE_SAMPLES,\n        output_dim=D_MODEL,\n        name='positional_embedding'\n    )(positions)\n    x = x + pos_emb\n    \n    # Transformer layers\n    for i in range(NUM_LAYERS):\n        attn = tf.keras.layers.MultiHeadAttention(\n            num_heads=NUM_HEADS,\n            key_dim=D_MODEL // NUM_HEADS,\n            dropout=DROPOUT,\n            name=f'mha_{i}'\n        )(x, x)\n        x = tf.keras.layers.Add(name=f'add_attn_{i}')([x, attn])\n        x = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=f'ln_attn_{i}')(x)\n        \n        ffn = tf.keras.Sequential([\n            tf.keras.layers.Dense(FF_DIM, activation='relu'),\n            tf.keras.layers.Dense(D_MODEL),\n            tf.keras.layers.Dropout(DROPOUT)\n        ], name=f'ffn_{i}')\n        \n        ffn_out = ffn(x)\n        x = tf.keras.layers.Add(name=f'add_ffn_{i}')([x, ffn_out])\n        x = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=f'ln_ffn_{i}')(x)\n    \n    eeg_emb = tf.keras.layers.GlobalAveragePooling1D(name='eeg_pool')(x)\n    \n    # ==================== BANDPOWER STREAM ====================\n    bp_x = tf.keras.layers.Dense(BANDPOWER_HIDDEN_DIM, activation='relu', name='bp_hidden')(bp_input)\n    bp_emb = tf.keras.layers.Dense(BANDPOWER_OUTPUT_DIM, activation='relu', name='bp_output')(bp_x)\n    \n    # ==================== TASK STREAM ====================\n    task_emb = tf.keras.layers.Embedding(NUM_TASKS, TASK_EMBEDDING_DIM, name='task_emb')(task_input)\n    task_emb = tf.keras.layers.Flatten(name='task_flatten')(task_emb)\n    \n    # ==================== FUSION ====================\n    fused = tf.keras.layers.Concatenate(name='fusion')([eeg_emb, bp_emb, task_emb])\n    \n    # ==================== MULTI-TASK HEADS ====================\n    out_channel = tf.keras.layers.Dense(num_output_channels, name='channel')(fused)\n    out_region = tf.keras.layers.Dense(NUM_OUTPUT_REGIONS, name='region')(fused)\n    out_band = tf.keras.layers.Dense(NUM_OUTPUT_BANDS, name='band')(fused)\n    out_state = tf.keras.layers.Dense(NUM_OUTPUT_STATES, name='state')(fused)\n    \n    model = tf.keras.Model(\n        inputs=[eeg_input, bp_input, task_input],\n        outputs={\n            'channel': out_channel,\n            'region': out_region,\n            'band': out_band,\n            'state': out_state\n        },\n        name='CogniVue_Transformer'\n    )\n    \n    return model\n\nprint(\" Model architecture defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T21:08:42.049687Z","iopub.execute_input":"2025-12-29T21:08:42.050273Z","iopub.status.idle":"2025-12-29T21:08:42.075440Z","shell.execute_reply.started":"2025-12-29T21:08:42.050251Z","shell.execute_reply":"2025-12-29T21:08:42.074881Z"}},"outputs":[{"name":"stdout","text":" Model architecture defined\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"##  6. Learning Rate Schedule","metadata":{}},{"cell_type":"code","source":"class WarmupCosineDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, initial_learning_rate, warmup_steps, total_steps):\n        super().__init__()\n        self.initial_learning_rate = initial_learning_rate\n        self.warmup_steps = warmup_steps\n        self.total_steps = total_steps\n    \n    def __call__(self, step):\n        step = tf.cast(step, tf.float32)\n        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n        total_steps = tf.cast(self.total_steps, tf.float32)\n        \n        warmup_lr = (step / warmup_steps) * self.initial_learning_rate\n        \n        decay_steps = total_steps - warmup_steps\n        decay_step = step - warmup_steps\n        cosine_decay = 0.5 * (1 + tf.cos(tf.constant(np.pi) * decay_step / decay_steps))\n        decay_lr = self.initial_learning_rate * cosine_decay\n        \n        return tf.cond(\n            step < warmup_steps,\n            lambda: warmup_lr,\n            lambda: decay_lr\n        )\n    \n    def get_config(self):\n        return {\n            \"initial_learning_rate\": self.initial_learning_rate,\n            \"warmup_steps\": self.warmup_steps,\n            \"total_steps\": self.total_steps,\n        }\n\nprint(\" LR schedule defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T21:08:42.076173Z","iopub.execute_input":"2025-12-29T21:08:42.076532Z","iopub.status.idle":"2025-12-29T21:08:42.098301Z","shell.execute_reply.started":"2025-12-29T21:08:42.076507Z","shell.execute_reply":"2025-12-29T21:08:42.097644Z"}},"outputs":[{"name":"stdout","text":" LR schedule defined\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"##  7. Data Pipeline & Callbacks","metadata":{}},{"cell_type":"code","source":"def create_tf_dataset(X, y, is_train=True):\n    dataset = tf.data.Dataset.from_tensor_slices((\n        {'eeg': X[0], 'bp': X[1], 'task': X[2]},\n        {'channel': y[0], 'region': y[1], 'band': y[2], 'state': y[3]}\n    ))\n    \n    if is_train:\n        dataset = dataset.shuffle(10000)\n    \n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    \n    return dataset\n\n\nclass PeriodicCheckpoint(tf.keras.callbacks.Callback):\n    def __init__(self, save_freq=5):\n        super().__init__()\n        self.save_freq = save_freq\n    \n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch + 1) % self.save_freq == 0:\n            filepath = os.path.join(CHECKPOINT_DIR, f\"checkpoint_epoch_{epoch+1:03d}.keras\")\n            self.model.save(filepath)\n            print(f\"\\n   Saved checkpoint: {os.path.basename(filepath)}\")\n\n\nclass LearningRateLogger(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        lr = self.model.optimizer.learning_rate\n        if hasattr(lr, '__call__'):\n            lr_value = lr(self.model.optimizer.iterations)\n        else:\n            lr_value = lr\n        lr_float = float(tf.keras.backend.get_value(lr_value))\n        if logs is not None:\n            logs['learning_rate'] = lr_float\n        print(f\"\\n   LR = {lr_float:.6f}\")\n\n\nclass ProgressLogger(tf.keras.callbacks.Callback):\n    def __init__(self):\n        super().__init__()\n        self.epoch_start = None\n    \n    def on_epoch_begin(self, epoch, logs=None):\n        self.epoch_start = time.time()\n        print(f\"\\n{'='*70}\")\n        print(f\" Epoch {epoch+1}/{EPOCHS}\")\n        print(f\"{'='*70}\")\n    \n    def on_epoch_end(self, epoch, logs=None):\n        elapsed = time.time() - self.epoch_start\n        print(f\"\\n Epoch {epoch+1} done in {elapsed:.1f}s\")\n        if logs:\n            print(f\"   Loss: {logs.get('loss', 0):.4f} | Val Loss: {logs.get('val_loss', 0):.4f}\")\n            print(f\"   Region Acc: {logs.get('region_accuracy', 0):.4f} | Val: {logs.get('val_region_accuracy', 0):.4f}\")\n        print(f\"{'='*70}\\n\")\n\nprint(\" Pipeline & callbacks defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T21:08:42.100318Z","iopub.execute_input":"2025-12-29T21:08:42.100560Z","iopub.status.idle":"2025-12-29T21:08:42.124680Z","shell.execute_reply.started":"2025-12-29T21:08:42.100541Z","shell.execute_reply":"2025-12-29T21:08:42.123967Z"}},"outputs":[{"name":"stdout","text":" Pipeline & callbacks defined\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"##  8. Main Training Function","metadata":{}},{"cell_type":"code","source":"def train_cognivue():\n    print(\"\\n\" + \"=\"*70)\n    print(\" CogniVue Training Pipeline\")\n    print(\"=\"*70)\n    \n    # Load ONLY training data\n    print(\"\\n Loading data...\")\n    train_result = load_preprocessed_data('train')\n    \n    if train_result is None:\n        print(\"\\n‚ùå Data loading failed!\")\n        return None\n    \n    train_data, train_labels, train_meta = train_result\n    \n    # =====================================================\n    # SPLIT TRAIN DATA INTO TRAIN/VAL (80/20)\n    # =====================================================\n    print(\"\\n Splitting data into train/val...\")\n    \n    num_samples = len(train_data[0])\n    indices = np.arange(num_samples)\n    np.random.seed(42)  # For reproducibility\n    np.random.shuffle(indices)\n    \n    # 80% train, 20% val\n    split_idx = int(0.8 * num_samples)\n    train_idx = indices[:split_idx]\n    val_idx = indices[split_idx:]\n    \n    # Split X data\n    train_X = (\n        train_data[0][train_idx],  # X_eeg\n        train_data[1][train_idx],  # X_bp\n        train_data[2][train_idx]   # X_task\n    )\n    val_X = (\n        train_data[0][val_idx],\n        train_data[1][val_idx],\n        train_data[2][val_idx]\n    )\n    \n    # Split y data\n    train_y = (\n        train_labels[0][train_idx],  # y_channel\n        train_labels[1][train_idx],  # y_region\n        train_labels[2][train_idx],  # y_band\n        train_labels[3][train_idx]   # y_state\n    )\n    val_y = (\n        train_labels[0][val_idx],\n        train_labels[1][val_idx],\n        train_labels[2][val_idx],\n        train_labels[3][val_idx]\n    )\n    \n    print(f\"   Train samples: {len(train_idx):,}\")\n    print(f\"   Val samples: {len(val_idx):,}\")\n    \n    # Get dimensions from data\n    NUM_CHANNELS = train_meta['num_channels']\n    BANDPOWER_INPUT_DIM = train_meta['bandpower_dim']\n    \n    # Determine NUM_OUTPUT_CHANNELS from labels\n    NUM_OUTPUT_CHANNELS = train_labels[0].max() + 1\n    \n    print(f\"\\n Model dimensions:\")\n    print(f\"   Input channels: {NUM_CHANNELS}\")\n    print(f\"   Bandpower dim: {BANDPOWER_INPUT_DIM}\")\n    print(f\"   Output channels: {NUM_OUTPUT_CHANNELS}\")\n    \n    # Create datasets\n    print(f\"\\n Creating TF datasets...\")\n    train_ds = create_tf_dataset(train_X, train_y, is_train=True)\n    val_ds = create_tf_dataset(val_X, val_y, is_train=False)\n    \n    steps_per_epoch = len(train_idx) // BATCH_SIZE\n    total_steps = steps_per_epoch * EPOCHS\n    warmup_steps = steps_per_epoch * WARMUP_EPOCHS\n    \n    print(f\"   Steps/epoch: {steps_per_epoch:,}\")\n    print(f\"   Total steps: {total_steps:,}\")\n    \n    # Build model\n    print(f\"\\nÔøΩÔ∏è Building model...\")\n    \n    with strategy.scope():\n        model = create_model(NUM_CHANNELS, BANDPOWER_INPUT_DIM, NUM_OUTPUT_CHANNELS)\n        \n        print(f\"   Parameters: {model.count_params():,}\")\n        \n        lr_schedule = WarmupCosineDecay(INITIAL_LR, warmup_steps, total_steps)\n        \n        optimizer = tf.keras.optimizers.AdamW(\n            learning_rate=lr_schedule,\n            weight_decay=WEIGHT_DECAY,\n            clipnorm=GRADIENT_CLIP_NORM\n        )\n        \n        loss_weights = {'channel': 0.4, 'region': 0.4, 'band': 0.1, 'state': 0.1}\n        model.compile(\n    optimizer=optimizer,\n    loss={\n        'channel': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        'region': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        'band': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        'state': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    },\n    loss_weights={\n        'channel': 0.4,\n        'region': 0.4,\n        'band': 0.1,\n        'state': 0.1\n    },\n    metrics={\n        'channel': ['accuracy'],\n        'region': ['accuracy'],\n        'band': ['accuracy'],\n        'state': ['accuracy']\n    }\n)\n    print(f\"    Compiled\")\n    \n    # Callbacks\n    callbacks = [\n        ProgressLogger(),\n        LearningRateLogger(),\n        tf.keras.callbacks.ModelCheckpoint(\n            filepath=os.path.join(CHECKPOINT_DIR, 'best_model.keras'),\n            monitor='val_loss',\n            save_best_only=True,\n            verbose=1\n        ),\n        PeriodicCheckpoint(save_freq=SAVE_CHECKPOINT_EVERY),\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=EARLY_STOPPING_PATIENCE,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        tf.keras.callbacks.TensorBoard(log_dir=LOGS_DIR)\n    ]\n    \n    # Train\n    print(f\"\\n Starting training...\")\n    print(f\" {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n    \n    try:\n        history = model.fit(\n            train_ds,\n            epochs=EPOCHS,\n            validation_data=val_ds,\n            callbacks=callbacks,\n            verbose=1\n        )\n        \n        print(\"\\n\" + \"=\"*70)\n        print(\" TRAINING COMPLETE!\")\n        print(\"=\"*70)\n        print(f\"\\n Saved to: {CHECKPOINT_DIR}\")\n        \n        # Save final\n        model.save(os.path.join(CHECKPOINT_DIR, 'final_model.keras'))\n        print(f\"   - final_model.keras\")\n        print(f\"   - best_model.keras\")\n        \n        return history\n        \n    except KeyboardInterrupt:\n        print(\"\\n Training interrupted!\")\n        model.save(os.path.join(CHECKPOINT_DIR, 'interrupted.keras'))\n        print(f\"    Saved: interrupted.keras\")\n        return None\n        \n    except Exception as e:\n        print(f\"\\n‚ùå Training failed: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None\n\nprint(\" Training function ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T21:08:42.125498Z","iopub.execute_input":"2025-12-29T21:08:42.125751Z","iopub.status.idle":"2025-12-29T21:08:42.144906Z","shell.execute_reply.started":"2025-12-29T21:08:42.125732Z","shell.execute_reply":"2025-12-29T21:08:42.144370Z"}},"outputs":[{"name":"stdout","text":" Training function ready\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"##  9. Run Training","metadata":{}},{"cell_type":"code","source":"history = train_cognivue()\n\nif history:\n    print(\"\\n Training Summary:\")\n    print(f\"   Best val_loss: {min(history.history['val_loss']):.4f}\")\n    print(f\"   Final region acc: {history.history['region_accuracy'][-1]:.4f}\")\n    print(f\"\\n Next: Click 'Save Version' to commit checkpoints!\")\nelse:\n    print(\"\\n‚ö†Ô∏è Training did not complete successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T21:08:42.145710Z","iopub.execute_input":"2025-12-29T21:08:42.145956Z","iopub.status.idle":"2025-12-29T21:42:28.125888Z","shell.execute_reply.started":"2025-12-29T21:08:42.145929Z","shell.execute_reply":"2025-12-29T21:42:28.125087Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\n CogniVue Training Pipeline\n======================================================================\n\n Loading data...\n\n Loading train data from: /kaggle/input/preprocessed-cog-eeg-dataset/processed/train/train_data.pkl\n   Loaded 21,538 samples\n\n  Data format:\n     X shape: (58, 256) (channels, time)\n     bp shape: (58, 5) (channels, bands)\n     Channels: 58\n\n   Converting to arrays...\n   Final shapes:\n     X_eeg: (21538, 256, 58) (N, time, channels)\n     X_bp: (21538, 290) (N, features)\n     X_task: (21538,)\n     Labels: (21538,) each\n\n Splitting data into train/val...\n   Train samples: 17,230\n   Val samples: 4,308\n\n Model dimensions:\n   Input channels: 58\n   Bandpower dim: 290\n   Output channels: 58\n\n Creating TF datasets...\n   Steps/epoch: 269\n   Total steps: 26,900\n\nÔøΩÔ∏è Building model...\n   Parameters: 4,837,162\n    Compiled\n\n Starting training...\n 2025-12-29 21:09:00\n\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n\n======================================================================\n Epoch 1/100\n======================================================================\nEpoch 1/100\nINFO:tensorflow:Collective all_reduce tensors: 110 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nINFO:tensorflow:Collective all_reduce IndexedSlices: 1 all_reduces, num_devices =2, group_size = 2, implementation = CommunicationImplementation.NCCL\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - band_accuracy: 0.1304 - band_loss: 4.4956 - channel_accuracy: 0.0227 - channel_loss: 10.5141 - loss: 7.1199 - region_accuracy: 0.2121 - region_loss: 6.1307 - state_accuracy: 1.0000 - state_loss: 0.1246\n Epoch 1 done in 99.4s\n   Loss: 4.4510 | Val Loss: 1.0701\n   Region Acc: 0.5432 | Val: 0.9174\n======================================================================\n\n\n   LR = 0.000010\n\nEpoch 1: val_loss improved from inf to 1.07010, saving model to /kaggle/working/checkpoints/best_model.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 251ms/step - band_accuracy: 0.1316 - band_loss: 4.4888 - channel_accuracy: 0.0230 - channel_loss: 10.5027 - loss: 7.1101 - region_accuracy: 0.2133 - region_loss: 6.1191 - state_accuracy: 1.0000 - state_loss: 0.1245 - val_band_accuracy: 0.9674 - val_band_loss: 0.2634 - val_channel_accuracy: 0.2840 - val_channel_loss: 2.2398 - val_loss: 1.0701 - val_region_accuracy: 0.9174 - val_region_loss: 0.3636 - val_state_accuracy: 1.0000 - val_state_loss: 0.0242 - learning_rate: 1.0000e-05\n\n======================================================================\n Epoch 2/100\n======================================================================\nEpoch 2/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - band_accuracy: 0.9616 - band_loss: 0.2743 - channel_accuracy: 0.3426 - channel_loss: 2.1218 - loss: 1.0218 - region_accuracy: 0.9123 - region_loss: 0.3607 - state_accuracy: 1.0000 - state_loss: 0.0131\n Epoch 2 done in 68.4s\n   Loss: 0.9577 | Val Loss: 0.8274\n   Region Acc: 0.9157 | Val: 0.9340\n======================================================================\n\n\n   LR = 0.000020\n\nEpoch 2: val_loss improved from 1.07010 to 0.82737, saving model to /kaggle/working/checkpoints/best_model.keras\n\n   Saved checkpoint: checkpoint_epoch_002.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 256ms/step - band_accuracy: 0.9616 - band_loss: 0.2742 - channel_accuracy: 0.3427 - channel_loss: 2.1214 - loss: 1.0215 - region_accuracy: 0.9123 - region_loss: 0.3606 - state_accuracy: 1.0000 - state_loss: 0.0131 - val_band_accuracy: 0.9674 - val_band_loss: 0.1796 - val_channel_accuracy: 0.4317 - val_channel_loss: 1.7539 - val_loss: 0.8274 - val_region_accuracy: 0.9340 - val_region_loss: 0.2685 - val_state_accuracy: 1.0000 - val_state_loss: 0.0043 - learning_rate: 2.0000e-05\n\n======================================================================\n Epoch 3/100\n======================================================================\nEpoch 3/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - band_accuracy: 0.9637 - band_loss: 0.1834 - channel_accuracy: 0.4646 - channel_loss: 1.6817 - loss: 0.7956 - region_accuracy: 0.9350 - region_loss: 0.2604 - state_accuracy: 1.0000 - state_loss: 0.0038\n Epoch 3 done in 68.0s\n   Loss: 0.7710 | Val Loss: 0.7546\n   Region Acc: 0.9370 | Val: 0.9354\n======================================================================\n\n\n   LR = 0.000030\n\nEpoch 3: val_loss improved from 0.82737 to 0.75456, saving model to /kaggle/working/checkpoints/best_model.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 252ms/step - band_accuracy: 0.9637 - band_loss: 0.1834 - channel_accuracy: 0.4646 - channel_loss: 1.6815 - loss: 0.7955 - region_accuracy: 0.9350 - region_loss: 0.2604 - state_accuracy: 1.0000 - state_loss: 0.0038 - val_band_accuracy: 0.9674 - val_band_loss: 0.1200 - val_channel_accuracy: 0.4599 - val_channel_loss: 1.6042 - val_loss: 0.7546 - val_region_accuracy: 0.9354 - val_region_loss: 0.2519 - val_state_accuracy: 1.0000 - val_state_loss: 0.0014 - learning_rate: 3.0000e-05\n\n======================================================================\n Epoch 4/100\n======================================================================\nEpoch 4/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - band_accuracy: 0.9615 - band_loss: 0.1373 - channel_accuracy: 0.5067 - channel_loss: 1.5212 - loss: 0.7187 - region_accuracy: 0.9368 - region_loss: 0.2408 - state_accuracy: 1.0000 - state_loss: 0.0014\n Epoch 4 done in 67.9s\n   Loss: 0.7046 | Val Loss: 0.7155\n   Region Acc: 0.9373 | Val: 0.9363\n======================================================================\n\n\n   LR = 0.000040\n\nEpoch 4: val_loss improved from 0.75456 to 0.71550, saving model to /kaggle/working/checkpoints/best_model.keras\n\n   Saved checkpoint: checkpoint_epoch_004.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 254ms/step - band_accuracy: 0.9615 - band_loss: 0.1373 - channel_accuracy: 0.5067 - channel_loss: 1.5211 - loss: 0.7186 - region_accuracy: 0.9368 - region_loss: 0.2408 - state_accuracy: 1.0000 - state_loss: 0.0014 - val_band_accuracy: 0.9667 - val_band_loss: 0.1091 - val_channel_accuracy: 0.4951 - val_channel_loss: 1.5260 - val_loss: 0.7155 - val_region_accuracy: 0.9363 - val_region_loss: 0.2353 - val_state_accuracy: 1.0000 - val_state_loss: 7.6125e-04 - learning_rate: 4.0000e-05\n\n======================================================================\n Epoch 5/100\n======================================================================\nEpoch 5/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - band_accuracy: 0.9611 - band_loss: 0.1200 - channel_accuracy: 0.5172 - channel_loss: 1.4247 - loss: 0.6699 - region_accuracy: 0.9381 - region_loss: 0.2199 - state_accuracy: 1.0000 - state_loss: 6.7453e-04\n Epoch 5 done in 68.1s\n   Loss: 0.6707 | Val Loss: 0.6741\n   Region Acc: 0.9383 | Val: 0.9366\n======================================================================\n\n\n   LR = 0.000050\n\nEpoch 5: val_loss improved from 0.71550 to 0.67412, saving model to /kaggle/working/checkpoints/best_model.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 253ms/step - band_accuracy: 0.9611 - band_loss: 0.1199 - channel_accuracy: 0.5172 - channel_loss: 1.4247 - loss: 0.6699 - region_accuracy: 0.9381 - region_loss: 0.2199 - state_accuracy: 1.0000 - state_loss: 6.7413e-04 - val_band_accuracy: 0.9671 - val_band_loss: 0.0993 - val_channel_accuracy: 0.5224 - val_channel_loss: 1.4328 - val_loss: 0.6741 - val_region_accuracy: 0.9366 - val_region_loss: 0.2276 - val_state_accuracy: 1.0000 - val_state_loss: 4.3008e-04 - learning_rate: 5.0000e-05\n\n======================================================================\n Epoch 6/100\n======================================================================\nEpoch 6/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - band_accuracy: 0.9641 - band_loss: 0.1073 - channel_accuracy: 0.5273 - channel_loss: 1.3931 - loss: 0.6540 - region_accuracy: 0.9403 - region_loss: 0.2151 - state_accuracy: 1.0000 - state_loss: 3.3883e-04\n Epoch 6 done in 68.0s\n   Loss: 0.6462 | Val Loss: 0.6735\n   Region Acc: 0.9400 | Val: 0.9300\n======================================================================\n\n\n   LR = 0.000060\n\nEpoch 6: val_loss improved from 0.67412 to 0.67352, saving model to /kaggle/working/checkpoints/best_model.keras\n\n   Saved checkpoint: checkpoint_epoch_006.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 254ms/step - band_accuracy: 0.9641 - band_loss: 0.1073 - channel_accuracy: 0.5273 - channel_loss: 1.3930 - loss: 0.6540 - region_accuracy: 0.9403 - region_loss: 0.2151 - state_accuracy: 1.0000 - state_loss: 3.3859e-04 - val_band_accuracy: 0.9650 - val_band_loss: 0.1063 - val_channel_accuracy: 0.5093 - val_channel_loss: 1.4221 - val_loss: 0.6735 - val_region_accuracy: 0.9300 - val_region_loss: 0.2351 - val_state_accuracy: 1.0000 - val_state_loss: 1.8832e-04 - learning_rate: 6.0000e-05\n\n======================================================================\n Epoch 7/100\n======================================================================\nEpoch 7/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - band_accuracy: 0.9621 - band_loss: 0.1148 - channel_accuracy: 0.5390 - channel_loss: 1.3497 - loss: 0.6385 - region_accuracy: 0.9378 - region_loss: 0.2178 - state_accuracy: 1.0000 - state_loss: 1.4890e-04\n Epoch 7 done in 67.9s\n   Loss: 0.6317 | Val Loss: 0.6493\n   Region Acc: 0.9398 | Val: 0.9370\n======================================================================\n\n\n   LR = 0.000070\n\nEpoch 7: val_loss improved from 0.67352 to 0.64930, saving model to /kaggle/working/checkpoints/best_model.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 252ms/step - band_accuracy: 0.9621 - band_loss: 0.1148 - channel_accuracy: 0.5390 - channel_loss: 1.3497 - loss: 0.6385 - region_accuracy: 0.9378 - region_loss: 0.2178 - state_accuracy: 1.0000 - state_loss: 1.4881e-04 - val_band_accuracy: 0.9690 - val_band_loss: 0.0969 - val_channel_accuracy: 0.5233 - val_channel_loss: 1.3841 - val_loss: 0.6493 - val_region_accuracy: 0.9370 - val_region_loss: 0.2149 - val_state_accuracy: 1.0000 - val_state_loss: 9.6812e-05 - learning_rate: 7.0000e-05\n\n======================================================================\n Epoch 8/100\n======================================================================\nEpoch 8/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - band_accuracy: 0.9648 - band_loss: 0.1047 - channel_accuracy: 0.5439 - channel_loss: 1.3100 - loss: 0.6156 - region_accuracy: 0.9416 - region_loss: 0.2028 - state_accuracy: 1.0000 - state_loss: 7.3424e-05\n Epoch 8 done in 68.1s\n   Loss: 0.6230 | Val Loss: 0.6592\n   Region Acc: 0.9394 | Val: 0.9279\n======================================================================\n\n\n   LR = 0.000080\n\nEpoch 8: val_loss did not improve from 0.64930\n\n   Saved checkpoint: checkpoint_epoch_008.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 252ms/step - band_accuracy: 0.9648 - band_loss: 0.1047 - channel_accuracy: 0.5439 - channel_loss: 1.3100 - loss: 0.6156 - region_accuracy: 0.9416 - region_loss: 0.2028 - state_accuracy: 1.0000 - state_loss: 7.3395e-05 - val_band_accuracy: 0.9690 - val_band_loss: 0.0949 - val_channel_accuracy: 0.5268 - val_channel_loss: 1.4003 - val_loss: 0.6592 - val_region_accuracy: 0.9279 - val_region_loss: 0.2240 - val_state_accuracy: 1.0000 - val_state_loss: 2.5088e-05 - learning_rate: 8.0000e-05\n\n======================================================================\n Epoch 9/100\n======================================================================\nEpoch 9/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - band_accuracy: 0.9648 - band_loss: 0.0999 - channel_accuracy: 0.5508 - channel_loss: 1.2908 - loss: 0.6067 - region_accuracy: 0.9429 - region_loss: 0.2009 - state_accuracy: 1.0000 - state_loss: 3.0902e-05\n Epoch 9 done in 68.0s\n   Loss: 0.6096 | Val Loss: 0.6303\n   Region Acc: 0.9400 | Val: 0.9394\n======================================================================\n\n\n   LR = 0.000090\n\nEpoch 9: val_loss improved from 0.64930 to 0.63033, saving model to /kaggle/working/checkpoints/best_model.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 252ms/step - band_accuracy: 0.9648 - band_loss: 0.0999 - channel_accuracy: 0.5507 - channel_loss: 1.2908 - loss: 0.6067 - region_accuracy: 0.9429 - region_loss: 0.2009 - state_accuracy: 1.0000 - state_loss: 3.0887e-05 - val_band_accuracy: 0.9692 - val_band_loss: 0.0929 - val_channel_accuracy: 0.5431 - val_channel_loss: 1.3440 - val_loss: 0.6303 - val_region_accuracy: 0.9394 - val_region_loss: 0.2086 - val_state_accuracy: 1.0000 - val_state_loss: 1.2395e-05 - learning_rate: 9.0000e-05\n\n======================================================================\n Epoch 10/100\n======================================================================\nEpoch 10/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - band_accuracy: 0.9640 - band_loss: 0.1049 - channel_accuracy: 0.5480 - channel_loss: 1.2844 - loss: 0.6014 - region_accuracy: 0.9428 - region_loss: 0.1929 - state_accuracy: 1.0000 - state_loss: 1.5733e-05\n Epoch 10 done in 68.0s\n   Loss: 0.6008 | Val Loss: 0.6631\n   Region Acc: 0.9428 | Val: 0.9256\n======================================================================\n\n\n   LR = 0.000100\n\nEpoch 10: val_loss did not improve from 0.63033\n\n   Saved checkpoint: checkpoint_epoch_010.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 252ms/step - band_accuracy: 0.9640 - band_loss: 0.1049 - channel_accuracy: 0.5480 - channel_loss: 1.2844 - loss: 0.6014 - region_accuracy: 0.9428 - region_loss: 0.1930 - state_accuracy: 1.0000 - state_loss: 1.5725e-05 - val_band_accuracy: 0.9650 - val_band_loss: 0.1090 - val_channel_accuracy: 0.5315 - val_channel_loss: 1.3882 - val_loss: 0.6631 - val_region_accuracy: 0.9256 - val_region_loss: 0.2424 - val_state_accuracy: 1.0000 - val_state_loss: 1.3727e-05 - learning_rate: 1.0000e-04\n\n======================================================================\n Epoch 11/100\n======================================================================\nEpoch 11/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9659 - band_loss: 0.0957 - channel_accuracy: 0.5529 - channel_loss: 1.2672 - loss: 0.5958 - region_accuracy: 0.9397 - region_loss: 0.1983 - state_accuracy: 1.0000 - state_loss: 1.1887e-05\n Epoch 11 done in 67.0s\n   Loss: 0.5888 | Val Loss: 0.6409\n   Region Acc: 0.9430 | Val: 0.9312\n======================================================================\n\n\n   LR = 0.000100\n\nEpoch 11: val_loss did not improve from 0.63033\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 246ms/step - band_accuracy: 0.9659 - band_loss: 0.0957 - channel_accuracy: 0.5529 - channel_loss: 1.2672 - loss: 0.5957 - region_accuracy: 0.9397 - region_loss: 0.1982 - state_accuracy: 1.0000 - state_loss: 1.1887e-05 - val_band_accuracy: 0.9671 - val_band_loss: 0.1006 - val_channel_accuracy: 0.5443 - val_channel_loss: 1.3486 - val_loss: 0.6409 - val_region_accuracy: 0.9312 - val_region_loss: 0.2284 - val_state_accuracy: 1.0000 - val_state_loss: 7.4063e-06 - learning_rate: 9.9970e-05\n\n======================================================================\n Epoch 12/100\n======================================================================\nEpoch 12/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9655 - band_loss: 0.1034 - channel_accuracy: 0.5623 - channel_loss: 1.2313 - loss: 0.5779 - region_accuracy: 0.9448 - region_loss: 0.1877 - state_accuracy: 1.0000 - state_loss: 8.7426e-06\n Epoch 12 done in 66.8s\n   Loss: 0.5731 | Val Loss: 0.6162\n   Region Acc: 0.9448 | Val: 0.9361\n======================================================================\n\n\n   LR = 0.000100\n\nEpoch 12: val_loss improved from 0.63033 to 0.61619, saving model to /kaggle/working/checkpoints/best_model.keras\n\n   Saved checkpoint: checkpoint_epoch_012.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 250ms/step - band_accuracy: 0.9655 - band_loss: 0.1034 - channel_accuracy: 0.5624 - channel_loss: 1.2312 - loss: 0.5779 - region_accuracy: 0.9448 - region_loss: 0.1877 - state_accuracy: 1.0000 - state_loss: 8.7435e-06 - val_band_accuracy: 0.9646 - val_band_loss: 0.0994 - val_channel_accuracy: 0.5382 - val_channel_loss: 1.3159 - val_loss: 0.6162 - val_region_accuracy: 0.9361 - val_region_loss: 0.1997 - val_state_accuracy: 1.0000 - val_state_loss: 1.4594e-05 - learning_rate: 9.9878e-05\n\n======================================================================\n Epoch 13/100\n======================================================================\nEpoch 13/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - band_accuracy: 0.9679 - band_loss: 0.0918 - channel_accuracy: 0.5759 - channel_loss: 1.1923 - loss: 0.5553 - region_accuracy: 0.9468 - region_loss: 0.1729 - state_accuracy: 1.0000 - state_loss: 9.0553e-06\n Epoch 13 done in 67.1s\n   Loss: 0.5554 | Val Loss: 0.6207\n   Region Acc: 0.9445 | Val: 0.9396\n======================================================================\n\n\n   LR = 0.000100\n\nEpoch 13: val_loss did not improve from 0.61619\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 246ms/step - band_accuracy: 0.9679 - band_loss: 0.0918 - channel_accuracy: 0.5759 - channel_loss: 1.1923 - loss: 0.5553 - region_accuracy: 0.9467 - region_loss: 0.1730 - state_accuracy: 1.0000 - state_loss: 9.0504e-06 - val_band_accuracy: 0.9678 - val_band_loss: 0.0917 - val_channel_accuracy: 0.5522 - val_channel_loss: 1.3189 - val_loss: 0.6207 - val_region_accuracy: 0.9396 - val_region_loss: 0.2099 - val_state_accuracy: 1.0000 - val_state_loss: 6.2062e-06 - learning_rate: 9.9726e-05\n\n======================================================================\n Epoch 14/100\n======================================================================\nEpoch 14/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9693 - band_loss: 0.0882 - channel_accuracy: 0.6040 - channel_loss: 1.1266 - loss: 0.5251 - region_accuracy: 0.9492 - region_loss: 0.1641 - state_accuracy: 1.0000 - state_loss: 7.3170e-06\n Epoch 14 done in 66.8s\n   Loss: 0.5362 | Val Loss: 0.6008\n   Region Acc: 0.9487 | Val: 0.9387\n======================================================================\n\n\n   LR = 0.000100\n\nEpoch 14: val_loss improved from 0.61619 to 0.60084, saving model to /kaggle/working/checkpoints/best_model.keras\n\n   Saved checkpoint: checkpoint_epoch_014.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 250ms/step - band_accuracy: 0.9693 - band_loss: 0.0882 - channel_accuracy: 0.6040 - channel_loss: 1.1267 - loss: 0.5252 - region_accuracy: 0.9492 - region_loss: 0.1642 - state_accuracy: 1.0000 - state_loss: 7.3145e-06 - val_band_accuracy: 0.9692 - val_band_loss: 0.0895 - val_channel_accuracy: 0.5501 - val_channel_loss: 1.2864 - val_loss: 0.6008 - val_region_accuracy: 0.9387 - val_region_loss: 0.1934 - val_state_accuracy: 1.0000 - val_state_loss: 3.5589e-06 - learning_rate: 9.9513e-05\n\n======================================================================\n Epoch 15/100\n======================================================================\nEpoch 15/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9658 - band_loss: 0.0955 - channel_accuracy: 0.5973 - channel_loss: 1.1097 - loss: 0.5141 - region_accuracy: 0.9506 - region_loss: 0.1516 - state_accuracy: 1.0000 - state_loss: 4.5323e-06\n Epoch 15 done in 66.9s\n   Loss: 0.5178 | Val Loss: 0.6354\n   Region Acc: 0.9491 | Val: 0.9312\n======================================================================\n\n\n   LR = 0.000099\n\nEpoch 15: val_loss did not improve from 0.60084\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 245ms/step - band_accuracy: 0.9658 - band_loss: 0.0954 - channel_accuracy: 0.5973 - channel_loss: 1.1097 - loss: 0.5141 - region_accuracy: 0.9506 - region_loss: 0.1516 - state_accuracy: 1.0000 - state_loss: 4.5332e-06 - val_band_accuracy: 0.9671 - val_band_loss: 0.0913 - val_channel_accuracy: 0.5375 - val_channel_loss: 1.3392 - val_loss: 0.6354 - val_region_accuracy: 0.9312 - val_region_loss: 0.2265 - val_state_accuracy: 1.0000 - val_state_loss: 3.6888e-06 - learning_rate: 9.9240e-05\n\n======================================================================\n Epoch 16/100\n======================================================================\nEpoch 16/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9694 - band_loss: 0.0870 - channel_accuracy: 0.6187 - channel_loss: 1.0549 - loss: 0.4878 - region_accuracy: 0.9523 - region_loss: 0.1428 - state_accuracy: 1.0000 - state_loss: 4.3787e-06\n Epoch 16 done in 66.9s\n   Loss: 0.4939 | Val Loss: 0.6205\n   Region Acc: 0.9520 | Val: 0.9422\n======================================================================\n\n\n   LR = 0.000099\n\nEpoch 16: val_loss did not improve from 0.60084\n\n   Saved checkpoint: checkpoint_epoch_016.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 248ms/step - band_accuracy: 0.9694 - band_loss: 0.0870 - channel_accuracy: 0.6187 - channel_loss: 1.0549 - loss: 0.4878 - region_accuracy: 0.9523 - region_loss: 0.1428 - state_accuracy: 1.0000 - state_loss: 4.3760e-06 - val_band_accuracy: 0.9699 - val_band_loss: 0.0974 - val_channel_accuracy: 0.5350 - val_channel_loss: 1.3300 - val_loss: 0.6205 - val_region_accuracy: 0.9422 - val_region_loss: 0.1968 - val_state_accuracy: 1.0000 - val_state_loss: 2.1514e-06 - learning_rate: 9.8907e-05\n\n======================================================================\n Epoch 17/100\n======================================================================\nEpoch 17/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - band_accuracy: 0.9696 - band_loss: 0.0883 - channel_accuracy: 0.6424 - channel_loss: 0.9974 - loss: 0.4603 - region_accuracy: 0.9544 - region_loss: 0.1313 - state_accuracy: 1.0000 - state_loss: 3.1334e-06\n Epoch 17 done in 67.1s\n   Loss: 0.4620 | Val Loss: 0.6182\n   Region Acc: 0.9563 | Val: 0.9366\n======================================================================\n\n\n   LR = 0.000099\n\nEpoch 17: val_loss did not improve from 0.60084\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 246ms/step - band_accuracy: 0.9696 - band_loss: 0.0883 - channel_accuracy: 0.6424 - channel_loss: 0.9974 - loss: 0.4603 - region_accuracy: 0.9544 - region_loss: 0.1313 - state_accuracy: 1.0000 - state_loss: 3.1335e-06 - val_band_accuracy: 0.9627 - val_band_loss: 0.0961 - val_channel_accuracy: 0.5546 - val_channel_loss: 1.3099 - val_loss: 0.6182 - val_region_accuracy: 0.9366 - val_region_loss: 0.2115 - val_state_accuracy: 1.0000 - val_state_loss: 3.6439e-06 - learning_rate: 9.8515e-05\n\n======================================================================\n Epoch 18/100\n======================================================================\nEpoch 18/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9698 - band_loss: 0.0824 - channel_accuracy: 0.6667 - channel_loss: 0.9194 - loss: 0.4222 - region_accuracy: 0.9601 - region_loss: 0.1155 - state_accuracy: 1.0000 - state_loss: 4.1580e-06\n Epoch 18 done in 67.0s\n   Loss: 0.4343 | Val Loss: 0.6805\n   Region Acc: 0.9590 | Val: 0.9170\n======================================================================\n\n\n   LR = 0.000098\n\nEpoch 18: val_loss did not improve from 0.60084\n\n   Saved checkpoint: checkpoint_epoch_018.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 248ms/step - band_accuracy: 0.9698 - band_loss: 0.0824 - channel_accuracy: 0.6666 - channel_loss: 0.9195 - loss: 0.4223 - region_accuracy: 0.9601 - region_loss: 0.1156 - state_accuracy: 1.0000 - state_loss: 4.1585e-06 - val_band_accuracy: 0.9503 - val_band_loss: 0.1154 - val_channel_accuracy: 0.5450 - val_channel_loss: 1.4107 - val_loss: 0.6805 - val_region_accuracy: 0.9170 - val_region_loss: 0.2617 - val_state_accuracy: 1.0000 - val_state_loss: 3.2783e-06 - learning_rate: 9.8063e-05\n\n======================================================================\n Epoch 19/100\n======================================================================\nEpoch 19/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9727 - band_loss: 0.0783 - channel_accuracy: 0.6816 - channel_loss: 0.8695 - loss: 0.3976 - region_accuracy: 0.9640 - region_loss: 0.1048 - state_accuracy: 1.0000 - state_loss: 3.4576e-06\n Epoch 19 done in 67.4s\n   Loss: 0.4075 | Val Loss: 0.6944\n   Region Acc: 0.9650 | Val: 0.9282\n======================================================================\n\n\n   LR = 0.000098\n\nEpoch 19: val_loss did not improve from 0.60084\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 247ms/step - band_accuracy: 0.9727 - band_loss: 0.0783 - channel_accuracy: 0.6815 - channel_loss: 0.8696 - loss: 0.3976 - region_accuracy: 0.9640 - region_loss: 0.1048 - state_accuracy: 1.0000 - state_loss: 3.4569e-06 - val_band_accuracy: 0.9608 - val_band_loss: 0.1023 - val_channel_accuracy: 0.5229 - val_channel_loss: 1.4629 - val_loss: 0.6944 - val_region_accuracy: 0.9282 - val_region_loss: 0.2475 - val_state_accuracy: 1.0000 - val_state_loss: 4.6188e-06 - learning_rate: 9.7553e-05\n\n======================================================================\n Epoch 20/100\n======================================================================\nEpoch 20/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9721 - band_loss: 0.0822 - channel_accuracy: 0.7006 - channel_loss: 0.8205 - loss: 0.3708 - region_accuracy: 0.9702 - region_loss: 0.0861 - state_accuracy: 1.0000 - state_loss: 4.2660e-06\n Epoch 20 done in 67.1s\n   Loss: 0.3730 | Val Loss: 0.6776\n   Region Acc: 0.9689 | Val: 0.9398\n======================================================================\n\n\n   LR = 0.000097\n\nEpoch 20: val_loss did not improve from 0.60084\n\n   Saved checkpoint: checkpoint_epoch_020.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 248ms/step - band_accuracy: 0.9721 - band_loss: 0.0822 - channel_accuracy: 0.7006 - channel_loss: 0.8205 - loss: 0.3708 - region_accuracy: 0.9702 - region_loss: 0.0861 - state_accuracy: 1.0000 - state_loss: 4.2666e-06 - val_band_accuracy: 0.9678 - val_band_loss: 0.0914 - val_channel_accuracy: 0.5469 - val_channel_loss: 1.4068 - val_loss: 0.6776 - val_region_accuracy: 0.9398 - val_region_loss: 0.2644 - val_state_accuracy: 1.0000 - val_state_loss: 2.5598e-06 - learning_rate: 9.6985e-05\n\n======================================================================\n Epoch 21/100\n======================================================================\nEpoch 21/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9757 - band_loss: 0.0717 - channel_accuracy: 0.7400 - channel_loss: 0.7269 - loss: 0.3260 - region_accuracy: 0.9753 - region_loss: 0.0702 - state_accuracy: 1.0000 - state_loss: 3.7646e-06\n Epoch 21 done in 66.9s\n   Loss: 0.3310 | Val Loss: 0.6915\n   Region Acc: 0.9748 | Val: 0.9335\n======================================================================\n\n\n   LR = 0.000096\n\nEpoch 21: val_loss did not improve from 0.60084\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 245ms/step - band_accuracy: 0.9757 - band_loss: 0.0718 - channel_accuracy: 0.7400 - channel_loss: 0.7269 - loss: 0.3260 - region_accuracy: 0.9753 - region_loss: 0.0702 - state_accuracy: 1.0000 - state_loss: 3.7653e-06 - val_band_accuracy: 0.9648 - val_band_loss: 0.0949 - val_channel_accuracy: 0.5529 - val_channel_loss: 1.4346 - val_loss: 0.6915 - val_region_accuracy: 0.9335 - val_region_loss: 0.2704 - val_state_accuracy: 1.0000 - val_state_loss: 2.2037e-06 - learning_rate: 9.6359e-05\n\n======================================================================\n Epoch 22/100\n======================================================================\nEpoch 22/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9733 - band_loss: 0.0762 - channel_accuracy: 0.7617 - channel_loss: 0.6510 - loss: 0.2900 - region_accuracy: 0.9787 - region_loss: 0.0548 - state_accuracy: 1.0000 - state_loss: 2.9452e-06\n Epoch 22 done in 67.0s\n   Loss: 0.2981 | Val Loss: 0.7604\n   Region Acc: 0.9793 | Val: 0.9321\n======================================================================\n\n\n   LR = 0.000096\n\nEpoch 22: val_loss did not improve from 0.60084\n\n   Saved checkpoint: checkpoint_epoch_022.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 248ms/step - band_accuracy: 0.9733 - band_loss: 0.0761 - channel_accuracy: 0.7617 - channel_loss: 0.6511 - loss: 0.2900 - region_accuracy: 0.9787 - region_loss: 0.0549 - state_accuracy: 1.0000 - state_loss: 2.9462e-06 - val_band_accuracy: 0.9527 - val_band_loss: 0.1188 - val_channel_accuracy: 0.5427 - val_channel_loss: 1.5972 - val_loss: 0.7604 - val_region_accuracy: 0.9321 - val_region_loss: 0.2740 - val_state_accuracy: 1.0000 - val_state_loss: 3.6958e-06 - learning_rate: 9.5677e-05\n\n======================================================================\n Epoch 23/100\n======================================================================\nEpoch 23/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9746 - band_loss: 0.0719 - channel_accuracy: 0.7902 - channel_loss: 0.5740 - loss: 0.2557 - region_accuracy: 0.9848 - region_loss: 0.0473 - state_accuracy: 1.0000 - state_loss: 3.5349e-06\n Epoch 23 done in 67.0s\n   Loss: 0.2605 | Val Loss: 0.7491\n   Region Acc: 0.9849 | Val: 0.9333\n======================================================================\n\n\n   LR = 0.000095\n\nEpoch 23: val_loss did not improve from 0.60084\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 246ms/step - band_accuracy: 0.9746 - band_loss: 0.0719 - channel_accuracy: 0.7902 - channel_loss: 0.5740 - loss: 0.2557 - region_accuracy: 0.9848 - region_loss: 0.0473 - state_accuracy: 1.0000 - state_loss: 3.5326e-06 - val_band_accuracy: 0.9613 - val_band_loss: 0.1046 - val_channel_accuracy: 0.5557 - val_channel_loss: 1.5624 - val_loss: 0.7491 - val_region_accuracy: 0.9333 - val_region_loss: 0.2842 - val_state_accuracy: 1.0000 - val_state_loss: 1.5866e-06 - learning_rate: 9.4940e-05\n\n======================================================================\n Epoch 24/100\n======================================================================\nEpoch 24/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9747 - band_loss: 0.0722 - channel_accuracy: 0.8230 - channel_loss: 0.4993 - loss: 0.2200 - region_accuracy: 0.9903 - region_loss: 0.0328 - state_accuracy: 1.0000 - state_loss: 2.3319e-06\n Epoch 24 done in 66.9s\n   Loss: 0.2270 | Val Loss: 0.7714\n   Region Acc: 0.9880 | Val: 0.9333\n======================================================================\n\n\n   LR = 0.000094\n\nEpoch 24: val_loss did not improve from 0.60084\n\n   Saved checkpoint: checkpoint_epoch_024.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 248ms/step - band_accuracy: 0.9747 - band_loss: 0.0722 - channel_accuracy: 0.8230 - channel_loss: 0.4993 - loss: 0.2201 - region_accuracy: 0.9903 - region_loss: 0.0328 - state_accuracy: 1.0000 - state_loss: 2.3314e-06 - val_band_accuracy: 0.9660 - val_band_loss: 0.0943 - val_channel_accuracy: 0.5564 - val_channel_loss: 1.6385 - val_loss: 0.7714 - val_region_accuracy: 0.9333 - val_region_loss: 0.2665 - val_state_accuracy: 1.0000 - val_state_loss: 1.9680e-06 - learning_rate: 9.4147e-05\n\n======================================================================\n Epoch 25/100\n======================================================================\nEpoch 25/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9760 - band_loss: 0.0669 - channel_accuracy: 0.8510 - channel_loss: 0.4233 - loss: 0.1883 - region_accuracy: 0.9903 - region_loss: 0.0308 - state_accuracy: 1.0000 - state_loss: 1.4794e-06\n Epoch 25 done in 67.1s\n   Loss: 0.2024 | Val Loss: 0.7885\n   Region Acc: 0.9895 | Val: 0.9373\n======================================================================\n\n\n   LR = 0.000093\n\nEpoch 25: val_loss did not improve from 0.60084\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 246ms/step - band_accuracy: 0.9760 - band_loss: 0.0669 - channel_accuracy: 0.8510 - channel_loss: 0.4234 - loss: 0.1883 - region_accuracy: 0.9903 - region_loss: 0.0308 - state_accuracy: 1.0000 - state_loss: 1.4797e-06 - val_band_accuracy: 0.9711 - val_band_loss: 0.0931 - val_channel_accuracy: 0.5648 - val_channel_loss: 1.6688 - val_loss: 0.7885 - val_region_accuracy: 0.9373 - val_region_loss: 0.2791 - val_state_accuracy: 1.0000 - val_state_loss: 1.1419e-06 - learning_rate: 9.3301e-05\n\n======================================================================\n Epoch 26/100\n======================================================================\nEpoch 26/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9769 - band_loss: 0.0660 - channel_accuracy: 0.8639 - channel_loss: 0.3867 - loss: 0.1711 - region_accuracy: 0.9922 - region_loss: 0.0245 - state_accuracy: 1.0000 - state_loss: 1.3148e-06\n Epoch 26 done in 67.0s\n   Loss: 0.1751 | Val Loss: 0.8287\n   Region Acc: 0.9915 | Val: 0.9359\n======================================================================\n\n\n   LR = 0.000092\n\nEpoch 26: val_loss did not improve from 0.60084\n\n   Saved checkpoint: checkpoint_epoch_026.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 248ms/step - band_accuracy: 0.9769 - band_loss: 0.0660 - channel_accuracy: 0.8639 - channel_loss: 0.3867 - loss: 0.1711 - region_accuracy: 0.9922 - region_loss: 0.0245 - state_accuracy: 1.0000 - state_loss: 1.3145e-06 - val_band_accuracy: 0.9681 - val_band_loss: 0.0937 - val_channel_accuracy: 0.5639 - val_channel_loss: 1.7450 - val_loss: 0.8287 - val_region_accuracy: 0.9359 - val_region_loss: 0.3034 - val_state_accuracy: 1.0000 - val_state_loss: 1.6065e-06 - learning_rate: 9.2402e-05\n\n======================================================================\n Epoch 27/100\n======================================================================\nEpoch 27/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9776 - band_loss: 0.0671 - channel_accuracy: 0.8787 - channel_loss: 0.3399 - loss: 0.1525 - region_accuracy: 0.9913 - region_loss: 0.0247 - state_accuracy: 1.0000 - state_loss: 1.4182e-06\n Epoch 27 done in 67.1s\n   Loss: 0.1556 | Val Loss: 0.8475\n   Region Acc: 0.9909 | Val: 0.9405\n======================================================================\n\n\n   LR = 0.000091\n\nEpoch 27: val_loss did not improve from 0.60084\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 246ms/step - band_accuracy: 0.9776 - band_loss: 0.0671 - channel_accuracy: 0.8787 - channel_loss: 0.3399 - loss: 0.1525 - region_accuracy: 0.9913 - region_loss: 0.0247 - state_accuracy: 1.0000 - state_loss: 1.4182e-06 - val_band_accuracy: 0.9674 - val_band_loss: 0.0996 - val_channel_accuracy: 0.5676 - val_channel_loss: 1.7860 - val_loss: 0.8475 - val_region_accuracy: 0.9405 - val_region_loss: 0.3077 - val_state_accuracy: 1.0000 - val_state_loss: 1.2816e-06 - learning_rate: 9.1452e-05\n\n======================================================================\n Epoch 28/100\n======================================================================\nEpoch 28/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - band_accuracy: 0.9764 - band_loss: 0.0641 - channel_accuracy: 0.8996 - channel_loss: 0.2844 - loss: 0.1266 - region_accuracy: 0.9947 - region_loss: 0.0161 - state_accuracy: 1.0000 - state_loss: 1.3601e-06\n Epoch 28 done in 66.9s\n   Loss: 0.1299 | Val Loss: 0.9249\n   Region Acc: 0.9944 | Val: 0.9352\n======================================================================\n\n\n   LR = 0.000090\n\nEpoch 28: val_loss did not improve from 0.60084\n\n   Saved checkpoint: checkpoint_epoch_028.keras\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 248ms/step - band_accuracy: 0.9764 - band_loss: 0.0641 - channel_accuracy: 0.8995 - channel_loss: 0.2844 - loss: 0.1266 - region_accuracy: 0.9947 - region_loss: 0.0161 - state_accuracy: 1.0000 - state_loss: 1.3600e-06 - val_band_accuracy: 0.9711 - val_band_loss: 0.0920 - val_channel_accuracy: 0.5676 - val_channel_loss: 1.9529 - val_loss: 0.9249 - val_region_accuracy: 0.9352 - val_region_loss: 0.3364 - val_state_accuracy: 1.0000 - val_state_loss: 8.3307e-07 - learning_rate: 9.0451e-05\n\n======================================================================\n Epoch 29/100\n======================================================================\nEpoch 29/100\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - band_accuracy: 0.9772 - band_loss: 0.0643 - channel_accuracy: 0.9184 - channel_loss: 0.2370 - loss: 0.1063 - region_accuracy: 0.9968 - region_loss: 0.0126 - state_accuracy: 1.0000 - state_loss: 1.0184e-06\n Epoch 29 done in 67.1s\n   Loss: 0.1157 | Val Loss: 0.9432\n   Region Acc: 0.9961 | Val: 0.9335\n======================================================================\n\n\n   LR = 0.000089\n\nEpoch 29: val_loss did not improve from 0.60084\n\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 246ms/step - band_accuracy: 0.9772 - band_loss: 0.0643 - channel_accuracy: 0.9183 - channel_loss: 0.2371 - loss: 0.1063 - region_accuracy: 0.9968 - region_loss: 0.0127 - state_accuracy: 1.0000 - state_loss: 1.0189e-06 - val_band_accuracy: 0.9667 - val_band_loss: 0.0994 - val_channel_accuracy: 0.5639 - val_channel_loss: 2.0067 - val_loss: 0.9432 - val_region_accuracy: 0.9335 - val_region_loss: 0.3264 - val_state_accuracy: 1.0000 - val_state_loss: 9.8837e-07 - learning_rate: 8.9401e-05\nEpoch 29: early stopping\nRestoring model weights from the end of the best epoch: 14.\n\n======================================================================\n TRAINING COMPLETE!\n======================================================================\n\n Saved to: /kaggle/working/checkpoints\n   - final_model.keras\n   - best_model.keras\n\n Training Summary:\n   Best val_loss: 0.6008\n   Final region acc: 0.9961\n\n Next: Click 'Save Version' to commit checkpoints!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"10: Save Training Results & Metrics","metadata":{}},{"cell_type":"code","source":"if history:\n    print(\"\\n Saving training results...\")\n    \n    # Convert history to JSON-serializable format\n    history_dict = {\n        key: [float(val) for val in values] \n        for key, values in history.history.items()\n    }\n    \n    # Save training history\n    history_path = os.path.join(RESULTS_DIR, 'training_history.json')\n    with open(history_path, 'w') as f:\n        json.dump(history_dict, f, indent=2)\n    print(f\"   Saved: training_history.json\")\n    \n    # Get model dimensions from loaded data\n    train_result = load_preprocessed_data('train')\n    if train_result:\n        _, _, train_meta = train_result\n        NUM_CHANNELS_USED = train_meta['num_channels']\n    else:\n        NUM_CHANNELS_USED = \"unknown\"\n    \n    # Save training configuration\n    config = {\n        'model_architecture': {\n            'name': 'CogniVue_Transformer',\n            'num_input_channels': NUM_CHANNELS_USED,\n            'd_model': D_MODEL,\n            'num_layers': NUM_LAYERS,\n            'num_heads': NUM_HEADS,\n            'ff_dim': FF_DIM,\n            'dropout': DROPOUT,\n            'window_size': WINDOW_SIZE_SAMPLES\n        },\n        'training_params': {\n            'epochs_trained': len(history.history['loss']),\n            'total_epochs': EPOCHS,\n            'batch_size': BATCH_SIZE,\n            'initial_lr': INITIAL_LR,\n            'warmup_epochs': WARMUP_EPOCHS,\n            'weight_decay': WEIGHT_DECAY,\n            'gradient_clip_norm': GRADIENT_CLIP_NORM\n        },\n        'output_tasks': {\n            'num_output_channels': NUM_OUTPUT_REGIONS,\n            'num_regions': NUM_OUTPUT_REGIONS,\n            'num_bands': NUM_OUTPUT_BANDS,\n            'num_states': NUM_OUTPUT_STATES\n        },\n        'final_metrics': {\n            'best_val_loss': float(min(history.history['val_loss'])),\n            'final_train_loss': float(history.history['loss'][-1]),\n            'final_val_loss': float(history.history['val_loss'][-1]),\n            'final_region_accuracy': float(history.history['region_accuracy'][-1]),\n            'final_val_region_accuracy': float(history.history['val_region_accuracy'][-1])\n        },\n        'training_info': {\n            'completed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n            'tensorflow_version': tf.__version__,\n            'accelerator': 'TPU' if 'TPU' in str(strategy.__class__) else 'CPU/GPU'\n        }\n    }\n    \n    config_path = os.path.join(RESULTS_DIR, 'training_config.json')\n    with open(config_path, 'w') as f:\n        json.dump(config, f, indent=2)\n    print(f\"   Saved: training_config.json\")\n    \n    # Create a summary markdown file\n    summary_md = f\"\"\"# CogniVue Training Summary\n\n**Training Completed:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n## Model Architecture\n- **Model:** CogniVue Transformer\n- **Input Channels:** {NUM_CHANNELS_USED}\n- **Model Dimension:** {D_MODEL}\n- **Transformer Layers:** {NUM_LAYERS}\n- **Attention Heads:** {NUM_HEADS}\n- **Feedforward Dim:** {FF_DIM}\n- **Dropout:** {DROPOUT}\n\n## Training Configuration\n- **Epochs:** {len(history.history['loss'])}/{EPOCHS}\n- **Batch Size:** {BATCH_SIZE}\n- **Initial LR:** {INITIAL_LR}\n- **Warmup Epochs:** {WARMUP_EPOCHS}\n- **Weight Decay:** {WEIGHT_DECAY}\n\n## Final Performance\n- **Best Val Loss:** {min(history.history['val_loss']):.4f}\n- **Final Train Loss:** {history.history['loss'][-1]:.4f}\n- **Final Val Loss:** {history.history['val_loss'][-1]:.4f}\n- **Final Region Accuracy:** {history.history['region_accuracy'][-1]:.4f}\n- **Final Val Region Accuracy:** {history.history['val_region_accuracy'][-1]:.4f}\n\n## Output Files\n- `checkpoints/best_model.keras` - Best model weights\n- `checkpoints/final_model.keras` - Final model weights\n- `checkpoints/checkpoint_epoch_*.keras` - Periodic checkpoints\n- `results/training_history.json` - Loss and metrics per epoch\n- `results/training_config.json` - Full configuration\n- `logs/` - TensorBoard logs\n\"\"\"\n    \n    summary_path = os.path.join(RESULTS_DIR, 'TRAINING_SUMMARY.md')\n    with open(summary_path, 'w') as f:\n        f.write(summary_md)\n    print(f\"   Saved: TRAINING_SUMMARY.md\")\n    \n    print(\"\\n All results saved!\")\n    print(f\"\\n Saved files:\")\n    print(f\"   {RESULTS_DIR}/\")\n    print(f\"   ‚îú‚îÄ‚îÄ training_history.json\")\n    print(f\"   ‚îú‚îÄ‚îÄ training_config.json\")\n    print(f\"   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\")\n    print(f\"\\n   {CHECKPOINT_DIR}/\")\n    print(f\"   ‚îú‚îÄ‚îÄ best_model.keras\")\n    print(f\"   ‚îú‚îÄ‚îÄ final_model.keras\")\n    print(f\"   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\")\n    \nelse:\n    print(\"\\n‚ö†Ô∏è No training history to save\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T21:42:28.126968Z","iopub.execute_input":"2025-12-29T21:42:28.127248Z","iopub.status.idle":"2025-12-29T21:42:30.030053Z","shell.execute_reply.started":"2025-12-29T21:42:28.127224Z","shell.execute_reply":"2025-12-29T21:42:30.029477Z"}},"outputs":[{"name":"stdout","text":"\n Saving training results...\n   Saved: training_history.json\n\n Loading train data from: /kaggle/input/preprocessed-cog-eeg-dataset/processed/train/train_data.pkl\n   Loaded 21,538 samples\n\n  Data format:\n     X shape: (58, 256) (channels, time)\n     bp shape: (58, 5) (channels, bands)\n     Channels: 58\n\n   Converting to arrays...\n   Final shapes:\n     X_eeg: (21538, 256, 58) (N, time, channels)\n     X_bp: (21538, 290) (N, features)\n     X_task: (21538,)\n     Labels: (21538,) each\n   Saved: training_config.json\n   Saved: TRAINING_SUMMARY.md\n\n All results saved!\n\n Saved files:\n   /kaggle/working/results/\n   ‚îú‚îÄ‚îÄ training_history.json\n   ‚îú‚îÄ‚îÄ training_config.json\n   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\n\n   /kaggle/working/checkpoints/\n   ‚îú‚îÄ‚îÄ best_model.keras\n   ‚îú‚îÄ‚îÄ final_model.keras\n   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"11: Package & Download All Outputs","metadata":{}},{"cell_type":"code","source":"\n# ============================================================\n# Section 11: Package & Download All Outputs\n# ============================================================\n\nimport zipfile\nfrom pathlib import Path\n\nprint(\"\\n Creating download package...\")\nprint(\"=\" * 70)\n\n# Create zip filename with timestamp\ntimestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\nzip_filename = f\"cognivue_training_outputs_{timestamp}.zip\"\nzip_path = os.path.join(WORKING_DIR, zip_filename)\n\ntry:\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        \n        # Add all files from results directory\n        print(\"\\n Adding results...\")\n        if os.path.exists(RESULTS_DIR):\n            for file in os.listdir(RESULTS_DIR):\n                file_path = os.path.join(RESULTS_DIR, file)\n                if os.path.isfile(file_path):\n                    arcname = os.path.join('results', file)\n                    zipf.write(file_path, arcname)\n                    print(f\"   {file}\")\n        \n        # Add all checkpoint files\n        print(\"\\nüîñ Adding checkpoints...\")\n        if os.path.exists(CHECKPOINT_DIR):\n            for file in os.listdir(CHECKPOINT_DIR):\n                file_path = os.path.join(CHECKPOINT_DIR, file)\n                if os.path.isfile(file_path):\n                    arcname = os.path.join('checkpoints', file)\n                    zipf.write(file_path, arcname)\n                    file_size_mb = os.path.getsize(file_path) / (1024 * 1024)\n                    print(f\"   {file} ({file_size_mb:.1f} MB)\")\n        \n        # Add TensorBoard logs (optional - can be large)\n        print(\"\\n Adding TensorBoard logs...\")\n        if os.path.exists(LOGS_DIR):\n            log_count = 0\n            for root, dirs, files in os.walk(LOGS_DIR):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    arcname = os.path.join('logs', os.path.relpath(file_path, LOGS_DIR))\n                    zipf.write(file_path, arcname)\n                    log_count += 1\n            print(f\"   Added {log_count} log files\")\n    \n    # Get final zip size\n    zip_size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\" PACKAGE CREATED SUCCESSFULLY!\")\n    print(\"=\" * 70)\n    print(f\"\\n Zip file: {zip_filename}\")\n    print(f\" Size: {zip_size_mb:.1f} MB\")\n    print(f\" Location: {zip_path}\")\n    \n    print(\"\\n To download:\")\n    print(\"   1. Go to the 'Output' tab (top right)\")\n    print(\"   2. Click 'Save Version' to commit outputs\")\n    print(f\"   3. Download '{zip_filename}'\")\n    print(\"\\n Or click the download icon next to the file in the Output tab\")\n    \n    # List contents\n    print(\"\\n Package contents:\")\n    with zipfile.ZipFile(zip_path, 'r') as zipf:\n        file_list = zipf.namelist()\n        print(f\"   Total files: {len(file_list)}\")\n        print(\"\\n   Structure:\")\n        print(\"   ‚îú‚îÄ‚îÄ results/\")\n        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ training_history.json\")\n        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ training_config.json\")\n        print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\")\n        print(\"   ‚îú‚îÄ‚îÄ checkpoints/\")\n        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ best_model.keras\")\n        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ final_model.keras\")\n        print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\")\n        print(\"   ‚îî‚îÄ‚îÄ logs/\")\n        print(\"       ‚îî‚îÄ‚îÄ TensorBoard logs\")\n    \n    print(\"\\n\" + \"=\" * 70)\n    \nexcept Exception as e:\n    print(f\"\\n‚ùå Error creating zip: {e}\")\n    import traceback\n    traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T21:42:30.031059Z","iopub.execute_input":"2025-12-29T21:42:30.031304Z","iopub.status.idle":"2025-12-29T21:43:17.487876Z","shell.execute_reply.started":"2025-12-29T21:42:30.031283Z","shell.execute_reply":"2025-12-29T21:43:17.487285Z"}},"outputs":[{"name":"stdout","text":"\n Creating download package...\n======================================================================\n\n Adding results...\n   training_history.json\n   TRAINING_SUMMARY.md\n   training_config.json\n\nüîñ Adding checkpoints...\n   checkpoint_epoch_012.keras (57.1 MB)\n   final_model.keras (57.1 MB)\n   checkpoint_epoch_020.keras (57.1 MB)\n   checkpoint_epoch_010.keras (57.1 MB)\n   checkpoint_epoch_014.keras (57.1 MB)\n   checkpoint_epoch_026.keras (57.1 MB)\n   checkpoint_epoch_002.keras (57.1 MB)\n   checkpoint_epoch_016.keras (57.1 MB)\n   checkpoint_epoch_008.keras (57.1 MB)\n   checkpoint_epoch_006.keras (57.1 MB)\n   checkpoint_epoch_024.keras (57.1 MB)\n   checkpoint_epoch_028.keras (57.1 MB)\n   best_model.keras (57.1 MB)\n   checkpoint_epoch_022.keras (57.1 MB)\n   checkpoint_epoch_018.keras (57.1 MB)\n   checkpoint_epoch_004.keras (57.1 MB)\n\n Adding TensorBoard logs...\n   Added 2 log files\n\n======================================================================\n PACKAGE CREATED SUCCESSFULLY!\n======================================================================\n\n Zip file: cognivue_training_outputs_20251229_214230.zip\n Size: 819.2 MB\n Location: /kaggle/working/cognivue_training_outputs_20251229_214230.zip\n\n To download:\n   1. Go to the 'Output' tab (top right)\n   2. Click 'Save Version' to commit outputs\n   3. Download 'cognivue_training_outputs_20251229_214230.zip'\n\n Or click the download icon next to the file in the Output tab\n\n Package contents:\n   Total files: 21\n\n   Structure:\n   ‚îú‚îÄ‚îÄ results/\n   ‚îÇ   ‚îú‚îÄ‚îÄ training_history.json\n   ‚îÇ   ‚îú‚îÄ‚îÄ training_config.json\n   ‚îÇ   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\n   ‚îú‚îÄ‚îÄ checkpoints/\n   ‚îÇ   ‚îú‚îÄ‚îÄ best_model.keras\n   ‚îÇ   ‚îú‚îÄ‚îÄ final_model.keras\n   ‚îÇ   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\n   ‚îî‚îÄ‚îÄ logs/\n       ‚îî‚îÄ‚îÄ TensorBoard logs\n\n======================================================================\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import os\nprint(os.listdir('/kaggle/working/'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T21:43:17.488930Z","iopub.execute_input":"2025-12-29T21:43:17.489310Z","iopub.status.idle":"2025-12-29T21:43:17.493215Z","shell.execute_reply.started":"2025-12-29T21:43:17.489282Z","shell.execute_reply":"2025-12-29T21:43:17.492659Z"}},"outputs":[{"name":"stdout","text":"['results', 'checkpoints', 'cognivue_training_outputs_20251229_214230.zip', 'logs', '.virtual_documents']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import os\nimport glob\nfrom IPython.display import FileLink, display\n\n# 1. Search for any zip files starting with 'cognivue_training_outputs'\nzip_files = glob.glob('/kaggle/working/cognivue_training_outputs_*.zip')\n\nif zip_files:\n    # 2. Sort by newest (incase there are multiple)\n    latest_zip = max(zip_files, key=os.path.getctime)\n    relative_path = os.path.basename(latest_zip)\n    \n    print(\"=\" * 50)\n    print(f\"‚úÖ LATEST PACKAGE FOUND: {relative_path}\")\n    print(\"Click the link below to download your results:\")\n    print(\"=\" * 50)\n    \n    # 3. Display the dynamic link\n    display(FileLink(relative_path))\nelse:\n    print(\"‚ùå No output zip files found in /kaggle/working/\")\n    print(\"Current directory contents:\", os.listdir('/kaggle/working/'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T21:43:17.493980Z","iopub.execute_input":"2025-12-29T21:43:17.494212Z","iopub.status.idle":"2025-12-29T21:43:17.520798Z","shell.execute_reply.started":"2025-12-29T21:43:17.494192Z","shell.execute_reply":"2025-12-29T21:43:17.520130Z"}},"outputs":[{"name":"stdout","text":"==================================================\n‚úÖ LATEST PACKAGE FOUND: cognivue_training_outputs_20251229_214230.zip\nClick the link below to download your results:\n==================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/cognivue_training_outputs_20251229_214230.zip","text/html":"<a href='cognivue_training_outputs_20251229_214230.zip' target='_blank'>cognivue_training_outputs_20251229_214230.zip</a><br>"},"metadata":{}}],"execution_count":13}]}