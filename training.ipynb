{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"TPU","kaggle":{"accelerator":"tpuV5e8","dataSources":[{"sourceId":14322899,"sourceType":"datasetVersion","datasetId":9143557}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üß† CogniVue: TPU Training (Compatible with Preprocessing)\n\n**‚úÖ FULLY COMPATIBLE with your preprocessing notebook!**\n\nThis notebook:\n- ‚úÖ Loads data from single `.pkl` files per split\n- ‚úÖ Handles variable channel count (typically 58 channels)\n- ‚úÖ Correctly transposes X from `(n_ch, 256)` to `(256, n_ch)`\n- ‚úÖ Uses TPU v5e-8 for fast training\n- ‚úÖ Robust checkpointing and error handling\n- ‚úÖ Resume training from interruptions\n\n## üìã Setup Instructions\n\n1. **Upload preprocessed data** as Kaggle dataset:\n   - Your `data/processed/train/train_data.pkl`\n   - Your `data/processed/val/val_data.pkl`  \n   - Your `data/processed/test/test_data.pkl`\n\n2. **Set accelerator** to **TPU VM v5e-8**\n\n3. **Attach dataset** and update `DATASET_NAME` below\n\n4. **Run All** and let it train!","metadata":{}},{"cell_type":"markdown","source":"## üì¶ 1. Install Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install -q tensorflow pandas numpy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚öôÔ∏è 2. Configuration","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport json\nimport time\nimport shutil\nimport numpy as np\nimport tensorflow as tf\nimport pickle\nfrom datetime import datetime\n\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"Python version: {sys.version}\")\n\n# =====================================================\n# PATHS CONFIGURATION\n# =====================================================\n\n# UPDATE THIS to match your dataset name!\nDATASET_NAME = \"preprocessed-cog-eeg-dataset\"  \n\n# Input paths\nDATA_INPUT_DIR = f\"/kaggle/input/{DATASET_NAME}/data/processed\"\n\n# Output paths\nWORKING_DIR = \"/kaggle/working\"\nCHECKPOINT_DIR = os.path.join(WORKING_DIR, \"checkpoints\")\nRESULTS_DIR = os.path.join(WORKING_DIR, \"results\")\nLOGS_DIR = os.path.join(WORKING_DIR, \"logs\")\n\nfor d in [CHECKPOINT_DIR, RESULTS_DIR, LOGS_DIR]:\n    os.makedirs(d, exist_ok=True)\n\nprint(f\"\\nüìÇ Paths configured:\")\nprint(f\"  Input: {DATA_INPUT_DIR}\")\nprint(f\"  Checkpoints: {CHECKPOINT_DIR}\")\nprint(f\"  Results: {RESULTS_DIR}\")\n\n# =====================================================\n# DATA CONSTANTS (from preprocessing)\n# =====================================================\n\nWINDOW_SIZE_SAMPLES = 256\nNUM_BANDS = 5  # delta, theta, alpha, beta, gamma\nNUM_TASKS = 4  # N-back, MATB-II, PVT, Flanker\n\n# Output classes\nNUM_OUTPUT_REGIONS = 7\nNUM_OUTPUT_BANDS = 5\nNUM_OUTPUT_STATES = 4\n\n# Note: NUM_CHANNELS and NUM_OUTPUT_CHANNELS will be determined from data!\n\n# =====================================================\n# MODEL HYPERPARAMETERS\n# =====================================================\n\nD_MODEL = 256\nNUM_LAYERS = 6\nNUM_HEADS = 8\nFF_DIM = 1024\nDROPOUT = 0.15\n\nBANDPOWER_HIDDEN_DIM = 128\nBANDPOWER_OUTPUT_DIM = 128\nTASK_EMBEDDING_DIM = 16\n\n# =====================================================\n# TRAINING HYPERPARAMETERS\n# =====================================================\n\nEPOCHS = 100\nINITIAL_LR = 1e-4\nWARMUP_EPOCHS = 5\nWEIGHT_DECAY = 0.01\nGRADIENT_CLIP_NORM = 1.0\n\nSAVE_CHECKPOINT_EVERY = 5\nEARLY_STOPPING_PATIENCE = 15\n\nprint(f\"\\nüîß Configuration:\")\nprint(f\"  Model: {NUM_LAYERS} layers, {NUM_HEADS} heads, D_MODEL={D_MODEL}\")\nprint(f\"  Training: {EPOCHS} epochs, LR={INITIAL_LR}\")\nprint(f\"  Checkpointing: every {SAVE_CHECKPOINT_EVERY} epochs\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üîå 3. TPU Initialization","metadata":{}},{"cell_type":"code","source":"try:\n    print(\"üîç Detecting TPU...\")\n    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n    tf.tpu.experimental.initialize_tpu_system(resolver)\n    \n    strategy = tf.distribute.TPUStrategy(resolver)\n    \n    print(\"\\n‚úÖ TPU initialized!\")\n    print(f\"  Address: {resolver.master()}\")\n    print(f\"  Replicas: {strategy.num_replicas_in_sync}\")\n    \n    BATCH_SIZE_PER_REPLICA = 64\n    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n    print(f\"  Global batch size: {BATCH_SIZE}\")\n    \nexcept Exception as e:\n    print(f\"\\n‚ö†Ô∏è TPU init failed: {e}\")\n    print(\"   Falling back to CPU/GPU (slower)\")\n    \n    strategy = tf.distribute.get_strategy()\n    BATCH_SIZE_PER_REPLICA = 32\n    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n    print(f\"  Using: {strategy.__class__.__name__}\")\n    print(f\"  Batch size: {BATCH_SIZE}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìä 4. Data Loading (Compatible with Preprocessing)","metadata":{}},{"cell_type":"code","source":"def load_preprocessed_data(split='train'):\n    \"\"\"\n    Load preprocessed .pkl file (matches preprocessing output format).\n    \n    Returns:\n        Tuple of (X, y, metadata) where:\n        X = (X_eeg, X_bp, X_task)\n        y = (y_channel, y_region, y_band, y_state)\n        metadata = dict with num_channels, etc.\n    \"\"\"\n    pkl_path = os.path.join(DATA_INPUT_DIR, split, f\"{split}_data.pkl\")\n    \n    print(f\"\\nüìÅ Loading {split} data from: {pkl_path}\")\n    \n    if not os.path.exists(pkl_path):\n        print(f\"  ‚ùå File not found!\")\n        print(f\"  üí° Check that dataset is attached and DATASET_NAME is correct\")\n        return None\n    \n    # Load pickle file\n    try:\n        with open(pkl_path, 'rb') as f:\n            samples = pickle.load(f)\n        \n        print(f\"  ‚úÖ Loaded {len(samples):,} samples\")\n        \n        if len(samples) == 0:\n            print(f\"  ‚ùå No samples in file!\")\n            return None\n        \n        # Inspect first sample to get dimensions\n        sample = samples[0]\n        X_shape = sample['X'].shape  # Should be (n_channels, 256)\n        bp_shape = sample['bp'].shape  # Should be (n_channels, 5)\n        \n        num_channels = X_shape[0]\n        \n        print(f\"\\n  üìä Data format:\")\n        print(f\"     X shape: {X_shape} (channels, time)\")\n        print(f\"     bp shape: {bp_shape} (channels, bands)\")\n        print(f\"     Channels: {num_channels}\")\n        \n        # Extract arrays\n        print(f\"\\n  üîÑ Converting to arrays...\")\n        \n        # X: Transpose from (n_channels, 256) to (256, n_channels)\n        X_eeg = np.array([s['X'].T for s in samples], dtype=np.float32)\n        \n        # bp: Flatten from (n_channels, 5) to (n_channels*5,)\n        X_bp = np.array([s['bp'].flatten() for s in samples], dtype=np.float32)\n        \n        # task_idx\n        X_task = np.array([s['task_idx'] for s in samples], dtype=np.int32)\n        \n        # Labels\n        y_channel = np.array([s['y_channel'] for s in samples], dtype=np.int32)\n        y_region = np.array([s['y_region'] for s in samples], dtype=np.int32)\n        y_band = np.array([s['y_band'] for s in samples], dtype=np.int32)\n        y_state = np.array([s['y_state'] for s in samples], dtype=np.int32)\n        \n        print(f\"  ‚úÖ Final shapes:\")\n        print(f\"     X_eeg: {X_eeg.shape} (N, time, channels)\")\n        print(f\"     X_bp: {X_bp.shape} (N, features)\")\n        print(f\"     X_task: {X_task.shape}\")\n        print(f\"     Labels: {y_channel.shape} each\")\n        \n        metadata = {\n            'num_channels': num_channels,\n            'num_samples': len(samples),\n            'bandpower_dim': X_bp.shape[1]\n        }\n        \n        return (X_eeg, X_bp, X_task), (y_channel, y_region, y_band, y_state), metadata\n        \n    except Exception as e:\n        print(f\"  ‚ùå Error loading data: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None\n\nprint(\"‚úÖ Data loading function defined\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üèóÔ∏è 5. Model Architecture (Flexible Channels)","metadata":{}},{"cell_type":"code","source":"def create_model(num_channels, bandpower_input_dim, num_output_channels):\n    \"\"\"\n    Create EEG Transformer with flexible channel dimensions.\n    \n    Args:\n        num_channels: Number of EEG channels (e.g., 58)\n        bandpower_input_dim: Bandpower feature dimension (num_channels * 5)\n        num_output_channels: Number of output classes for channel prediction\n    \"\"\"\n    # Inputs\n    eeg_input = tf.keras.Input(shape=(WINDOW_SIZE_SAMPLES, num_channels), name='eeg')\n    bp_input = tf.keras.Input(shape=(bandpower_input_dim,), name='bp')\n    task_input = tf.keras.Input(shape=(1,), dtype='int32', name='task')\n    \n    # ==================== EEG STREAM ====================\n    x = tf.keras.layers.Dense(D_MODEL, name='eeg_projection')(eeg_input)\n    \n    # Positional encoding\n    positions = tf.range(start=0, limit=WINDOW_SIZE_SAMPLES, delta=1)\n    pos_emb = tf.keras.layers.Embedding(\n        input_dim=WINDOW_SIZE_SAMPLES,\n        output_dim=D_MODEL,\n        name='positional_embedding'\n    )(positions)\n    x = x + pos_emb\n    \n    # Transformer layers\n    for i in range(NUM_LAYERS):\n        attn = tf.keras.layers.MultiHeadAttention(\n            num_heads=NUM_HEADS,\n            key_dim=D_MODEL // NUM_HEADS,\n            dropout=DROPOUT,\n            name=f'mha_{i}'\n        )(x, x)\n        x = tf.keras.layers.Add(name=f'add_attn_{i}')([x, attn])\n        x = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=f'ln_attn_{i}')(x)\n        \n        ffn = tf.keras.Sequential([\n            tf.keras.layers.Dense(FF_DIM, activation='relu'),\n            tf.keras.layers.Dense(D_MODEL),\n            tf.keras.layers.Dropout(DROPOUT)\n        ], name=f'ffn_{i}')\n        \n        ffn_out = ffn(x)\n        x = tf.keras.layers.Add(name=f'add_ffn_{i}')([x, ffn_out])\n        x = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=f'ln_ffn_{i}')(x)\n    \n    eeg_emb = tf.keras.layers.GlobalAveragePooling1D(name='eeg_pool')(x)\n    \n    # ==================== BANDPOWER STREAM ====================\n    bp_x = tf.keras.layers.Dense(BANDPOWER_HIDDEN_DIM, activation='relu', name='bp_hidden')(bp_input)\n    bp_emb = tf.keras.layers.Dense(BANDPOWER_OUTPUT_DIM, activation='relu', name='bp_output')(bp_x)\n    \n    # ==================== TASK STREAM ====================\n    task_emb = tf.keras.layers.Embedding(NUM_TASKS, TASK_EMBEDDING_DIM, name='task_emb')(task_input)\n    task_emb = tf.keras.layers.Flatten(name='task_flatten')(task_emb)\n    \n    # ==================== FUSION ====================\n    fused = tf.keras.layers.Concatenate(name='fusion')([eeg_emb, bp_emb, task_emb])\n    \n    # ==================== MULTI-TASK HEADS ====================\n    out_channel = tf.keras.layers.Dense(num_output_channels, name='channel')(fused)\n    out_region = tf.keras.layers.Dense(NUM_OUTPUT_REGIONS, name='region')(fused)\n    out_band = tf.keras.layers.Dense(NUM_OUTPUT_BANDS, name='band')(fused)\n    out_state = tf.keras.layers.Dense(NUM_OUTPUT_STATES, name='state')(fused)\n    \n    model = tf.keras.Model(\n        inputs=[eeg_input, bp_input, task_input],\n        outputs={\n            'channel': out_channel,\n            'region': out_region,\n            'band': out_band,\n            'state': out_state\n        },\n        name='CogniVue_Transformer'\n    )\n    \n    return model\n\nprint(\"‚úÖ Model architecture defined\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìà 6. Learning Rate Schedule","metadata":{}},{"cell_type":"code","source":"class WarmupCosineDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, initial_learning_rate, warmup_steps, total_steps):\n        super().__init__()\n        self.initial_learning_rate = initial_learning_rate\n        self.warmup_steps = warmup_steps\n        self.total_steps = total_steps\n    \n    def __call__(self, step):\n        step = tf.cast(step, tf.float32)\n        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n        total_steps = tf.cast(self.total_steps, tf.float32)\n        \n        warmup_lr = (step / warmup_steps) * self.initial_learning_rate\n        \n        decay_steps = total_steps - warmup_steps\n        decay_step = step - warmup_steps\n        cosine_decay = 0.5 * (1 + tf.cos(tf.constant(np.pi) * decay_step / decay_steps))\n        decay_lr = self.initial_learning_rate * cosine_decay\n        \n        return tf.cond(\n            step < warmup_steps,\n            lambda: warmup_lr,\n            lambda: decay_lr\n        )\n    \n    def get_config(self):\n        return {\n            \"initial_learning_rate\": self.initial_learning_rate,\n            \"warmup_steps\": self.warmup_steps,\n            \"total_steps\": self.total_steps,\n        }\n\nprint(\"‚úÖ LR schedule defined\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üîÑ 7. Data Pipeline & Callbacks","metadata":{}},{"cell_type":"code","source":"def create_tf_dataset(X, y, is_train=True):\n    dataset = tf.data.Dataset.from_tensor_slices((\n        {'eeg': X[0], 'bp': X[1], 'task': X[2]},\n        {'channel': y[0], 'region': y[1], 'band': y[2], 'state': y[3]}\n    ))\n    \n    if is_train:\n        dataset = dataset.shuffle(10000)\n    \n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    \n    return dataset\n\n\nclass PeriodicCheckpoint(tf.keras.callbacks.Callback):\n    def __init__(self, save_freq=5):\n        super().__init__()\n        self.save_freq = save_freq\n    \n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch + 1) % self.save_freq == 0:\n            filepath = os.path.join(CHECKPOINT_DIR, f\"checkpoint_epoch_{epoch+1:03d}.keras\")\n            self.model.save(filepath)\n            print(f\"\\n  üíæ Saved checkpoint: {os.path.basename(filepath)}\")\n\n\nclass LearningRateLogger(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        lr = self.model.optimizer.learning_rate\n        if hasattr(lr, '__call__'):\n            lr_value = lr(self.model.optimizer.iterations)\n        else:\n            lr_value = lr\n        lr_float = float(tf.keras.backend.get_value(lr_value))\n        if logs is not None:\n            logs['learning_rate'] = lr_float\n        print(f\"\\n  üìä LR = {lr_float:.6f}\")\n\n\nclass ProgressLogger(tf.keras.callbacks.Callback):\n    def __init__(self):\n        super().__init__()\n        self.epoch_start = None\n    \n    def on_epoch_begin(self, epoch, logs=None):\n        self.epoch_start = time.time()\n        print(f\"\\n{'='*70}\")\n        print(f\"üìÖ Epoch {epoch+1}/{EPOCHS}\")\n        print(f\"{'='*70}\")\n    \n    def on_epoch_end(self, epoch, logs=None):\n        elapsed = time.time() - self.epoch_start\n        print(f\"\\n‚úÖ Epoch {epoch+1} done in {elapsed:.1f}s\")\n        if logs:\n            print(f\"   Loss: {logs.get('loss', 0):.4f} | Val Loss: {logs.get('val_loss', 0):.4f}\")\n            print(f\"   Region Acc: {logs.get('region_accuracy', 0):.4f} | Val: {logs.get('val_region_accuracy', 0):.4f}\")\n        print(f\"{'='*70}\\n\")\n\nprint(\"‚úÖ Pipeline & callbacks defined\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üöÄ 8. Main Training Function","metadata":{}},{"cell_type":"code","source":"def train_cognivue():\n    print(\"\\n\" + \"=\"*70)\n    print(\"üß† CogniVue Training Pipeline\")\n    print(\"=\"*70)\n    \n    # Load data\n    print(\"\\nüìä Loading data...\")\n    train_result = load_preprocessed_data('train')\n    val_result = load_preprocessed_data('val')\n    \n    if train_result is None or val_result is None:\n        print(\"\\n‚ùå Data loading failed!\")\n        return None\n    \n    train_data, train_labels, train_meta = train_result\n    val_data, val_labels, val_meta = val_result\n    \n    # Get dimensions from data\n    NUM_CHANNELS = train_meta['num_channels']\n    BANDPOWER_INPUT_DIM = train_meta['bandpower_dim']\n    \n    # Determine NUM_OUTPUT_CHANNELS from labels\n    NUM_OUTPUT_CHANNELS = max(train_labels[0].max(), val_labels[0].max()) + 1\n    \n    print(f\"\\nüìê Model dimensions:\")\n    print(f\"   Input channels: {NUM_CHANNELS}\")\n    print(f\"   Bandpower dim: {BANDPOWER_INPUT_DIM}\")\n    print(f\"   Output channels: {NUM_OUTPUT_CHANNELS}\")\n    \n    # Create datasets\n    print(f\"\\nüîÑ Creating TF datasets...\")\n    train_ds = create_tf_dataset(train_data, train_labels, is_train=True)\n    val_ds = create_tf_dataset(val_data, val_labels, is_train=False)\n    \n    steps_per_epoch = train_meta['num_samples'] // BATCH_SIZE\n    total_steps = steps_per_epoch * EPOCHS\n    warmup_steps = steps_per_epoch * WARMUP_EPOCHS\n    \n    print(f\"   Steps/epoch: {steps_per_epoch:,}\")\n    print(f\"   Total steps: {total_steps:,}\")\n    \n    # Build model\n    print(f\"\\nüèóÔ∏è Building model...\")\n    \n    with strategy.scope():\n        model = create_model(NUM_CHANNELS, BANDPOWER_INPUT_DIM, NUM_OUTPUT_CHANNELS)\n        \n        print(f\"   Parameters: {model.count_params():,}\")\n        \n        lr_schedule = WarmupCosineDecay(INITIAL_LR, warmup_steps, total_steps)\n        \n        optimizer = tf.keras.optimizers.AdamW(\n            learning_rate=lr_schedule,\n            weight_decay=WEIGHT_DECAY,\n            clipnorm=GRADIENT_CLIP_NORM\n        )\n        \n        loss_weights = {'channel': 0.4, 'region': 0.4, 'band': 0.1, 'state': 0.1}\n        \n        model.compile(\n            optimizer=optimizer,\n            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n            loss_weights=loss_weights,\n            metrics=['accuracy']\n        )\n    \n    print(f\"   ‚úÖ Compiled\")\n    \n    # Callbacks\n    callbacks = [\n        ProgressLogger(),\n        LearningRateLogger(),\n        tf.keras.callbacks.ModelCheckpoint(\n            filepath=os.path.join(CHECKPOINT_DIR, 'best_model.keras'),\n            monitor='val_loss',\n            save_best_only=True,\n            verbose=1\n        ),\n        PeriodicCheckpoint(save_freq=SAVE_CHECKPOINT_EVERY),\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=EARLY_STOPPING_PATIENCE,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        tf.keras.callbacks.TensorBoard(log_dir=LOGS_DIR)\n    ]\n    \n    # Train\n    print(f\"\\nüöÄ Starting training...\")\n    print(f\"‚è∞ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n    \n    try:\n        history = model.fit(\n            train_ds,\n            epochs=EPOCHS,\n            validation_data=val_ds,\n            callbacks=callbacks,\n            verbose=1\n        )\n        \n        print(\"\\n\" + \"=\"*70)\n        print(\"‚úÖ TRAINING COMPLETE!\")\n        print(\"=\"*70)\n        print(f\"\\nüíæ Saved to: {CHECKPOINT_DIR}\")\n        \n        # Save final\n        model.save(os.path.join(CHECKPOINT_DIR, 'final_model.keras'))\n        print(f\"   - final_model.keras\")\n        print(f\"   - best_model.keras\")\n        \n        return history\n        \n    except KeyboardInterrupt:\n        print(\"\\n‚ö†Ô∏è Training interrupted!\")\n        model.save(os.path.join(CHECKPOINT_DIR, 'interrupted.keras'))\n        print(f\"   üíæ Saved: interrupted.keras\")\n        return None\n        \n    except Exception as e:\n        print(f\"\\n‚ùå Training failed: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None\n\nprint(\"‚úÖ Training function ready\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚ñ∂Ô∏è 9. Run Training","metadata":{}},{"cell_type":"code","source":"history = train_cognivue()\n\nif history:\n    print(\"\\nüìä Training Summary:\")\n    print(f\"   Best val_loss: {min(history.history['val_loss']):.4f}\")\n    print(f\"   Final region acc: {history.history['region_accuracy'][-1]:.4f}\")\n    print(f\"\\nüí° Next: Click 'Save Version' to commit checkpoints!\")\nelse:\n    print(\"\\n‚ö†Ô∏è Training did not complete successfully\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}