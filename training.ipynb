{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633779b3",
   "metadata": {
    "papermill": {
     "duration": 0.004525,
     "end_time": "2025-12-29T22:10:22.315115",
     "exception": false,
     "start_time": "2025-12-29T22:10:22.310590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  CogniVue: Training\n",
    "\n",
    "** FULLY COMPATIBLE with your preprocessing notebook!**\n",
    "\n",
    "This notebook:\n",
    "-  Loads data from single `.pkl` files per split\n",
    "-  Handles variable channel count (typically 58 channels)\n",
    "-  Correctly transposes X from `(n_ch, 256)` to `(256, n_ch)`\n",
    "-  Robust checkpointing and error handling\n",
    "-  Resume training from interruptions\n",
    "-  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314c73c8",
   "metadata": {
    "papermill": {
     "duration": 0.003303,
     "end_time": "2025-12-29T22:10:22.322210",
     "exception": false,
     "start_time": "2025-12-29T22:10:22.318907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  1. Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44945a54",
   "metadata": {
    "papermill": {
     "duration": 0.003488,
     "end_time": "2025-12-29T22:10:22.330362",
     "exception": false,
     "start_time": "2025-12-29T22:10:22.326874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87a12f5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T22:10:22.338529Z",
     "iopub.status.busy": "2025-12-29T22:10:22.338260Z",
     "iopub.status.idle": "2025-12-29T22:10:48.941762Z",
     "shell.execute_reply": "2025-12-29T22:10:48.940863Z"
    },
    "papermill": {
     "duration": 26.609625,
     "end_time": "2025-12-29T22:10:48.943339",
     "exception": false,
     "start_time": "2025-12-29T22:10:22.333714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 22:10:26.533711: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767046227.105358      23 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767046227.237069      23 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767046228.516080      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767046228.516121      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767046228.516124      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767046228.516126      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "\n",
      " Paths configured:\n",
      "  Input: /kaggle/input/preprocessed-cog-eeg-dataset/processed\n",
      "  Checkpoints: /kaggle/working/checkpoints\n",
      "  Results: /kaggle/working/results\n",
      "\n",
      "üîß Configuration:\n",
      "  Model: 6 layers, 8 heads, D_MODEL=256\n",
      "  Training: 100 epochs, LR=0.0001\n",
      "  Checkpointing: every 2 epochs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# =====================================================\n",
    "# PATHS CONFIGURATION\n",
    "# =====================================================\n",
    "\n",
    "# UPDATE THIS to match your dataset name!\n",
    "DATASET_NAME = \"preprocessed-cog-eeg-dataset\"  \n",
    "\n",
    "# Input paths\n",
    "DATA_INPUT_DIR = f\"/kaggle/input/{DATASET_NAME}/processed\"\n",
    "\n",
    "# Output paths\n",
    "WORKING_DIR = \"/kaggle/working\"\n",
    "CHECKPOINT_DIR = os.path.join(WORKING_DIR, \"checkpoints\")\n",
    "RESULTS_DIR = os.path.join(WORKING_DIR, \"results\")\n",
    "LOGS_DIR = os.path.join(WORKING_DIR, \"logs\")\n",
    "\n",
    "for d in [CHECKPOINT_DIR, RESULTS_DIR, LOGS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(f\"\\n Paths configured:\")\n",
    "print(f\"  Input: {DATA_INPUT_DIR}\")\n",
    "print(f\"  Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"  Results: {RESULTS_DIR}\")\n",
    "\n",
    "# =====================================================\n",
    "# DATA CONSTANTS (from preprocessing)\n",
    "# =====================================================\n",
    "\n",
    "WINDOW_SIZE_SAMPLES = 256\n",
    "NUM_BANDS = 5  # delta, theta, alpha, beta, gamma\n",
    "NUM_TASKS = 4  # N-back, MATB-II, PVT, Flanker\n",
    "\n",
    "# Output classes\n",
    "NUM_OUTPUT_REGIONS = 7\n",
    "NUM_OUTPUT_BANDS = 5\n",
    "NUM_OUTPUT_STATES = 4\n",
    "\n",
    "# Note: NUM_CHANNELS and NUM_OUTPUT_CHANNELS will be determined from data!\n",
    "\n",
    "# =====================================================\n",
    "# MODEL HYPERPARAMETERS\n",
    "# =====================================================\n",
    "\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 6\n",
    "NUM_HEADS = 8\n",
    "FF_DIM = 1024\n",
    "DROPOUT = 0.15\n",
    "\n",
    "BANDPOWER_HIDDEN_DIM = 128\n",
    "BANDPOWER_OUTPUT_DIM = 128\n",
    "TASK_EMBEDDING_DIM = 16\n",
    "\n",
    "# =====================================================\n",
    "# TRAINING HYPERPARAMETERS\n",
    "# =====================================================\n",
    "\n",
    "EPOCHS = 100\n",
    "INITIAL_LR = 1e-4\n",
    "WARMUP_EPOCHS = 10\n",
    "WEIGHT_DECAY = 0.01\n",
    "GRADIENT_CLIP_NORM = 1.0\n",
    "\n",
    "SAVE_CHECKPOINT_EVERY = 2\n",
    "EARLY_STOPPING_PATIENCE = 15\n",
    "\n",
    "print(f\"\\nüîß Configuration:\")\n",
    "print(f\"  Model: {NUM_LAYERS} layers, {NUM_HEADS} heads, D_MODEL={D_MODEL}\")\n",
    "print(f\"  Training: {EPOCHS} epochs, LR={INITIAL_LR}\")\n",
    "print(f\"  Checkpointing: every {SAVE_CHECKPOINT_EVERY} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23541b2",
   "metadata": {
    "papermill": {
     "duration": 0.003529,
     "end_time": "2025-12-29T22:10:48.950799",
     "exception": false,
     "start_time": "2025-12-29T22:10:48.947270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  3. TPU Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9191e91b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T22:10:48.959511Z",
     "iopub.status.busy": "2025-12-29T22:10:48.959028Z",
     "iopub.status.idle": "2025-12-29T22:10:50.721493Z",
     "shell.execute_reply": "2025-12-29T22:10:50.720584Z"
    },
    "papermill": {
     "duration": 1.768889,
     "end_time": "2025-12-29T22:10:50.723200",
     "exception": false,
     "start_time": "2025-12-29T22:10:48.954311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ GPU T4 x2 INITIALIZATION\n",
      "======================================================================\n",
      "\n",
      "TensorFlow version: 2.19.0\n",
      "\n",
      "üìä Creating GPU strategy...\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "‚úÖ Strategy: MirroredStrategy\n",
      "   GPUs detected: 2\n",
      "\n",
      "üéÆ GPU devices:\n",
      "   1. /physical_device:GPU:0\n",
      "   2. /physical_device:GPU:1\n",
      "\n",
      "üì¶ Batch Configuration:\n",
      "   Per-GPU batch: 32\n",
      "   Global batch: 64\n",
      "\n",
      "======================================================================\n",
      "‚úÖ GPU READY FOR TRAINING\n",
      "======================================================================\n",
      "\n",
      "üí° Next: Create model in strategy scope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1767046250.674142      23 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1767046250.678050      23 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üöÄ GPU T4 x2 INITIALIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nTensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Create GPU strategy\n",
    "print(\"\\nüìä Creating GPU strategy...\")\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "num_replicas = strategy.num_replicas_in_sync\n",
    "print(f\"‚úÖ Strategy: {strategy.__class__.__name__}\")\n",
    "print(f\"   GPUs detected: {num_replicas}\")\n",
    "\n",
    "# List GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"\\nüéÆ GPU devices:\")\n",
    "for i, gpu in enumerate(gpus):\n",
    "    print(f\"   {i+1}. {gpu.name}\")\n",
    "\n",
    "# Batch size configuration\n",
    "BATCH_SIZE_PER_REPLICA = 32  # Reduce to 16 if you get OOM errors\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * num_replicas\n",
    "\n",
    "print(f\"\\nüì¶ Batch Configuration:\")\n",
    "print(f\"   Per-GPU batch: {BATCH_SIZE_PER_REPLICA}\")\n",
    "print(f\"   Global batch: {BATCH_SIZE}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ GPU READY FOR TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Make variables global\n",
    "globals()['strategy'] = strategy\n",
    "globals()['BATCH_SIZE'] = BATCH_SIZE\n",
    "\n",
    "print(\"\\nüí° Next: Create model in strategy scope\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c32ccde3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T22:10:50.732219Z",
     "iopub.status.busy": "2025-12-29T22:10:50.731981Z",
     "iopub.status.idle": "2025-12-29T22:10:50.737398Z",
     "shell.execute_reply": "2025-12-29T22:10:50.736778Z"
    },
    "papermill": {
     "duration": 0.011707,
     "end_time": "2025-12-29T22:10:50.738962",
     "exception": false,
     "start_time": "2025-12-29T22:10:50.727255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Auto-save callback ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# AUTO-SAVE CALLBACK (Add this BEFORE training section)\n",
    "# ============================================================\n",
    "\n",
    "class AutoSaveCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Custom callback to create marker files for auto-committing\"\"\"\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Create a marker file every epoch\n",
    "        # Kaggle auto-commits when new files appear\n",
    "        marker_path = f\"/kaggle/working/progress_epoch_{epoch+1}.txt\"\n",
    "        with open(marker_path, 'w') as f:\n",
    "            f.write(f\"Completed epoch {epoch+1}/{EPOCHS}\\n\")\n",
    "            f.write(f\"Loss: {logs.get('loss', 0):.4f}\\n\")\n",
    "            f.write(f\"Val Loss: {logs.get('val_loss', 0):.4f}\\n\")\n",
    "            f.write(f\"Timestamp: {datetime.now()}\\n\")\n",
    "        \n",
    "        print(f\"   Progress saved: progress_epoch_{epoch+1}.txt\")\n",
    "\n",
    "print(\" Auto-save callback ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c8712d",
   "metadata": {
    "papermill": {
     "duration": 0.003698,
     "end_time": "2025-12-29T22:10:50.746467",
     "exception": false,
     "start_time": "2025-12-29T22:10:50.742769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  4. Data Loading (Compatible with Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bbf3153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T22:10:50.755503Z",
     "iopub.status.busy": "2025-12-29T22:10:50.755208Z",
     "iopub.status.idle": "2025-12-29T22:10:50.764857Z",
     "shell.execute_reply": "2025-12-29T22:10:50.764243Z"
    },
    "papermill": {
     "duration": 0.016009,
     "end_time": "2025-12-29T22:10:50.766407",
     "exception": false,
     "start_time": "2025-12-29T22:10:50.750398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data loading function defined\n"
     ]
    }
   ],
   "source": [
    "def load_preprocessed_data(split='train'):\n",
    "    \"\"\"\n",
    "    Load preprocessed .pkl file (matches preprocessing output format).\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (X, y, metadata) where:\n",
    "        X = (X_eeg, X_bp, X_task)\n",
    "        y = (y_channel, y_region, y_band, y_state)\n",
    "        metadata = dict with num_channels, etc.\n",
    "    \"\"\"\n",
    "    pkl_path = os.path.join(DATA_INPUT_DIR, split, f\"{split}_data.pkl\")\n",
    "    \n",
    "    print(f\"\\n Loading {split} data from: {pkl_path}\")\n",
    "    \n",
    "    if not os.path.exists(pkl_path):\n",
    "        print(f\"   File not found!\")\n",
    "        print(f\"   Check that dataset is attached and DATASET_NAME is correct\")\n",
    "        return None\n",
    "    \n",
    "    # Load pickle file\n",
    "    try:\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            samples = pickle.load(f)\n",
    "        \n",
    "        print(f\"   Loaded {len(samples):,} samples\")\n",
    "        \n",
    "        if len(samples) == 0:\n",
    "            print(f\"   No samples in file!\")\n",
    "            return None\n",
    "        \n",
    "        # Inspect first sample to get dimensions\n",
    "        sample = samples[0]\n",
    "        X_shape = sample['X'].shape  # Should be (n_channels, 256)\n",
    "        bp_shape = sample['bp'].shape  # Should be (n_channels, 5)\n",
    "        \n",
    "        num_channels = X_shape[0]\n",
    "        \n",
    "        print(f\"\\n  Data format:\")\n",
    "        print(f\"     X shape: {X_shape} (channels, time)\")\n",
    "        print(f\"     bp shape: {bp_shape} (channels, bands)\")\n",
    "        print(f\"     Channels: {num_channels}\")\n",
    "        \n",
    "        # Extract arrays\n",
    "        print(f\"\\n   Converting to arrays...\")\n",
    "        \n",
    "        # X: Transpose from (n_channels, 256) to (256, n_channels)\n",
    "        X_eeg = np.array([s['X'].T for s in samples], dtype=np.float32)\n",
    "        \n",
    "        # bp: Flatten from (n_channels, 5) to (n_channels*5,)\n",
    "        X_bp = np.array([s['bp'].flatten() for s in samples], dtype=np.float32)\n",
    "        \n",
    "        # task_idx\n",
    "        X_task = np.array([s['task_idx'] for s in samples], dtype=np.int32)\n",
    "        \n",
    "        # Labels\n",
    "        y_channel = np.array([s['y_channel'] for s in samples], dtype=np.int32)\n",
    "        y_region = np.array([s['y_region'] for s in samples], dtype=np.int32)\n",
    "        y_band = np.array([s['y_band'] for s in samples], dtype=np.int32)\n",
    "        y_state = np.array([s['y_state'] for s in samples], dtype=np.int32)\n",
    "        \n",
    "        print(f\"   Final shapes:\")\n",
    "        print(f\"     X_eeg: {X_eeg.shape} (N, time, channels)\")\n",
    "        print(f\"     X_bp: {X_bp.shape} (N, features)\")\n",
    "        print(f\"     X_task: {X_task.shape}\")\n",
    "        print(f\"     Labels: {y_channel.shape} each\")\n",
    "        \n",
    "        metadata = {\n",
    "            'num_channels': num_channels,\n",
    "            'num_samples': len(samples),\n",
    "            'bandpower_dim': X_bp.shape[1]\n",
    "        }\n",
    "        \n",
    "        return (X_eeg, X_bp, X_task), (y_channel, y_region, y_band, y_state), metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error loading data: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "print(\" Data loading function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33eb13c",
   "metadata": {
    "papermill": {
     "duration": 0.003613,
     "end_time": "2025-12-29T22:10:50.773766",
     "exception": false,
     "start_time": "2025-12-29T22:10:50.770153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  5. Model Architecture (Flexible Channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fce499e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T22:10:50.782501Z",
     "iopub.status.busy": "2025-12-29T22:10:50.782070Z",
     "iopub.status.idle": "2025-12-29T22:10:50.792491Z",
     "shell.execute_reply": "2025-12-29T22:10:50.791707Z"
    },
    "papermill": {
     "duration": 0.016408,
     "end_time": "2025-12-29T22:10:50.793886",
     "exception": false,
     "start_time": "2025-12-29T22:10:50.777478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model architecture defined\n"
     ]
    }
   ],
   "source": [
    "def create_model(num_channels, bandpower_input_dim, num_output_channels):\n",
    "    \"\"\"\n",
    "    Create EEG Transformer with flexible channel dimensions.\n",
    "    \n",
    "    Args:\n",
    "        num_channels: Number of EEG channels (e.g., 58)\n",
    "        bandpower_input_dim: Bandpower feature dimension (num_channels * 5)\n",
    "        num_output_channels: Number of output classes for channel prediction\n",
    "    \"\"\"\n",
    "    # Inputs\n",
    "    eeg_input = tf.keras.Input(shape=(WINDOW_SIZE_SAMPLES, num_channels), name='eeg')\n",
    "    bp_input = tf.keras.Input(shape=(bandpower_input_dim,), name='bp')\n",
    "    task_input = tf.keras.Input(shape=(1,), dtype='int32', name='task')\n",
    "    \n",
    "    # ==================== EEG STREAM ====================\n",
    "    x = tf.keras.layers.Dense(D_MODEL, name='eeg_projection')(eeg_input)\n",
    "    \n",
    "    # Positional encoding\n",
    "    positions = tf.range(start=0, limit=WINDOW_SIZE_SAMPLES, delta=1)\n",
    "    pos_emb = tf.keras.layers.Embedding(\n",
    "        input_dim=WINDOW_SIZE_SAMPLES,\n",
    "        output_dim=D_MODEL,\n",
    "        name='positional_embedding'\n",
    "    )(positions)\n",
    "    x = x + pos_emb\n",
    "    \n",
    "    # Transformer layers\n",
    "    for i in range(NUM_LAYERS):\n",
    "        attn = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=NUM_HEADS,\n",
    "            key_dim=D_MODEL // NUM_HEADS,\n",
    "            dropout=DROPOUT,\n",
    "            name=f'mha_{i}'\n",
    "        )(x, x)\n",
    "        x = tf.keras.layers.Add(name=f'add_attn_{i}')([x, attn])\n",
    "        x = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=f'ln_attn_{i}')(x)\n",
    "        \n",
    "        ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(FF_DIM, activation='relu'),\n",
    "            tf.keras.layers.Dense(D_MODEL),\n",
    "            tf.keras.layers.Dropout(DROPOUT)\n",
    "        ], name=f'ffn_{i}')\n",
    "        \n",
    "        ffn_out = ffn(x)\n",
    "        x = tf.keras.layers.Add(name=f'add_ffn_{i}')([x, ffn_out])\n",
    "        x = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=f'ln_ffn_{i}')(x)\n",
    "    \n",
    "    eeg_emb = tf.keras.layers.GlobalAveragePooling1D(name='eeg_pool')(x)\n",
    "    \n",
    "    # ==================== BANDPOWER STREAM ====================\n",
    "    bp_x = tf.keras.layers.Dense(BANDPOWER_HIDDEN_DIM, activation='relu', name='bp_hidden')(bp_input)\n",
    "    bp_emb = tf.keras.layers.Dense(BANDPOWER_OUTPUT_DIM, activation='relu', name='bp_output')(bp_x)\n",
    "    \n",
    "    # ==================== TASK STREAM ====================\n",
    "    task_emb = tf.keras.layers.Embedding(NUM_TASKS, TASK_EMBEDDING_DIM, name='task_emb')(task_input)\n",
    "    task_emb = tf.keras.layers.Flatten(name='task_flatten')(task_emb)\n",
    "    \n",
    "    # ==================== FUSION ====================\n",
    "    fused = tf.keras.layers.Concatenate(name='fusion')([eeg_emb, bp_emb, task_emb])\n",
    "    \n",
    "    # ==================== MULTI-TASK HEADS ====================\n",
    "    out_channel = tf.keras.layers.Dense(num_output_channels, name='channel')(fused)\n",
    "    out_region = tf.keras.layers.Dense(NUM_OUTPUT_REGIONS, name='region')(fused)\n",
    "    out_band = tf.keras.layers.Dense(NUM_OUTPUT_BANDS, name='band')(fused)\n",
    "    out_state = tf.keras.layers.Dense(NUM_OUTPUT_STATES, name='state')(fused)\n",
    "    \n",
    "    model = tf.keras.Model(\n",
    "        inputs=[eeg_input, bp_input, task_input],\n",
    "        outputs={\n",
    "            'channel': out_channel,\n",
    "            'region': out_region,\n",
    "            'band': out_band,\n",
    "            'state': out_state\n",
    "        },\n",
    "        name='CogniVue_Transformer'\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\" Model architecture defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c035f",
   "metadata": {
    "papermill": {
     "duration": 0.003781,
     "end_time": "2025-12-29T22:10:50.801496",
     "exception": false,
     "start_time": "2025-12-29T22:10:50.797715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  6. Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda54f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T22:10:50.810755Z",
     "iopub.status.busy": "2025-12-29T22:10:50.810531Z",
     "iopub.status.idle": "2025-12-29T22:10:50.816648Z",
     "shell.execute_reply": "2025-12-29T22:10:50.815985Z"
    },
    "papermill": {
     "duration": 0.012687,
     "end_time": "2025-12-29T22:10:50.817910",
     "exception": false,
     "start_time": "2025-12-29T22:10:50.805223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LR schedule defined\n"
     ]
    }
   ],
   "source": [
    "class WarmupCosineDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_learning_rate, warmup_steps, total_steps):\n",
    "        super().__init__()\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n",
    "        total_steps = tf.cast(self.total_steps, tf.float32)\n",
    "        \n",
    "        warmup_lr = (step / warmup_steps) * self.initial_learning_rate\n",
    "        \n",
    "        decay_steps = total_steps - warmup_steps\n",
    "        decay_step = step - warmup_steps\n",
    "        cosine_decay = 0.5 * (1 + tf.cos(tf.constant(np.pi) * decay_step / decay_steps))\n",
    "        decay_lr = self.initial_learning_rate * cosine_decay\n",
    "        \n",
    "        return tf.cond(\n",
    "            step < warmup_steps,\n",
    "            lambda: warmup_lr,\n",
    "            lambda: decay_lr\n",
    "        )\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"initial_learning_rate\": self.initial_learning_rate,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"total_steps\": self.total_steps,\n",
    "        }\n",
    "\n",
    "print(\" LR schedule defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5c1af",
   "metadata": {
    "papermill": {
     "duration": 0.003747,
     "end_time": "2025-12-29T22:10:50.825521",
     "exception": false,
     "start_time": "2025-12-29T22:10:50.821774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  7. Data Pipeline & Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da70e48f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T22:10:50.834479Z",
     "iopub.status.busy": "2025-12-29T22:10:50.834060Z",
     "iopub.status.idle": "2025-12-29T22:10:50.844996Z",
     "shell.execute_reply": "2025-12-29T22:10:50.844181Z"
    },
    "papermill": {
     "duration": 0.016985,
     "end_time": "2025-12-29T22:10:50.846441",
     "exception": false,
     "start_time": "2025-12-29T22:10:50.829456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pipeline & callbacks defined\n"
     ]
    }
   ],
   "source": [
    "def create_tf_dataset(X, y, is_train=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {'eeg': X[0], 'bp': X[1], 'task': X[2]},\n",
    "        {'channel': y[0], 'region': y[1], 'band': y[2], 'state': y[3]}\n",
    "    ))\n",
    "    \n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    \n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "class PeriodicCheckpoint(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_freq=5):\n",
    "        super().__init__()\n",
    "        self.save_freq = save_freq\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.save_freq == 0:\n",
    "            filepath = os.path.join(CHECKPOINT_DIR, f\"checkpoint_epoch_{epoch+1:03d}.keras\")\n",
    "            self.model.save(filepath)\n",
    "            print(f\"\\n   Saved checkpoint: {os.path.basename(filepath)}\")\n",
    "\n",
    "\n",
    "class LearningRateLogger(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.learning_rate\n",
    "        if hasattr(lr, '__call__'):\n",
    "            lr_value = lr(self.model.optimizer.iterations)\n",
    "        else:\n",
    "            lr_value = lr\n",
    "        lr_float = float(tf.keras.backend.get_value(lr_value))\n",
    "        if logs is not None:\n",
    "            logs['learning_rate'] = lr_float\n",
    "        print(f\"\\n   LR = {lr_float:.6f}\")\n",
    "\n",
    "\n",
    "class ProgressLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.epoch_start = None\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start = time.time()\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\" Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"{'='*70}\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        elapsed = time.time() - self.epoch_start\n",
    "        print(f\"\\n Epoch {epoch+1} done in {elapsed:.1f}s\")\n",
    "        if logs:\n",
    "            print(f\"   Loss: {logs.get('loss', 0):.4f} | Val Loss: {logs.get('val_loss', 0):.4f}\")\n",
    "            print(f\"   Region Acc: {logs.get('region_accuracy', 0):.4f} | Val: {logs.get('val_region_accuracy', 0):.4f}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(\" Pipeline & callbacks defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b77a03",
   "metadata": {
    "papermill": {
     "duration": 0.003705,
     "end_time": "2025-12-29T22:10:50.854261",
     "exception": false,
     "start_time": "2025-12-29T22:10:50.850556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  8. Main Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46aff76b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T22:10:50.863156Z",
     "iopub.status.busy": "2025-12-29T22:10:50.862906Z",
     "iopub.status.idle": "2025-12-29T22:10:50.877055Z",
     "shell.execute_reply": "2025-12-29T22:10:50.876332Z"
    },
    "papermill": {
     "duration": 0.020467,
     "end_time": "2025-12-29T22:10:50.878421",
     "exception": false,
     "start_time": "2025-12-29T22:10:50.857954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training function ready\n"
     ]
    }
   ],
   "source": [
    "def train_cognivue():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" CogniVue Training Pipeline\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load ONLY training data\n",
    "    print(\"\\n Loading data...\")\n",
    "    train_result = load_preprocessed_data('train')\n",
    "    \n",
    "    if train_result is None:\n",
    "        print(\"\\n‚ùå Data loading failed!\")\n",
    "        return None\n",
    "    \n",
    "    train_data, train_labels, train_meta = train_result\n",
    "    \n",
    "    # =====================================================\n",
    "    # SPLIT TRAIN DATA INTO TRAIN/VAL (80/20)\n",
    "    # =====================================================\n",
    "    print(\"\\n Splitting data into train/val...\")\n",
    "    \n",
    "    num_samples = len(train_data[0])\n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # 80% train, 20% val\n",
    "    split_idx = int(0.8 * num_samples)\n",
    "    train_idx = indices[:split_idx]\n",
    "    val_idx = indices[split_idx:]\n",
    "    \n",
    "    # Split X data\n",
    "    train_X = (\n",
    "        train_data[0][train_idx],  # X_eeg\n",
    "        train_data[1][train_idx],  # X_bp\n",
    "        train_data[2][train_idx]   # X_task\n",
    "    )\n",
    "    val_X = (\n",
    "        train_data[0][val_idx],\n",
    "        train_data[1][val_idx],\n",
    "        train_data[2][val_idx]\n",
    "    )\n",
    "    \n",
    "    # Split y data\n",
    "    train_y = (\n",
    "        train_labels[0][train_idx],  # y_channel\n",
    "        train_labels[1][train_idx],  # y_region\n",
    "        train_labels[2][train_idx],  # y_band\n",
    "        train_labels[3][train_idx]   # y_state\n",
    "    )\n",
    "    val_y = (\n",
    "        train_labels[0][val_idx],\n",
    "        train_labels[1][val_idx],\n",
    "        train_labels[2][val_idx],\n",
    "        train_labels[3][val_idx]\n",
    "    )\n",
    "    \n",
    "    print(f\"   Train samples: {len(train_idx):,}\")\n",
    "    print(f\"   Val samples: {len(val_idx):,}\")\n",
    "    \n",
    "    # Get dimensions from data\n",
    "    NUM_CHANNELS = train_meta['num_channels']\n",
    "    BANDPOWER_INPUT_DIM = train_meta['bandpower_dim']\n",
    "    \n",
    "    # Determine NUM_OUTPUT_CHANNELS from labels\n",
    "    NUM_OUTPUT_CHANNELS = train_labels[0].max() + 1\n",
    "    \n",
    "    print(f\"\\n Model dimensions:\")\n",
    "    print(f\"   Input channels: {NUM_CHANNELS}\")\n",
    "    print(f\"   Bandpower dim: {BANDPOWER_INPUT_DIM}\")\n",
    "    print(f\"   Output channels: {NUM_OUTPUT_CHANNELS}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    print(f\"\\n Creating TF datasets...\")\n",
    "    train_ds = create_tf_dataset(train_X, train_y, is_train=True)\n",
    "    val_ds = create_tf_dataset(val_X, val_y, is_train=False)\n",
    "    \n",
    "    steps_per_epoch = len(train_idx) // BATCH_SIZE\n",
    "    total_steps = steps_per_epoch * EPOCHS\n",
    "    warmup_steps = steps_per_epoch * WARMUP_EPOCHS\n",
    "    \n",
    "    print(f\"   Steps/epoch: {steps_per_epoch:,}\")\n",
    "    print(f\"   Total steps: {total_steps:,}\")\n",
    "    \n",
    "    # Build model\n",
    "    print(f\"\\nÔøΩÔ∏è Building model...\")\n",
    "    \n",
    "    with strategy.scope():\n",
    "        model = create_model(NUM_CHANNELS, BANDPOWER_INPUT_DIM, NUM_OUTPUT_CHANNELS)\n",
    "        \n",
    "        print(f\"   Parameters: {model.count_params():,}\")\n",
    "        \n",
    "        lr_schedule = WarmupCosineDecay(INITIAL_LR, warmup_steps, total_steps)\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=lr_schedule,\n",
    "            weight_decay=WEIGHT_DECAY,\n",
    "            clipnorm=GRADIENT_CLIP_NORM\n",
    "        )\n",
    "        \n",
    "        loss_weights = {'channel': 0.4, 'region': 0.4, 'band': 0.1, 'state': 0.1}\n",
    "        model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss={\n",
    "        'channel': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        'region': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        'band': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        'state': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    },\n",
    "    loss_weights={\n",
    "        'channel': 0.4,\n",
    "        'region': 0.4,\n",
    "        'band': 0.1,\n",
    "        'state': 0.1\n",
    "    },\n",
    "    metrics={\n",
    "        'channel': ['accuracy'],\n",
    "        'region': ['accuracy'],\n",
    "        'band': ['accuracy'],\n",
    "        'state': ['accuracy']\n",
    "    }\n",
    ")\n",
    "    print(f\"    Compiled\")\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        ProgressLogger(),\n",
    "        LearningRateLogger(),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(CHECKPOINT_DIR, 'best_model.keras'),\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        PeriodicCheckpoint(save_freq=SAVE_CHECKPOINT_EVERY),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=EARLY_STOPPING_PATIENCE,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=LOGS_DIR)\n",
    "    ]\n",
    "    \n",
    "    # Train\n",
    "    print(f\"\\n Starting training...\")\n",
    "    print(f\" {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    \n",
    "    try:\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=val_ds,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\" TRAINING COMPLETE!\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\n Saved to: {CHECKPOINT_DIR}\")\n",
    "        \n",
    "        # Save final\n",
    "        model.save(os.path.join(CHECKPOINT_DIR, 'final_model.keras'))\n",
    "        print(f\"   - final_model.keras\")\n",
    "        print(f\"   - best_model.keras\")\n",
    "        \n",
    "        return history\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n Training interrupted!\")\n",
    "        model.save(os.path.join(CHECKPOINT_DIR, 'interrupted.keras'))\n",
    "        print(f\"    Saved: interrupted.keras\")\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Training failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "print(\" Training function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb7c0fb",
   "metadata": {
    "papermill": {
     "duration": 0.003818,
     "end_time": "2025-12-29T22:10:50.886290",
     "exception": false,
     "start_time": "2025-12-29T22:10:50.882472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  9. Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d85058e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T22:10:50.895677Z",
     "iopub.status.busy": "2025-12-29T22:10:50.895226Z",
     "iopub.status.idle": "2025-12-29T22:42:02.518130Z",
     "shell.execute_reply": "2025-12-29T22:42:02.517236Z"
    },
    "papermill": {
     "duration": 1871.629458,
     "end_time": "2025-12-29T22:42:02.519753",
     "exception": false,
     "start_time": "2025-12-29T22:10:50.890295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " CogniVue Training Pipeline\n",
      "======================================================================\n",
      "\n",
      " Loading data...\n",
      "\n",
      " Loading train data from: /kaggle/input/preprocessed-cog-eeg-dataset/processed/train/train_data.pkl\n",
      "   Loaded 21,538 samples\n",
      "\n",
      "  Data format:\n",
      "     X shape: (58, 256) (channels, time)\n",
      "     bp shape: (58, 5) (channels, bands)\n",
      "     Channels: 58\n",
      "\n",
      "   Converting to arrays...\n",
      "   Final shapes:\n",
      "     X_eeg: (21538, 256, 58) (N, time, channels)\n",
      "     X_bp: (21538, 290) (N, features)\n",
      "     X_task: (21538,)\n",
      "     Labels: (21538,) each\n",
      "\n",
      " Splitting data into train/val...\n",
      "   Train samples: 17,230\n",
      "   Val samples: 4,308\n",
      "\n",
      " Model dimensions:\n",
      "   Input channels: 58\n",
      "   Bandpower dim: 290\n",
      "   Output channels: 58\n",
      "\n",
      " Creating TF datasets...\n",
      "   Steps/epoch: 269\n",
      "   Total steps: 26,900\n",
      "\n",
      "ÔøΩÔ∏è Building model...\n",
      "   Parameters: 4,837,162\n",
      "    Compiled\n",
      "\n",
      " Starting training...\n",
      " 2025-12-29 22:11:08\n",
      "\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "\n",
      "======================================================================\n",
      " Epoch 1/100\n",
      "======================================================================\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:Collective all_reduce tensors: 110 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce IndexedSlices: 1 all_reduces, num_devices =2, group_size = 2, implementation = CommunicationImplementation.NCCL\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - band_accuracy: 0.1977 - band_loss: 5.2488 - channel_accuracy: 0.1652 - channel_loss: 6.2459 - loss: 4.5585 - region_accuracy: 0.3474 - region_loss: 3.6248 - state_accuracy: 0.3742 - state_loss: 0.8537\n",
      " Epoch 1 done in 98.8s\n",
      "   Loss: 3.0749 | Val Loss: 1.1775\n",
      "   Region Acc: 0.6682 | Val: 0.9174\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000010\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.17751, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 247ms/step - band_accuracy: 0.1990 - band_loss: 5.2395 - channel_accuracy: 0.1653 - channel_loss: 6.2403 - loss: 4.5530 - region_accuracy: 0.3486 - region_loss: 3.6194 - state_accuracy: 0.3755 - state_loss: 0.8521 - val_band_accuracy: 0.9674 - val_band_loss: 0.1713 - val_channel_accuracy: 0.2544 - val_channel_loss: 2.2232 - val_loss: 1.1775 - val_region_accuracy: 0.9174 - val_region_loss: 0.6713 - val_state_accuracy: 1.0000 - val_state_loss: 0.0255 - learning_rate: 1.0000e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 2/100\n",
      "======================================================================\n",
      "Epoch 2/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - band_accuracy: 0.9630 - band_loss: 0.1897 - channel_accuracy: 0.3429 - channel_loss: 2.1280 - loss: 1.0616 - region_accuracy: 0.9149 - region_loss: 0.4732 - state_accuracy: 1.0000 - state_loss: 0.0215\n",
      " Epoch 2 done in 67.9s\n",
      "   Loss: 0.9852 | Val Loss: 0.8579\n",
      "   Region Acc: 0.9143 | Val: 0.9296\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000020\n",
      "\n",
      "Epoch 2: val_loss improved from 1.17751 to 0.85792, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\n",
      "   Saved checkpoint: checkpoint_epoch_002.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 254ms/step - band_accuracy: 0.9630 - band_loss: 0.1897 - channel_accuracy: 0.3430 - channel_loss: 2.1276 - loss: 1.0613 - region_accuracy: 0.9149 - region_loss: 0.4729 - state_accuracy: 1.0000 - state_loss: 0.0215 - val_band_accuracy: 0.9674 - val_band_loss: 0.1529 - val_channel_accuracy: 0.4263 - val_channel_loss: 1.8126 - val_loss: 0.8579 - val_region_accuracy: 0.9296 - val_region_loss: 0.2923 - val_state_accuracy: 1.0000 - val_state_loss: 0.0068 - learning_rate: 2.0000e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 3/100\n",
      "======================================================================\n",
      "Epoch 3/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - band_accuracy: 0.9594 - band_loss: 0.1730 - channel_accuracy: 0.4723 - channel_loss: 1.6956 - loss: 0.8026 - region_accuracy: 0.9295 - region_loss: 0.2658 - state_accuracy: 1.0000 - state_loss: 0.0070\n",
      " Epoch 3 done in 69.9s\n",
      "   Loss: 0.7702 | Val Loss: 0.7438\n",
      "   Region Acc: 0.9347 | Val: 0.9256\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000030\n",
      "\n",
      "Epoch 3: val_loss improved from 0.85792 to 0.74383, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 259ms/step - band_accuracy: 0.9594 - band_loss: 0.1729 - channel_accuracy: 0.4723 - channel_loss: 1.6954 - loss: 0.8024 - region_accuracy: 0.9295 - region_loss: 0.2658 - state_accuracy: 1.0000 - state_loss: 0.0070 - val_band_accuracy: 0.9674 - val_band_loss: 0.1216 - val_channel_accuracy: 0.5012 - val_channel_loss: 1.5626 - val_loss: 0.7438 - val_region_accuracy: 0.9256 - val_region_loss: 0.2657 - val_state_accuracy: 1.0000 - val_state_loss: 0.0034 - learning_rate: 3.0000e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 4/100\n",
      "======================================================================\n",
      "Epoch 4/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - band_accuracy: 0.9588 - band_loss: 0.1432 - channel_accuracy: 0.5224 - channel_loss: 1.5015 - loss: 0.7125 - region_accuracy: 0.9363 - region_loss: 0.2431 - state_accuracy: 1.0000 - state_loss: 0.0039\n",
      " Epoch 4 done in 70.0s\n",
      "   Loss: 0.6981 | Val Loss: 0.6916\n",
      "   Region Acc: 0.9377 | Val: 0.9286\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000040\n",
      "\n",
      "Epoch 4: val_loss improved from 0.74383 to 0.69165, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\n",
      "   Saved checkpoint: checkpoint_epoch_004.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 262ms/step - band_accuracy: 0.9588 - band_loss: 0.1432 - channel_accuracy: 0.5224 - channel_loss: 1.5014 - loss: 0.7125 - region_accuracy: 0.9363 - region_loss: 0.2430 - state_accuracy: 1.0000 - state_loss: 0.0039 - val_band_accuracy: 0.9667 - val_band_loss: 0.1113 - val_channel_accuracy: 0.5154 - val_channel_loss: 1.4545 - val_loss: 0.6916 - val_region_accuracy: 0.9286 - val_region_loss: 0.2465 - val_state_accuracy: 1.0000 - val_state_loss: 0.0011 - learning_rate: 4.0000e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 5/100\n",
      "======================================================================\n",
      "Epoch 5/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - band_accuracy: 0.9649 - band_loss: 0.1221 - channel_accuracy: 0.5310 - channel_loss: 1.4232 - loss: 0.6703 - region_accuracy: 0.9394 - region_loss: 0.2217 - state_accuracy: 1.0000 - state_loss: 0.0015\n",
      " Epoch 5 done in 70.1s\n",
      "   Loss: 0.6671 | Val Loss: 0.6837\n",
      "   Region Acc: 0.9388 | Val: 0.9216\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000050\n",
      "\n",
      "Epoch 5: val_loss improved from 0.69165 to 0.68367, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 260ms/step - band_accuracy: 0.9649 - band_loss: 0.1221 - channel_accuracy: 0.5310 - channel_loss: 1.4232 - loss: 0.6703 - region_accuracy: 0.9394 - region_loss: 0.2217 - state_accuracy: 1.0000 - state_loss: 0.0015 - val_band_accuracy: 0.9662 - val_band_loss: 0.1061 - val_channel_accuracy: 0.5271 - val_channel_loss: 1.4333 - val_loss: 0.6837 - val_region_accuracy: 0.9216 - val_region_loss: 0.2490 - val_state_accuracy: 1.0000 - val_state_loss: 0.0015 - learning_rate: 5.0000e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 6/100\n",
      "======================================================================\n",
      "Epoch 6/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - band_accuracy: 0.9600 - band_loss: 0.1195 - channel_accuracy: 0.5335 - channel_loss: 1.3934 - loss: 0.6563 - region_accuracy: 0.9384 - region_loss: 0.2172 - state_accuracy: 1.0000 - state_loss: 0.0015\n",
      " Epoch 6 done in 70.0s\n",
      "   Loss: 0.6480 | Val Loss: 0.6636\n",
      "   Region Acc: 0.9377 | Val: 0.9349\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000060\n",
      "\n",
      "Epoch 6: val_loss improved from 0.68367 to 0.66364, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\n",
      "   Saved checkpoint: checkpoint_epoch_006.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 262ms/step - band_accuracy: 0.9600 - band_loss: 0.1195 - channel_accuracy: 0.5335 - channel_loss: 1.3934 - loss: 0.6563 - region_accuracy: 0.9384 - region_loss: 0.2172 - state_accuracy: 1.0000 - state_loss: 0.0015 - val_band_accuracy: 0.9688 - val_band_loss: 0.0976 - val_channel_accuracy: 0.5329 - val_channel_loss: 1.4190 - val_loss: 0.6636 - val_region_accuracy: 0.9349 - val_region_loss: 0.2155 - val_state_accuracy: 1.0000 - val_state_loss: 8.0739e-04 - learning_rate: 6.0000e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 7/100\n",
      "======================================================================\n",
      "Epoch 7/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - band_accuracy: 0.9641 - band_loss: 0.1072 - channel_accuracy: 0.5345 - channel_loss: 1.3587 - loss: 0.6376 - region_accuracy: 0.9408 - region_loss: 0.2083 - state_accuracy: 1.0000 - state_loss: 8.3876e-04\n",
      " Epoch 7 done in 70.1s\n",
      "   Loss: 0.6363 | Val Loss: 0.6767\n",
      "   Region Acc: 0.9397 | Val: 0.9261\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000070\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.66364\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 257ms/step - band_accuracy: 0.9641 - band_loss: 0.1072 - channel_accuracy: 0.5345 - channel_loss: 1.3587 - loss: 0.6376 - region_accuracy: 0.9408 - region_loss: 0.2083 - state_accuracy: 1.0000 - state_loss: 8.3837e-04 - val_band_accuracy: 0.9592 - val_band_loss: 0.1077 - val_channel_accuracy: 0.5191 - val_channel_loss: 1.4391 - val_loss: 0.6767 - val_region_accuracy: 0.9261 - val_region_loss: 0.2256 - val_state_accuracy: 1.0000 - val_state_loss: 5.6662e-04 - learning_rate: 7.0000e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 8/100\n",
      "======================================================================\n",
      "Epoch 8/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - band_accuracy: 0.9648 - band_loss: 0.1101 - channel_accuracy: 0.5458 - channel_loss: 1.3142 - loss: 0.6193 - region_accuracy: 0.9383 - region_loss: 0.2063 - state_accuracy: 1.0000 - state_loss: 4.6718e-04\n",
      " Epoch 8 done in 70.0s\n",
      "   Loss: 0.6171 | Val Loss: 0.6660\n",
      "   Region Acc: 0.9402 | Val: 0.9307\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000080\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.66364\n",
      "\n",
      "   Saved checkpoint: checkpoint_epoch_008.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 260ms/step - band_accuracy: 0.9648 - band_loss: 0.1101 - channel_accuracy: 0.5458 - channel_loss: 1.3142 - loss: 0.6193 - region_accuracy: 0.9383 - region_loss: 0.2063 - state_accuracy: 1.0000 - state_loss: 4.6691e-04 - val_band_accuracy: 0.9646 - val_band_loss: 0.1031 - val_channel_accuracy: 0.5224 - val_channel_loss: 1.4236 - val_loss: 0.6660 - val_region_accuracy: 0.9307 - val_region_loss: 0.2156 - val_state_accuracy: 1.0000 - val_state_loss: 2.1721e-04 - learning_rate: 8.0000e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 9/100\n",
      "======================================================================\n",
      "Epoch 9/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - band_accuracy: 0.9665 - band_loss: 0.1004 - channel_accuracy: 0.5398 - channel_loss: 1.3104 - loss: 0.6169 - region_accuracy: 0.9381 - region_loss: 0.2066 - state_accuracy: 1.0000 - state_loss: 2.5458e-04\n",
      " Epoch 9 done in 69.8s\n",
      "   Loss: 0.6154 | Val Loss: 0.6443\n",
      "   Region Acc: 0.9403 | Val: 0.9296\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000090\n",
      "\n",
      "Epoch 9: val_loss improved from 0.66364 to 0.64434, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 259ms/step - band_accuracy: 0.9665 - band_loss: 0.1004 - channel_accuracy: 0.5399 - channel_loss: 1.3104 - loss: 0.6169 - region_accuracy: 0.9381 - region_loss: 0.2066 - state_accuracy: 1.0000 - state_loss: 2.5456e-04 - val_band_accuracy: 0.9646 - val_band_loss: 0.1001 - val_channel_accuracy: 0.5345 - val_channel_loss: 1.3595 - val_loss: 0.6443 - val_region_accuracy: 0.9296 - val_region_loss: 0.2262 - val_state_accuracy: 1.0000 - val_state_loss: 2.8733e-04 - learning_rate: 9.0000e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 10/100\n",
      "======================================================================\n",
      "Epoch 10/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - band_accuracy: 0.9657 - band_loss: 0.1010 - channel_accuracy: 0.5506 - channel_loss: 1.2782 - loss: 0.5984 - region_accuracy: 0.9421 - region_loss: 0.1926 - state_accuracy: 1.0000 - state_loss: 2.0306e-04\n",
      " Epoch 10 done in 70.1s\n",
      "   Loss: 0.6025 | Val Loss: 0.6430\n",
      "   Region Acc: 0.9417 | Val: 0.9417\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.64434 to 0.64299, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\n",
      "   Saved checkpoint: checkpoint_epoch_010.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 262ms/step - band_accuracy: 0.9657 - band_loss: 0.1010 - channel_accuracy: 0.5506 - channel_loss: 1.2783 - loss: 0.5985 - region_accuracy: 0.9421 - region_loss: 0.1926 - state_accuracy: 1.0000 - state_loss: 2.0298e-04 - val_band_accuracy: 0.9664 - val_band_loss: 0.0996 - val_channel_accuracy: 0.5254 - val_channel_loss: 1.3803 - val_loss: 0.6430 - val_region_accuracy: 0.9417 - val_region_loss: 0.2022 - val_state_accuracy: 1.0000 - val_state_loss: 9.8300e-05 - learning_rate: 1.0000e-04\n",
      "\n",
      "======================================================================\n",
      " Epoch 11/100\n",
      "======================================================================\n",
      "Epoch 11/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - band_accuracy: 0.9646 - band_loss: 0.1054 - channel_accuracy: 0.5554 - channel_loss: 1.2581 - loss: 0.5858 - region_accuracy: 0.9474 - region_loss: 0.1801 - state_accuracy: 1.0000 - state_loss: 1.9341e-04\n",
      " Epoch 11 done in 69.1s\n",
      "   Loss: 0.5911 | Val Loss: 0.6260\n",
      "   Region Acc: 0.9439 | Val: 0.9377\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000100\n",
      "\n",
      "Epoch 11: val_loss improved from 0.64299 to 0.62596, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 256ms/step - band_accuracy: 0.9646 - band_loss: 0.1054 - channel_accuracy: 0.5554 - channel_loss: 1.2581 - loss: 0.5859 - region_accuracy: 0.9474 - region_loss: 0.1802 - state_accuracy: 1.0000 - state_loss: 1.9333e-04 - val_band_accuracy: 0.9685 - val_band_loss: 0.0958 - val_channel_accuracy: 0.5373 - val_channel_loss: 1.3326 - val_loss: 0.6260 - val_region_accuracy: 0.9377 - val_region_loss: 0.2084 - val_state_accuracy: 1.0000 - val_state_loss: 4.8205e-05 - learning_rate: 9.9970e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 12/100\n",
      "======================================================================\n",
      "Epoch 12/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - band_accuracy: 0.9668 - band_loss: 0.0993 - channel_accuracy: 0.5663 - channel_loss: 1.2284 - loss: 0.5753 - region_accuracy: 0.9443 - region_loss: 0.1849 - state_accuracy: 1.0000 - state_loss: 1.2216e-04\n",
      " Epoch 12 done in 69.1s\n",
      "   Loss: 0.5731 | Val Loss: 0.6303\n",
      "   Region Acc: 0.9448 | Val: 0.9352\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000100\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.62596\n",
      "\n",
      "   Saved checkpoint: checkpoint_epoch_012.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 256ms/step - band_accuracy: 0.9668 - band_loss: 0.0993 - channel_accuracy: 0.5663 - channel_loss: 1.2284 - loss: 0.5753 - region_accuracy: 0.9443 - region_loss: 0.1849 - state_accuracy: 1.0000 - state_loss: 1.2225e-04 - val_band_accuracy: 0.9674 - val_band_loss: 0.0960 - val_channel_accuracy: 0.5392 - val_channel_loss: 1.3388 - val_loss: 0.6303 - val_region_accuracy: 0.9352 - val_region_loss: 0.2129 - val_state_accuracy: 1.0000 - val_state_loss: 1.7615e-04 - learning_rate: 9.9878e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 13/100\n",
      "======================================================================\n",
      "Epoch 13/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - band_accuracy: 0.9636 - band_loss: 0.1024 - channel_accuracy: 0.5742 - channel_loss: 1.1912 - loss: 0.5583 - region_accuracy: 0.9455 - region_loss: 0.1790 - state_accuracy: 1.0000 - state_loss: 2.0146e-04\n",
      " Epoch 13 done in 69.0s\n",
      "   Loss: 0.5601 | Val Loss: 0.6325\n",
      "   Region Acc: 0.9457 | Val: 0.9359\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000100\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.62596\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 253ms/step - band_accuracy: 0.9637 - band_loss: 0.1023 - channel_accuracy: 0.5742 - channel_loss: 1.1912 - loss: 0.5583 - region_accuracy: 0.9455 - region_loss: 0.1789 - state_accuracy: 1.0000 - state_loss: 2.0135e-04 - val_band_accuracy: 0.9699 - val_band_loss: 0.0944 - val_channel_accuracy: 0.5268 - val_channel_loss: 1.3572 - val_loss: 0.6325 - val_region_accuracy: 0.9359 - val_region_loss: 0.2004 - val_state_accuracy: 1.0000 - val_state_loss: 1.0024e-04 - learning_rate: 9.9726e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 14/100\n",
      "======================================================================\n",
      "Epoch 14/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - band_accuracy: 0.9642 - band_loss: 0.1016 - channel_accuracy: 0.5848 - channel_loss: 1.1711 - loss: 0.5463 - region_accuracy: 0.9461 - region_loss: 0.1693 - state_accuracy: 1.0000 - state_loss: 1.4362e-04\n",
      " Epoch 14 done in 69.1s\n",
      "   Loss: 0.5435 | Val Loss: 0.6451\n",
      "   Region Acc: 0.9476 | Val: 0.9342\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000100\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.62596\n",
      "\n",
      "   Saved checkpoint: checkpoint_epoch_014.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 256ms/step - band_accuracy: 0.9642 - band_loss: 0.1015 - channel_accuracy: 0.5848 - channel_loss: 1.1711 - loss: 0.5463 - region_accuracy: 0.9461 - region_loss: 0.1693 - state_accuracy: 1.0000 - state_loss: 1.4369e-04 - val_band_accuracy: 0.9629 - val_band_loss: 0.0985 - val_channel_accuracy: 0.5422 - val_channel_loss: 1.3703 - val_loss: 0.6451 - val_region_accuracy: 0.9342 - val_region_loss: 0.2177 - val_state_accuracy: 1.0000 - val_state_loss: 1.0614e-04 - learning_rate: 9.9513e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 15/100\n",
      "======================================================================\n",
      "Epoch 15/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - band_accuracy: 0.9683 - band_loss: 0.0930 - channel_accuracy: 0.5954 - channel_loss: 1.1348 - loss: 0.5248 - region_accuracy: 0.9497 - region_loss: 0.1538 - state_accuracy: 1.0000 - state_loss: 9.6612e-05\n",
      " Epoch 15 done in 68.9s\n",
      "   Loss: 0.5231 | Val Loss: 0.6335\n",
      "   Region Acc: 0.9494 | Val: 0.9349\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000099\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.62596\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 253ms/step - band_accuracy: 0.9683 - band_loss: 0.0930 - channel_accuracy: 0.5954 - channel_loss: 1.1348 - loss: 0.5248 - region_accuracy: 0.9497 - region_loss: 0.1538 - state_accuracy: 1.0000 - state_loss: 9.6672e-05 - val_band_accuracy: 0.9683 - val_band_loss: 0.0916 - val_channel_accuracy: 0.5410 - val_channel_loss: 1.3559 - val_loss: 0.6335 - val_region_accuracy: 0.9349 - val_region_loss: 0.2049 - val_state_accuracy: 1.0000 - val_state_loss: 1.2575e-04 - learning_rate: 9.9240e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 16/100\n",
      "======================================================================\n",
      "Epoch 16/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - band_accuracy: 0.9682 - band_loss: 0.0888 - channel_accuracy: 0.6074 - channel_loss: 1.0902 - loss: 0.5040 - region_accuracy: 0.9519 - region_loss: 0.1476 - state_accuracy: 1.0000 - state_loss: 1.5395e-04\n",
      " Epoch 16 done in 69.1s\n",
      "   Loss: 0.4979 | Val Loss: 0.6275\n",
      "   Region Acc: 0.9545 | Val: 0.9368\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000099\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.62596\n",
      "\n",
      "   Saved checkpoint: checkpoint_epoch_016.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 256ms/step - band_accuracy: 0.9682 - band_loss: 0.0888 - channel_accuracy: 0.6075 - channel_loss: 1.0902 - loss: 0.5040 - region_accuracy: 0.9519 - region_loss: 0.1476 - state_accuracy: 1.0000 - state_loss: 1.5416e-04 - val_band_accuracy: 0.9701 - val_band_loss: 0.0941 - val_channel_accuracy: 0.5490 - val_channel_loss: 1.3352 - val_loss: 0.6275 - val_region_accuracy: 0.9368 - val_region_loss: 0.2100 - val_state_accuracy: 1.0000 - val_state_loss: 2.8633e-04 - learning_rate: 9.8907e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 17/100\n",
      "======================================================================\n",
      "Epoch 17/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - band_accuracy: 0.9668 - band_loss: 0.0917 - channel_accuracy: 0.6332 - channel_loss: 1.0151 - loss: 0.4688 - region_accuracy: 0.9545 - region_loss: 0.1340 - state_accuracy: 1.0000 - state_loss: 1.9766e-04\n",
      " Epoch 17 done in 69.2s\n",
      "   Loss: 0.4774 | Val Loss: 0.6815\n",
      "   Region Acc: 0.9556 | Val: 0.9109\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000099\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.62596\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 254ms/step - band_accuracy: 0.9668 - band_loss: 0.0917 - channel_accuracy: 0.6332 - channel_loss: 1.0152 - loss: 0.4689 - region_accuracy: 0.9545 - region_loss: 0.1340 - state_accuracy: 1.0000 - state_loss: 1.9753e-04 - val_band_accuracy: 0.9634 - val_band_loss: 0.1005 - val_channel_accuracy: 0.5366 - val_channel_loss: 1.4119 - val_loss: 0.6815 - val_region_accuracy: 0.9109 - val_region_loss: 0.2668 - val_state_accuracy: 1.0000 - val_state_loss: 1.0663e-04 - learning_rate: 9.8515e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 18/100\n",
      "======================================================================\n",
      "Epoch 18/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - band_accuracy: 0.9726 - band_loss: 0.0818 - channel_accuracy: 0.6534 - channel_loss: 0.9602 - loss: 0.4376 - region_accuracy: 0.9635 - region_loss: 0.1133 - state_accuracy: 1.0000 - state_loss: 1.4212e-04\n",
      " Epoch 18 done in 69.1s\n",
      "   Loss: 0.4428 | Val Loss: 0.6461\n",
      "   Region Acc: 0.9623 | Val: 0.9338\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000098\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.62596\n",
      "\n",
      "   Saved checkpoint: checkpoint_epoch_018.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 256ms/step - band_accuracy: 0.9726 - band_loss: 0.0818 - channel_accuracy: 0.6534 - channel_loss: 0.9602 - loss: 0.4376 - region_accuracy: 0.9635 - region_loss: 0.1133 - state_accuracy: 1.0000 - state_loss: 1.4229e-04 - val_band_accuracy: 0.9592 - val_band_loss: 0.1083 - val_channel_accuracy: 0.5312 - val_channel_loss: 1.3701 - val_loss: 0.6461 - val_region_accuracy: 0.9338 - val_region_loss: 0.2181 - val_state_accuracy: 1.0000 - val_state_loss: 1.5867e-04 - learning_rate: 9.8063e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 19/100\n",
      "======================================================================\n",
      "Epoch 19/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - band_accuracy: 0.9702 - band_loss: 0.0852 - channel_accuracy: 0.6680 - channel_loss: 0.9107 - loss: 0.4139 - region_accuracy: 0.9665 - region_loss: 0.1028 - state_accuracy: 1.0000 - state_loss: 1.0825e-04\n",
      " Epoch 19 done in 69.1s\n",
      "   Loss: 0.4145 | Val Loss: 0.6563\n",
      "   Region Acc: 0.9660 | Val: 0.9373\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000098\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.62596\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 253ms/step - band_accuracy: 0.9702 - band_loss: 0.0852 - channel_accuracy: 0.6680 - channel_loss: 0.9107 - loss: 0.4139 - region_accuracy: 0.9665 - region_loss: 0.1028 - state_accuracy: 1.0000 - state_loss: 1.0819e-04 - val_band_accuracy: 0.9662 - val_band_loss: 0.0949 - val_channel_accuracy: 0.5452 - val_channel_loss: 1.3964 - val_loss: 0.6563 - val_region_accuracy: 0.9373 - val_region_loss: 0.2207 - val_state_accuracy: 1.0000 - val_state_loss: 1.0245e-04 - learning_rate: 9.7553e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 20/100\n",
      "======================================================================\n",
      "Epoch 20/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - band_accuracy: 0.9743 - band_loss: 0.0761 - channel_accuracy: 0.6959 - channel_loss: 0.8425 - loss: 0.3795 - region_accuracy: 0.9686 - region_loss: 0.0871 - state_accuracy: 1.0000 - state_loss: 8.9261e-05\n",
      " Epoch 20 done in 69.8s\n",
      "   Loss: 0.3808 | Val Loss: 0.6762\n",
      "   Region Acc: 0.9704 | Val: 0.9389\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000097\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.62596\n",
      "\n",
      "   Saved checkpoint: checkpoint_epoch_020.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 258ms/step - band_accuracy: 0.9743 - band_loss: 0.0761 - channel_accuracy: 0.6958 - channel_loss: 0.8426 - loss: 0.3795 - region_accuracy: 0.9686 - region_loss: 0.0871 - state_accuracy: 1.0000 - state_loss: 8.9285e-05 - val_band_accuracy: 0.9697 - val_band_loss: 0.0908 - val_channel_accuracy: 0.5292 - val_channel_loss: 1.4260 - val_loss: 0.6762 - val_region_accuracy: 0.9389 - val_region_loss: 0.2418 - val_state_accuracy: 1.0000 - val_state_loss: 8.9917e-05 - learning_rate: 9.6985e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 21/100\n",
      "======================================================================\n",
      "Epoch 21/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - band_accuracy: 0.9751 - band_loss: 0.0735 - channel_accuracy: 0.7213 - channel_loss: 0.7705 - loss: 0.3428 - region_accuracy: 0.9760 - region_loss: 0.0682 - state_accuracy: 1.0000 - state_loss: 1.1122e-04\n",
      " Epoch 21 done in 69.1s\n",
      "   Loss: 0.3477 | Val Loss: 0.7322\n",
      "   Region Acc: 0.9755 | Val: 0.9345\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000096\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.62596\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 254ms/step - band_accuracy: 0.9751 - band_loss: 0.0735 - channel_accuracy: 0.7212 - channel_loss: 0.7705 - loss: 0.3428 - region_accuracy: 0.9760 - region_loss: 0.0682 - state_accuracy: 1.0000 - state_loss: 1.1113e-04 - val_band_accuracy: 0.9634 - val_band_loss: 0.0998 - val_channel_accuracy: 0.5299 - val_channel_loss: 1.5625 - val_loss: 0.7322 - val_region_accuracy: 0.9345 - val_region_loss: 0.2432 - val_state_accuracy: 1.0000 - val_state_loss: 7.9369e-05 - learning_rate: 9.6359e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 22/100\n",
      "======================================================================\n",
      "Epoch 22/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - band_accuracy: 0.9762 - band_loss: 0.0701 - channel_accuracy: 0.7568 - channel_loss: 0.6800 - loss: 0.3011 - region_accuracy: 0.9811 - region_loss: 0.0553 - state_accuracy: 1.0000 - state_loss: 8.5641e-05\n",
      " Epoch 22 done in 69.1s\n",
      "   Loss: 0.3101 | Val Loss: 0.6953\n",
      "   Region Acc: 0.9813 | Val: 0.9377\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000096\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.62596\n",
      "\n",
      "   Saved checkpoint: checkpoint_epoch_022.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 256ms/step - band_accuracy: 0.9762 - band_loss: 0.0701 - channel_accuracy: 0.7568 - channel_loss: 0.6801 - loss: 0.3012 - region_accuracy: 0.9811 - region_loss: 0.0553 - state_accuracy: 1.0000 - state_loss: 8.5623e-05 - val_band_accuracy: 0.9701 - val_band_loss: 0.0949 - val_channel_accuracy: 0.5623 - val_channel_loss: 1.4498 - val_loss: 0.6953 - val_region_accuracy: 0.9377 - val_region_loss: 0.2647 - val_state_accuracy: 1.0000 - val_state_loss: 3.1402e-05 - learning_rate: 9.5677e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 23/100\n",
      "======================================================================\n",
      "Epoch 23/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - band_accuracy: 0.9747 - band_loss: 0.0750 - channel_accuracy: 0.7787 - channel_loss: 0.6056 - loss: 0.2656 - region_accuracy: 0.9862 - region_loss: 0.0397 - state_accuracy: 1.0000 - state_loss: 5.2093e-05\n",
      " Epoch 23 done in 69.1s\n",
      "   Loss: 0.2793 | Val Loss: 0.7010\n",
      "   Region Acc: 0.9836 | Val: 0.9405\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000095\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.62596\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 253ms/step - band_accuracy: 0.9747 - band_loss: 0.0750 - channel_accuracy: 0.7787 - channel_loss: 0.6057 - loss: 0.2657 - region_accuracy: 0.9861 - region_loss: 0.0397 - state_accuracy: 1.0000 - state_loss: 5.2100e-05 - val_band_accuracy: 0.9720 - val_band_loss: 0.0968 - val_channel_accuracy: 0.5641 - val_channel_loss: 1.4713 - val_loss: 0.7010 - val_region_accuracy: 0.9405 - val_region_loss: 0.2569 - val_state_accuracy: 1.0000 - val_state_loss: 2.4959e-05 - learning_rate: 9.4940e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 24/100\n",
      "======================================================================\n",
      "Epoch 24/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - band_accuracy: 0.9754 - band_loss: 0.0718 - channel_accuracy: 0.8015 - channel_loss: 0.5500 - loss: 0.2418 - region_accuracy: 0.9880 - region_loss: 0.0365 - state_accuracy: 1.0000 - state_loss: 4.7417e-05\n",
      " Epoch 24 done in 69.2s\n",
      "   Loss: 0.2467 | Val Loss: 0.7385\n",
      "   Region Acc: 0.9878 | Val: 0.9363\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000094\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.62596\n",
      "\n",
      "   Saved checkpoint: checkpoint_epoch_024.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 256ms/step - band_accuracy: 0.9754 - band_loss: 0.0718 - channel_accuracy: 0.8015 - channel_loss: 0.5500 - loss: 0.2418 - region_accuracy: 0.9880 - region_loss: 0.0365 - state_accuracy: 1.0000 - state_loss: 4.7410e-05 - val_band_accuracy: 0.9692 - val_band_loss: 0.0952 - val_channel_accuracy: 0.5602 - val_channel_loss: 1.5483 - val_loss: 0.7385 - val_region_accuracy: 0.9363 - val_region_loss: 0.2742 - val_state_accuracy: 1.0000 - val_state_loss: 5.7403e-05 - learning_rate: 9.4147e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 25/100\n",
      "======================================================================\n",
      "Epoch 25/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - band_accuracy: 0.9768 - band_loss: 0.0683 - channel_accuracy: 0.8353 - channel_loss: 0.4720 - loss: 0.2069 - region_accuracy: 0.9909 - region_loss: 0.0282 - state_accuracy: 1.0000 - state_loss: 5.5381e-05\n",
      " Epoch 25 done in 68.9s\n",
      "   Loss: 0.2176 | Val Loss: 0.7911\n",
      "   Region Acc: 0.9895 | Val: 0.9419\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000093\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.62596\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 252ms/step - band_accuracy: 0.9768 - band_loss: 0.0683 - channel_accuracy: 0.8353 - channel_loss: 0.4721 - loss: 0.2070 - region_accuracy: 0.9909 - region_loss: 0.0282 - state_accuracy: 1.0000 - state_loss: 5.5406e-05 - val_band_accuracy: 0.9708 - val_band_loss: 0.0937 - val_channel_accuracy: 0.5508 - val_channel_loss: 1.6789 - val_loss: 0.7911 - val_region_accuracy: 0.9419 - val_region_loss: 0.2754 - val_state_accuracy: 1.0000 - val_state_loss: 6.6403e-05 - learning_rate: 9.3301e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 26/100\n",
      "======================================================================\n",
      "Epoch 26/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - band_accuracy: 0.9773 - band_loss: 0.0659 - channel_accuracy: 0.8596 - channel_loss: 0.4078 - loss: 0.1786 - region_accuracy: 0.9928 - region_loss: 0.0221 - state_accuracy: 1.0000 - state_loss: 7.9059e-05\n",
      " Epoch 26 done in 69.1s\n",
      "   Loss: 0.1864 | Val Loss: 0.8155\n",
      "   Region Acc: 0.9926 | Val: 0.9380\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000092\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.62596\n",
      "\n",
      "   Saved checkpoint: checkpoint_epoch_026.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 256ms/step - band_accuracy: 0.9773 - band_loss: 0.0659 - channel_accuracy: 0.8595 - channel_loss: 0.4079 - loss: 0.1786 - region_accuracy: 0.9928 - region_loss: 0.0221 - state_accuracy: 1.0000 - state_loss: 7.9000e-05 - val_band_accuracy: 0.9681 - val_band_loss: 0.0931 - val_channel_accuracy: 0.5620 - val_channel_loss: 1.7221 - val_loss: 0.8155 - val_region_accuracy: 0.9380 - val_region_loss: 0.2935 - val_state_accuracy: 1.0000 - val_state_loss: 2.9134e-05 - learning_rate: 9.2402e-05\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\n",
      "======================================================================\n",
      " TRAINING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      " Saved to: /kaggle/working/checkpoints\n",
      "   - final_model.keras\n",
      "   - best_model.keras\n",
      "\n",
      " Training Summary:\n",
      "   Best val_loss: 0.6260\n",
      "   Final region acc: 0.9926\n",
      "\n",
      " Next: Click 'Save Version' to commit checkpoints!\n"
     ]
    }
   ],
   "source": [
    "history = train_cognivue()\n",
    "\n",
    "if history:\n",
    "    print(\"\\n Training Summary:\")\n",
    "    print(f\"   Best val_loss: {min(history.history['val_loss']):.4f}\")\n",
    "    print(f\"   Final region acc: {history.history['region_accuracy'][-1]:.4f}\")\n",
    "    print(f\"\\n Next: Click 'Save Version' to commit checkpoints!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Training did not complete successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99d2a8",
   "metadata": {
    "papermill": {
     "duration": 0.320172,
     "end_time": "2025-12-29T22:42:03.242248",
     "exception": false,
     "start_time": "2025-12-29T22:42:02.922076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "10: Save Training Results & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d88da2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T22:42:03.883242Z",
     "iopub.status.busy": "2025-12-29T22:42:03.882653Z",
     "iopub.status.idle": "2025-12-29T22:42:05.834034Z",
     "shell.execute_reply": "2025-12-29T22:42:05.833306Z"
    },
    "papermill": {
     "duration": 2.272897,
     "end_time": "2025-12-29T22:42:05.835626",
     "exception": false,
     "start_time": "2025-12-29T22:42:03.562729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saving training results...\n",
      "   Saved: training_history.json\n",
      "\n",
      " Loading train data from: /kaggle/input/preprocessed-cog-eeg-dataset/processed/train/train_data.pkl\n",
      "   Loaded 21,538 samples\n",
      "\n",
      "  Data format:\n",
      "     X shape: (58, 256) (channels, time)\n",
      "     bp shape: (58, 5) (channels, bands)\n",
      "     Channels: 58\n",
      "\n",
      "   Converting to arrays...\n",
      "   Final shapes:\n",
      "     X_eeg: (21538, 256, 58) (N, time, channels)\n",
      "     X_bp: (21538, 290) (N, features)\n",
      "     X_task: (21538,)\n",
      "     Labels: (21538,) each\n",
      "   Saved: training_config.json\n",
      "   Saved: TRAINING_SUMMARY.md\n",
      "\n",
      " All results saved!\n",
      "\n",
      " Saved files:\n",
      "   /kaggle/working/results/\n",
      "   ‚îú‚îÄ‚îÄ training_history.json\n",
      "   ‚îú‚îÄ‚îÄ training_config.json\n",
      "   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\n",
      "\n",
      "   /kaggle/working/checkpoints/\n",
      "   ‚îú‚îÄ‚îÄ best_model.keras\n",
      "   ‚îú‚îÄ‚îÄ final_model.keras\n",
      "   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\n"
     ]
    }
   ],
   "source": [
    "if history:\n",
    "    print(\"\\n Saving training results...\")\n",
    "    \n",
    "    # Convert history to JSON-serializable format\n",
    "    history_dict = {\n",
    "        key: [float(val) for val in values] \n",
    "        for key, values in history.history.items()\n",
    "    }\n",
    "    \n",
    "    # Save training history\n",
    "    history_path = os.path.join(RESULTS_DIR, 'training_history.json')\n",
    "    with open(history_path, 'w') as f:\n",
    "        json.dump(history_dict, f, indent=2)\n",
    "    print(f\"   Saved: training_history.json\")\n",
    "    \n",
    "    # Get model dimensions from loaded data\n",
    "    train_result = load_preprocessed_data('train')\n",
    "    if train_result:\n",
    "        _, _, train_meta = train_result\n",
    "        NUM_CHANNELS_USED = train_meta['num_channels']\n",
    "    else:\n",
    "        NUM_CHANNELS_USED = \"unknown\"\n",
    "    \n",
    "    # Save training configuration\n",
    "    config = {\n",
    "        'model_architecture': {\n",
    "            'name': 'CogniVue_Transformer',\n",
    "            'num_input_channels': NUM_CHANNELS_USED,\n",
    "            'd_model': D_MODEL,\n",
    "            'num_layers': NUM_LAYERS,\n",
    "            'num_heads': NUM_HEADS,\n",
    "            'ff_dim': FF_DIM,\n",
    "            'dropout': DROPOUT,\n",
    "            'window_size': WINDOW_SIZE_SAMPLES\n",
    "        },\n",
    "        'training_params': {\n",
    "            'epochs_trained': len(history.history['loss']),\n",
    "            'total_epochs': EPOCHS,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'initial_lr': INITIAL_LR,\n",
    "            'warmup_epochs': WARMUP_EPOCHS,\n",
    "            'weight_decay': WEIGHT_DECAY,\n",
    "            'gradient_clip_norm': GRADIENT_CLIP_NORM\n",
    "        },\n",
    "        'output_tasks': {\n",
    "            'num_output_channels': NUM_OUTPUT_REGIONS,\n",
    "            'num_regions': NUM_OUTPUT_REGIONS,\n",
    "            'num_bands': NUM_OUTPUT_BANDS,\n",
    "            'num_states': NUM_OUTPUT_STATES\n",
    "        },\n",
    "        'final_metrics': {\n",
    "            'best_val_loss': float(min(history.history['val_loss'])),\n",
    "            'final_train_loss': float(history.history['loss'][-1]),\n",
    "            'final_val_loss': float(history.history['val_loss'][-1]),\n",
    "            'final_region_accuracy': float(history.history['region_accuracy'][-1]),\n",
    "            'final_val_region_accuracy': float(history.history['val_region_accuracy'][-1])\n",
    "        },\n",
    "        'training_info': {\n",
    "            'completed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'tensorflow_version': tf.__version__,\n",
    "            'accelerator': 'TPU' if 'TPU' in str(strategy.__class__) else 'CPU/GPU'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config_path = os.path.join(RESULTS_DIR, 'training_config.json')\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    print(f\"   Saved: training_config.json\")\n",
    "    \n",
    "    # Create a summary markdown file\n",
    "    summary_md = f\"\"\"# CogniVue Training Summary\n",
    "\n",
    "**Training Completed:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Model Architecture\n",
    "- **Model:** CogniVue Transformer\n",
    "- **Input Channels:** {NUM_CHANNELS_USED}\n",
    "- **Model Dimension:** {D_MODEL}\n",
    "- **Transformer Layers:** {NUM_LAYERS}\n",
    "- **Attention Heads:** {NUM_HEADS}\n",
    "- **Feedforward Dim:** {FF_DIM}\n",
    "- **Dropout:** {DROPOUT}\n",
    "\n",
    "## Training Configuration\n",
    "- **Epochs:** {len(history.history['loss'])}/{EPOCHS}\n",
    "- **Batch Size:** {BATCH_SIZE}\n",
    "- **Initial LR:** {INITIAL_LR}\n",
    "- **Warmup Epochs:** {WARMUP_EPOCHS}\n",
    "- **Weight Decay:** {WEIGHT_DECAY}\n",
    "\n",
    "## Final Performance\n",
    "- **Best Val Loss:** {min(history.history['val_loss']):.4f}\n",
    "- **Final Train Loss:** {history.history['loss'][-1]:.4f}\n",
    "- **Final Val Loss:** {history.history['val_loss'][-1]:.4f}\n",
    "- **Final Region Accuracy:** {history.history['region_accuracy'][-1]:.4f}\n",
    "- **Final Val Region Accuracy:** {history.history['val_region_accuracy'][-1]:.4f}\n",
    "\n",
    "## Output Files\n",
    "- `checkpoints/best_model.keras` - Best model weights\n",
    "- `checkpoints/final_model.keras` - Final model weights\n",
    "- `checkpoints/checkpoint_epoch_*.keras` - Periodic checkpoints\n",
    "- `results/training_history.json` - Loss and metrics per epoch\n",
    "- `results/training_config.json` - Full configuration\n",
    "- `logs/` - TensorBoard logs\n",
    "\"\"\"\n",
    "    \n",
    "    summary_path = os.path.join(RESULTS_DIR, 'TRAINING_SUMMARY.md')\n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write(summary_md)\n",
    "    print(f\"   Saved: TRAINING_SUMMARY.md\")\n",
    "    \n",
    "    print(\"\\n All results saved!\")\n",
    "    print(f\"\\n Saved files:\")\n",
    "    print(f\"   {RESULTS_DIR}/\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ training_history.json\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ training_config.json\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\")\n",
    "    print(f\"\\n   {CHECKPOINT_DIR}/\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ best_model.keras\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ final_model.keras\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No training history to save\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8aaf35",
   "metadata": {
    "papermill": {
     "duration": 0.347231,
     "end_time": "2025-12-29T22:42:06.505453",
     "exception": false,
     "start_time": "2025-12-29T22:42:06.158222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "11: Package & Download All Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b52581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T22:42:07.248490Z",
     "iopub.status.busy": "2025-12-29T22:42:07.247977Z",
     "iopub.status.idle": "2025-12-29T22:42:52.223967Z",
     "shell.execute_reply": "2025-12-29T22:42:52.222862Z"
    },
    "papermill": {
     "duration": 45.377604,
     "end_time": "2025-12-29T22:42:52.225898",
     "exception": false,
     "start_time": "2025-12-29T22:42:06.848294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Creating download package...\n",
      "======================================================================\n",
      "\n",
      " Adding results...\n",
      "   training_config.json\n",
      "   training_history.json\n",
      "   TRAINING_SUMMARY.md\n",
      "\n",
      "üîñ Adding checkpoints...\n",
      "   checkpoint_epoch_012.keras (57.1 MB)\n",
      "   checkpoint_epoch_018.keras (57.1 MB)\n",
      "   checkpoint_epoch_026.keras (57.1 MB)\n",
      "   final_model.keras (57.1 MB)\n",
      "   checkpoint_epoch_008.keras (57.1 MB)\n",
      "   checkpoint_epoch_022.keras (57.1 MB)\n",
      "   checkpoint_epoch_004.keras (57.1 MB)\n",
      "   checkpoint_epoch_010.keras (57.1 MB)\n",
      "   checkpoint_epoch_020.keras (57.1 MB)\n",
      "   best_model.keras (57.1 MB)\n",
      "   checkpoint_epoch_016.keras (57.1 MB)\n",
      "   checkpoint_epoch_002.keras (57.1 MB)\n",
      "   checkpoint_epoch_014.keras (57.1 MB)\n",
      "   checkpoint_epoch_024.keras (57.1 MB)\n",
      "   checkpoint_epoch_006.keras (57.1 MB)\n",
      "\n",
      " Adding TensorBoard logs...\n",
      "   Added 2 log files\n",
      "\n",
      "======================================================================\n",
      " PACKAGE CREATED SUCCESSFULLY!\n",
      "======================================================================\n",
      "\n",
      " Zip file: cognivue_training_outputs_20251229_224207.zip\n",
      " Size: 768.1 MB\n",
      " Location: /kaggle/working/cognivue_training_outputs_20251229_224207.zip\n",
      "\n",
      " To download:\n",
      "   1. Go to the 'Output' tab (top right)\n",
      "   2. Click 'Save Version' to commit outputs\n",
      "   3. Download 'cognivue_training_outputs_20251229_224207.zip'\n",
      "\n",
      " Or click the download icon next to the file in the Output tab\n",
      "\n",
      " Package contents:\n",
      "   Total files: 20\n",
      "\n",
      "   Structure:\n",
      "   ‚îú‚îÄ‚îÄ results/\n",
      "   ‚îÇ   ‚îú‚îÄ‚îÄ training_history.json\n",
      "   ‚îÇ   ‚îú‚îÄ‚îÄ training_config.json\n",
      "   ‚îÇ   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\n",
      "   ‚îú‚îÄ‚îÄ checkpoints/\n",
      "   ‚îÇ   ‚îú‚îÄ‚îÄ best_model.keras\n",
      "   ‚îÇ   ‚îú‚îÄ‚îÄ final_model.keras\n",
      "   ‚îÇ   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\n",
      "   ‚îî‚îÄ‚îÄ logs/\n",
      "       ‚îî‚îÄ‚îÄ TensorBoard logs\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# Section 11: Package & Download All Outputs\n",
    "# ============================================================\n",
    "\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n Creating download package...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create zip filename with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "zip_filename = f\"cognivue_training_outputs_{timestamp}.zip\"\n",
    "zip_path = os.path.join(WORKING_DIR, zip_filename)\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        \n",
    "        # Add all files from results directory\n",
    "        print(\"\\n Adding results...\")\n",
    "        if os.path.exists(RESULTS_DIR):\n",
    "            for file in os.listdir(RESULTS_DIR):\n",
    "                file_path = os.path.join(RESULTS_DIR, file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    arcname = os.path.join('results', file)\n",
    "                    zipf.write(file_path, arcname)\n",
    "                    print(f\"   {file}\")\n",
    "        \n",
    "        # Add all checkpoint files\n",
    "        print(\"\\nüîñ Adding checkpoints...\")\n",
    "        if os.path.exists(CHECKPOINT_DIR):\n",
    "            for file in os.listdir(CHECKPOINT_DIR):\n",
    "                file_path = os.path.join(CHECKPOINT_DIR, file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    arcname = os.path.join('checkpoints', file)\n",
    "                    zipf.write(file_path, arcname)\n",
    "                    file_size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "                    print(f\"   {file} ({file_size_mb:.1f} MB)\")\n",
    "        \n",
    "        # Add TensorBoard logs (optional - can be large)\n",
    "        print(\"\\n Adding TensorBoard logs...\")\n",
    "        if os.path.exists(LOGS_DIR):\n",
    "            log_count = 0\n",
    "            for root, dirs, files in os.walk(LOGS_DIR):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.join('logs', os.path.relpath(file_path, LOGS_DIR))\n",
    "                    zipf.write(file_path, arcname)\n",
    "                    log_count += 1\n",
    "            print(f\"   Added {log_count} log files\")\n",
    "    \n",
    "    # Get final zip size\n",
    "    zip_size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\" PACKAGE CREATED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\n Zip file: {zip_filename}\")\n",
    "    print(f\" Size: {zip_size_mb:.1f} MB\")\n",
    "    print(f\" Location: {zip_path}\")\n",
    "    \n",
    "    print(\"\\n To download:\")\n",
    "    print(\"   1. Go to the 'Output' tab (top right)\")\n",
    "    print(\"   2. Click 'Save Version' to commit outputs\")\n",
    "    print(f\"   3. Download '{zip_filename}'\")\n",
    "    print(\"\\n Or click the download icon next to the file in the Output tab\")\n",
    "    \n",
    "    # List contents\n",
    "    print(\"\\n Package contents:\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "        file_list = zipf.namelist()\n",
    "        print(f\"   Total files: {len(file_list)}\")\n",
    "        print(\"\\n   Structure:\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ results/\")\n",
    "        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ training_history.json\")\n",
    "        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ training_config.json\")\n",
    "        print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ checkpoints/\")\n",
    "        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ best_model.keras\")\n",
    "        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ final_model.keras\")\n",
    "        print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\")\n",
    "        print(\"   ‚îî‚îÄ‚îÄ logs/\")\n",
    "        print(\"       ‚îî‚îÄ‚îÄ TensorBoard logs\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error creating zip: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59bea89b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T22:42:52.873349Z",
     "iopub.status.busy": "2025-12-29T22:42:52.872519Z",
     "iopub.status.idle": "2025-12-29T22:42:52.876644Z",
     "shell.execute_reply": "2025-12-29T22:42:52.875980Z"
    },
    "papermill": {
     "duration": 0.328944,
     "end_time": "2025-12-29T22:42:52.878172",
     "exception": false,
     "start_time": "2025-12-29T22:42:52.549228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cognivue_training_outputs_20251229_224207.zip', 'checkpoints', 'logs', '__notebook__.ipynb', 'results']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('/kaggle/working/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62e3e904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T22:42:53.522705Z",
     "iopub.status.busy": "2025-12-29T22:42:53.522402Z",
     "iopub.status.idle": "2025-12-29T22:42:53.530620Z",
     "shell.execute_reply": "2025-12-29T22:42:53.529920Z"
    },
    "papermill": {
     "duration": 0.335216,
     "end_time": "2025-12-29T22:42:53.532092",
     "exception": false,
     "start_time": "2025-12-29T22:42:53.196876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "‚úÖ LATEST PACKAGE FOUND: cognivue_training_outputs_20251229_224207.zip\n",
      "Click the link below to download your results:\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='cognivue_training_outputs_20251229_224207.zip' target='_blank'>cognivue_training_outputs_20251229_224207.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/cognivue_training_outputs_20251229_224207.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "# 1. Search for any zip files starting with 'cognivue_training_outputs'\n",
    "zip_files = glob.glob('/kaggle/working/cognivue_training_outputs_*.zip')\n",
    "\n",
    "if zip_files:\n",
    "    # 2. Sort by newest (incase there are multiple)\n",
    "    latest_zip = max(zip_files, key=os.path.getctime)\n",
    "    relative_path = os.path.basename(latest_zip)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(f\"‚úÖ LATEST PACKAGE FOUND: {relative_path}\")\n",
    "    print(\"Click the link below to download your results:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 3. Display the dynamic link\n",
    "    display(FileLink(relative_path))\n",
    "else:\n",
    "    print(\"‚ùå No output zip files found in /kaggle/working/\")\n",
    "    print(\"Current directory contents:\", os.listdir('/kaggle/working/'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9143557,
     "sourceId": 14322899,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1958.843895,
   "end_time": "2025-12-29T22:42:57.364311",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-29T22:10:18.520416",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
