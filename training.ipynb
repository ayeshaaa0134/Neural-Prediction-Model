{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"TPU","kaggle":{"accelerator":"tpuV5e8","dataSources":[{"sourceId":14322899,"sourceType":"datasetVersion","datasetId":9143557}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üß† CogniVue: TPU Training (Compatible with Preprocessing)\n\n**‚úÖ FULLY COMPATIBLE with your preprocessing notebook!**\n\nThis notebook:\n- ‚úÖ Loads data from single `.pkl` files per split\n- ‚úÖ Handles variable channel count (typically 58 channels)\n- ‚úÖ Correctly transposes X from `(n_ch, 256)` to `(256, n_ch)`\n- ‚úÖ Uses TPU v5e-8 for fast training\n- ‚úÖ Robust checkpointing and error handling\n- ‚úÖ Resume training from interruptions\n\n## üìã Setup Instructions\n\n1. **Upload preprocessed data** as Kaggle dataset:\n   - Your `data/processed/train/train_data.pkl`\n   - Your `data/processed/val/val_data.pkl`  \n   - Your `data/processed/test/test_data.pkl`\n\n2. **Set accelerator** to **TPU VM v5e-8**\n\n3. **Attach dataset** and update `DATASET_NAME` below\n\n4. **Run All** and let it train!","metadata":{}},{"cell_type":"markdown","source":"## üì¶ 1. Install Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install -q tensorflow pandas numpy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T09:00:49.979140Z","iopub.execute_input":"2025-12-29T09:00:49.979299Z","iopub.status.idle":"2025-12-29T09:00:52.448581Z","shell.execute_reply.started":"2025-12-29T09:00:49.979280Z","shell.execute_reply":"2025-12-29T09:00:52.447350Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## ‚öôÔ∏è 2. Configuration","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport json\nimport time\nimport shutil\nimport numpy as np\nimport tensorflow as tf\nimport pickle\nfrom datetime import datetime\n\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"Python version: {sys.version}\")\n\n# =====================================================\n# PATHS CONFIGURATION\n# =====================================================\n\n# UPDATE THIS to match your dataset name!\nDATASET_NAME = \"preprocessed-cog-eeg-dataset\"  \n\n# Input paths\nDATA_INPUT_DIR = f\"/kaggle/input/{DATASET_NAME}/processed\"\n\n# Output paths\nWORKING_DIR = \"/kaggle/working\"\nCHECKPOINT_DIR = os.path.join(WORKING_DIR, \"checkpoints\")\nRESULTS_DIR = os.path.join(WORKING_DIR, \"results\")\nLOGS_DIR = os.path.join(WORKING_DIR, \"logs\")\n\nfor d in [CHECKPOINT_DIR, RESULTS_DIR, LOGS_DIR]:\n    os.makedirs(d, exist_ok=True)\n\nprint(f\"\\nüìÇ Paths configured:\")\nprint(f\"  Input: {DATA_INPUT_DIR}\")\nprint(f\"  Checkpoints: {CHECKPOINT_DIR}\")\nprint(f\"  Results: {RESULTS_DIR}\")\n\n# =====================================================\n# DATA CONSTANTS (from preprocessing)\n# =====================================================\n\nWINDOW_SIZE_SAMPLES = 256\nNUM_BANDS = 5  # delta, theta, alpha, beta, gamma\nNUM_TASKS = 4  # N-back, MATB-II, PVT, Flanker\n\n# Output classes\nNUM_OUTPUT_REGIONS = 7\nNUM_OUTPUT_BANDS = 5\nNUM_OUTPUT_STATES = 4\n\n# Note: NUM_CHANNELS and NUM_OUTPUT_CHANNELS will be determined from data!\n\n# =====================================================\n# MODEL HYPERPARAMETERS\n# =====================================================\n\nD_MODEL = 256\nNUM_LAYERS = 6\nNUM_HEADS = 8\nFF_DIM = 1024\nDROPOUT = 0.15\n\nBANDPOWER_HIDDEN_DIM = 128\nBANDPOWER_OUTPUT_DIM = 128\nTASK_EMBEDDING_DIM = 16\n\n# =====================================================\n# TRAINING HYPERPARAMETERS\n# =====================================================\n\nEPOCHS = 20\nINITIAL_LR = 1e-4\nWARMUP_EPOCHS = 5\nWEIGHT_DECAY = 0.01\nGRADIENT_CLIP_NORM = 1.0\n\nSAVE_CHECKPOINT_EVERY = 2\nEARLY_STOPPING_PATIENCE = 15\n\nprint(f\"\\nüîß Configuration:\")\nprint(f\"  Model: {NUM_LAYERS} layers, {NUM_HEADS} heads, D_MODEL={D_MODEL}\")\nprint(f\"  Training: {EPOCHS} epochs, LR={INITIAL_LR}\")\nprint(f\"  Checkpointing: every {SAVE_CHECKPOINT_EVERY} epochs\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T09:00:52.449335Z","iopub.execute_input":"2025-12-29T09:00:52.449521Z","iopub.status.idle":"2025-12-29T09:01:16.505648Z","shell.execute_reply.started":"2025-12-29T09:00:52.449501Z","shell.execute_reply":"2025-12-29T09:01:16.504474Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/site-packages/jax/_src/cloud_tpu_init.py:93: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"TensorFlow version: 2.20.0\nPython version: 3.12.12 (main, Dec  9 2025, 02:04:51) [GCC 14.2.0]\n\nüìÇ Paths configured:\n  Input: /kaggle/input/preprocessed-cog-eeg-dataset/processed\n  Checkpoints: /kaggle/working/checkpoints\n  Results: /kaggle/working/results\n\nüîß Configuration:\n  Model: 6 layers, 8 heads, D_MODEL=256\n  Training: 20 epochs, LR=0.0001\n  Checkpointing: every 2 epochs\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## üîå 3. TPU Initialization","metadata":{}},{"cell_type":"code","source":"\n\nimport tensorflow as tf\n\nprint(\"üîç Detecting TPU...\")\nprint(f\"TensorFlow version: {tf.__version__}\")\n\ntry:\n    # Step 1: Detect TPU\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\n    print(f\"‚úÖ TPU detected: {tpu.master()}\")\n    \n    # Step 2: Connect to cluster (CRITICAL - this was missing!)\n    tf.config.experimental_connect_to_cluster(tpu)\n    print(\"‚úÖ Connected to TPU cluster\")\n    \n    # Step 3: Initialize TPU system\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    print(\"‚úÖ TPU system initialized\")\n    \n    # Step 4: Create TPU strategy\n    strategy = tf.distribute.TPUStrategy(tpu)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"‚úÖ TPU INITIALIZED SUCCESSFULLY!\")\n    print(\"=\"*70)\n    print(f\"  TPU Address: {tpu.master()}\")\n    print(f\"  Number of replicas: {strategy.num_replicas_in_sync} üöÄ\")\n    print(\"=\"*70)\n    \n    # Set batch size for TPU\n    BATCH_SIZE_PER_REPLICA = 64\n    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n    print(f\"\\n  Batch size per replica: {BATCH_SIZE_PER_REPLICA}\")\n    print(f\"  Global batch size: {BATCH_SIZE}\")\n    \nexcept Exception as e:\n    print(f\"\\n‚ö†Ô∏è TPU initialization failed: {e}\")\n    print(\"   Falling back to CPU/GPU (slower)\")\n    print(\"\\nüí° Make sure:\")\n    print(\"   1. Accelerator is set to 'TPU VM v5e-8' in notebook settings\")\n    print(\"   2. You're running this cell FIRST before other imports\")\n    print(\"   3. Kaggle TPU is available (check quota)\")\n    \n    strategy = tf.distribute.get_strategy()\n    BATCH_SIZE_PER_REPLICA = 32\n    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n    \n    print(f\"\\n  Using fallback strategy: {strategy.__class__.__name__}\")\n    print(f\"  Batch size: {BATCH_SIZE}\")\n\nprint(\"\\n‚úÖ Strategy configured and ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T09:01:16.506410Z","iopub.execute_input":"2025-12-29T09:01:16.506786Z","iopub.status.idle":"2025-12-29T09:01:16.746393Z","shell.execute_reply.started":"2025-12-29T09:01:16.506768Z","shell.execute_reply":"2025-12-29T09:01:16.745328Z"}},"outputs":[{"name":"stdout","text":"üîç Detecting TPU...\nTensorFlow version: 2.20.0\n‚úÖ TPU detected: \n‚úÖ Connected to TPU cluster\nINFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n\n‚ö†Ô∏è TPU initialization failed: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [tpu_embedding_config=\"\", is_global_init=false, enable_whole_mesh_compilations=false, embedding_config=\"\", tpu_cancellation_closes_chips=2, compilation_failure_closes_chips=false]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]\n   Falling back to CPU/GPU (slower)\n\nüí° Make sure:\n   1. Accelerator is set to 'TPU VM v5e-8' in notebook settings\n   2. You're running this cell FIRST before other imports\n   3. Kaggle TPU is available (check quota)\n\n  Using fallback strategy: _DefaultDistributionStrategy\n  Batch size: 32\n\n‚úÖ Strategy configured and ready!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ============================================================\n# AUTO-SAVE CALLBACK (Add this BEFORE training section)\n# ============================================================\n\nclass AutoSaveCallback(tf.keras.callbacks.Callback):\n    \"\"\"Custom callback to create marker files for auto-committing\"\"\"\n    \n    def on_epoch_end(self, epoch, logs=None):\n        # Create a marker file every epoch\n        # Kaggle auto-commits when new files appear\n        marker_path = f\"/kaggle/working/progress_epoch_{epoch+1}.txt\"\n        with open(marker_path, 'w') as f:\n            f.write(f\"Completed epoch {epoch+1}/{EPOCHS}\\n\")\n            f.write(f\"Loss: {logs.get('loss', 0):.4f}\\n\")\n            f.write(f\"Val Loss: {logs.get('val_loss', 0):.4f}\\n\")\n            f.write(f\"Timestamp: {datetime.now()}\\n\")\n        \n        print(f\"  üíæ Progress saved: progress_epoch_{epoch+1}.txt\")\n\nprint(\"‚úÖ Auto-save callback ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T09:01:16.747091Z","iopub.execute_input":"2025-12-29T09:01:16.747261Z","iopub.status.idle":"2025-12-29T09:01:16.751950Z","shell.execute_reply.started":"2025-12-29T09:01:16.747245Z","shell.execute_reply":"2025-12-29T09:01:16.751092Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Auto-save callback ready!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## üìä 4. Data Loading (Compatible with Preprocessing)","metadata":{}},{"cell_type":"code","source":"def load_preprocessed_data(split='train'):\n    \"\"\"\n    Load preprocessed .pkl file (matches preprocessing output format).\n    \n    Returns:\n        Tuple of (X, y, metadata) where:\n        X = (X_eeg, X_bp, X_task)\n        y = (y_channel, y_region, y_band, y_state)\n        metadata = dict with num_channels, etc.\n    \"\"\"\n    pkl_path = os.path.join(DATA_INPUT_DIR, split, f\"{split}_data.pkl\")\n    \n    print(f\"\\nüìÅ Loading {split} data from: {pkl_path}\")\n    \n    if not os.path.exists(pkl_path):\n        print(f\"  ‚ùå File not found!\")\n        print(f\"  üí° Check that dataset is attached and DATASET_NAME is correct\")\n        return None\n    \n    # Load pickle file\n    try:\n        with open(pkl_path, 'rb') as f:\n            samples = pickle.load(f)\n        \n        print(f\"  ‚úÖ Loaded {len(samples):,} samples\")\n        \n        if len(samples) == 0:\n            print(f\"  ‚ùå No samples in file!\")\n            return None\n        \n        # Inspect first sample to get dimensions\n        sample = samples[0]\n        X_shape = sample['X'].shape  # Should be (n_channels, 256)\n        bp_shape = sample['bp'].shape  # Should be (n_channels, 5)\n        \n        num_channels = X_shape[0]\n        \n        print(f\"\\n  üìä Data format:\")\n        print(f\"     X shape: {X_shape} (channels, time)\")\n        print(f\"     bp shape: {bp_shape} (channels, bands)\")\n        print(f\"     Channels: {num_channels}\")\n        \n        # Extract arrays\n        print(f\"\\n  üîÑ Converting to arrays...\")\n        \n        # X: Transpose from (n_channels, 256) to (256, n_channels)\n        X_eeg = np.array([s['X'].T for s in samples], dtype=np.float32)\n        \n        # bp: Flatten from (n_channels, 5) to (n_channels*5,)\n        X_bp = np.array([s['bp'].flatten() for s in samples], dtype=np.float32)\n        \n        # task_idx\n        X_task = np.array([s['task_idx'] for s in samples], dtype=np.int32)\n        \n        # Labels\n        y_channel = np.array([s['y_channel'] for s in samples], dtype=np.int32)\n        y_region = np.array([s['y_region'] for s in samples], dtype=np.int32)\n        y_band = np.array([s['y_band'] for s in samples], dtype=np.int32)\n        y_state = np.array([s['y_state'] for s in samples], dtype=np.int32)\n        \n        print(f\"  ‚úÖ Final shapes:\")\n        print(f\"     X_eeg: {X_eeg.shape} (N, time, channels)\")\n        print(f\"     X_bp: {X_bp.shape} (N, features)\")\n        print(f\"     X_task: {X_task.shape}\")\n        print(f\"     Labels: {y_channel.shape} each\")\n        \n        metadata = {\n            'num_channels': num_channels,\n            'num_samples': len(samples),\n            'bandpower_dim': X_bp.shape[1]\n        }\n        \n        return (X_eeg, X_bp, X_task), (y_channel, y_region, y_band, y_state), metadata\n        \n    except Exception as e:\n        print(f\"  ‚ùå Error loading data: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None\n\nprint(\"‚úÖ Data loading function defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T09:01:16.752644Z","iopub.execute_input":"2025-12-29T09:01:16.752803Z","iopub.status.idle":"2025-12-29T09:01:16.769483Z","shell.execute_reply.started":"2025-12-29T09:01:16.752788Z","shell.execute_reply":"2025-12-29T09:01:16.768534Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Data loading function defined\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## üèóÔ∏è 5. Model Architecture (Flexible Channels)","metadata":{}},{"cell_type":"code","source":"def create_model(num_channels, bandpower_input_dim, num_output_channels):\n    \"\"\"\n    Create EEG Transformer with flexible channel dimensions.\n    \n    Args:\n        num_channels: Number of EEG channels (e.g., 58)\n        bandpower_input_dim: Bandpower feature dimension (num_channels * 5)\n        num_output_channels: Number of output classes for channel prediction\n    \"\"\"\n    # Inputs\n    eeg_input = tf.keras.Input(shape=(WINDOW_SIZE_SAMPLES, num_channels), name='eeg')\n    bp_input = tf.keras.Input(shape=(bandpower_input_dim,), name='bp')\n    task_input = tf.keras.Input(shape=(1,), dtype='int32', name='task')\n    \n    # ==================== EEG STREAM ====================\n    x = tf.keras.layers.Dense(D_MODEL, name='eeg_projection')(eeg_input)\n    \n    # Positional encoding\n    positions = tf.range(start=0, limit=WINDOW_SIZE_SAMPLES, delta=1)\n    pos_emb = tf.keras.layers.Embedding(\n        input_dim=WINDOW_SIZE_SAMPLES,\n        output_dim=D_MODEL,\n        name='positional_embedding'\n    )(positions)\n    x = x + pos_emb\n    \n    # Transformer layers\n    for i in range(NUM_LAYERS):\n        attn = tf.keras.layers.MultiHeadAttention(\n            num_heads=NUM_HEADS,\n            key_dim=D_MODEL // NUM_HEADS,\n            dropout=DROPOUT,\n            name=f'mha_{i}'\n        )(x, x)\n        x = tf.keras.layers.Add(name=f'add_attn_{i}')([x, attn])\n        x = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=f'ln_attn_{i}')(x)\n        \n        ffn = tf.keras.Sequential([\n            tf.keras.layers.Dense(FF_DIM, activation='relu'),\n            tf.keras.layers.Dense(D_MODEL),\n            tf.keras.layers.Dropout(DROPOUT)\n        ], name=f'ffn_{i}')\n        \n        ffn_out = ffn(x)\n        x = tf.keras.layers.Add(name=f'add_ffn_{i}')([x, ffn_out])\n        x = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=f'ln_ffn_{i}')(x)\n    \n    eeg_emb = tf.keras.layers.GlobalAveragePooling1D(name='eeg_pool')(x)\n    \n    # ==================== BANDPOWER STREAM ====================\n    bp_x = tf.keras.layers.Dense(BANDPOWER_HIDDEN_DIM, activation='relu', name='bp_hidden')(bp_input)\n    bp_emb = tf.keras.layers.Dense(BANDPOWER_OUTPUT_DIM, activation='relu', name='bp_output')(bp_x)\n    \n    # ==================== TASK STREAM ====================\n    task_emb = tf.keras.layers.Embedding(NUM_TASKS, TASK_EMBEDDING_DIM, name='task_emb')(task_input)\n    task_emb = tf.keras.layers.Flatten(name='task_flatten')(task_emb)\n    \n    # ==================== FUSION ====================\n    fused = tf.keras.layers.Concatenate(name='fusion')([eeg_emb, bp_emb, task_emb])\n    \n    # ==================== MULTI-TASK HEADS ====================\n    out_channel = tf.keras.layers.Dense(num_output_channels, name='channel')(fused)\n    out_region = tf.keras.layers.Dense(NUM_OUTPUT_REGIONS, name='region')(fused)\n    out_band = tf.keras.layers.Dense(NUM_OUTPUT_BANDS, name='band')(fused)\n    out_state = tf.keras.layers.Dense(NUM_OUTPUT_STATES, name='state')(fused)\n    \n    model = tf.keras.Model(\n        inputs=[eeg_input, bp_input, task_input],\n        outputs={\n            'channel': out_channel,\n            'region': out_region,\n            'band': out_band,\n            'state': out_state\n        },\n        name='CogniVue_Transformer'\n    )\n    \n    return model\n\nprint(\"‚úÖ Model architecture defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T09:01:16.769933Z","iopub.execute_input":"2025-12-29T09:01:16.770085Z","iopub.status.idle":"2025-12-29T09:01:16.785662Z","shell.execute_reply.started":"2025-12-29T09:01:16.770071Z","shell.execute_reply":"2025-12-29T09:01:16.784711Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Model architecture defined\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## üìà 6. Learning Rate Schedule","metadata":{}},{"cell_type":"code","source":"class WarmupCosineDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, initial_learning_rate, warmup_steps, total_steps):\n        super().__init__()\n        self.initial_learning_rate = initial_learning_rate\n        self.warmup_steps = warmup_steps\n        self.total_steps = total_steps\n    \n    def __call__(self, step):\n        step = tf.cast(step, tf.float32)\n        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n        total_steps = tf.cast(self.total_steps, tf.float32)\n        \n        warmup_lr = (step / warmup_steps) * self.initial_learning_rate\n        \n        decay_steps = total_steps - warmup_steps\n        decay_step = step - warmup_steps\n        cosine_decay = 0.5 * (1 + tf.cos(tf.constant(np.pi) * decay_step / decay_steps))\n        decay_lr = self.initial_learning_rate * cosine_decay\n        \n        return tf.cond(\n            step < warmup_steps,\n            lambda: warmup_lr,\n            lambda: decay_lr\n        )\n    \n    def get_config(self):\n        return {\n            \"initial_learning_rate\": self.initial_learning_rate,\n            \"warmup_steps\": self.warmup_steps,\n            \"total_steps\": self.total_steps,\n        }\n\nprint(\"‚úÖ LR schedule defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T09:01:16.786168Z","iopub.execute_input":"2025-12-29T09:01:16.786338Z","iopub.status.idle":"2025-12-29T09:01:16.800500Z","shell.execute_reply.started":"2025-12-29T09:01:16.786323Z","shell.execute_reply":"2025-12-29T09:01:16.799666Z"}},"outputs":[{"name":"stdout","text":"‚úÖ LR schedule defined\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## üîÑ 7. Data Pipeline & Callbacks","metadata":{}},{"cell_type":"code","source":"def create_tf_dataset(X, y, is_train=True):\n    dataset = tf.data.Dataset.from_tensor_slices((\n        {'eeg': X[0], 'bp': X[1], 'task': X[2]},\n        {'channel': y[0], 'region': y[1], 'band': y[2], 'state': y[3]}\n    ))\n    \n    if is_train:\n        dataset = dataset.shuffle(10000)\n    \n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    \n    return dataset\n\n\nclass PeriodicCheckpoint(tf.keras.callbacks.Callback):\n    def __init__(self, save_freq=5):\n        super().__init__()\n        self.save_freq = save_freq\n    \n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch + 1) % self.save_freq == 0:\n            filepath = os.path.join(CHECKPOINT_DIR, f\"checkpoint_epoch_{epoch+1:03d}.keras\")\n            self.model.save(filepath)\n            print(f\"\\n  üíæ Saved checkpoint: {os.path.basename(filepath)}\")\n\n\nclass LearningRateLogger(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        lr = self.model.optimizer.learning_rate\n        if hasattr(lr, '__call__'):\n            lr_value = lr(self.model.optimizer.iterations)\n        else:\n            lr_value = lr\n        lr_float = float(tf.keras.backend.get_value(lr_value))\n        if logs is not None:\n            logs['learning_rate'] = lr_float\n        print(f\"\\n  üìä LR = {lr_float:.6f}\")\n\n\nclass ProgressLogger(tf.keras.callbacks.Callback):\n    def __init__(self):\n        super().__init__()\n        self.epoch_start = None\n    \n    def on_epoch_begin(self, epoch, logs=None):\n        self.epoch_start = time.time()\n        print(f\"\\n{'='*70}\")\n        print(f\"üìÖ Epoch {epoch+1}/{EPOCHS}\")\n        print(f\"{'='*70}\")\n    \n    def on_epoch_end(self, epoch, logs=None):\n        elapsed = time.time() - self.epoch_start\n        print(f\"\\n‚úÖ Epoch {epoch+1} done in {elapsed:.1f}s\")\n        if logs:\n            print(f\"   Loss: {logs.get('loss', 0):.4f} | Val Loss: {logs.get('val_loss', 0):.4f}\")\n            print(f\"   Region Acc: {logs.get('region_accuracy', 0):.4f} | Val: {logs.get('val_region_accuracy', 0):.4f}\")\n        print(f\"{'='*70}\\n\")\n\nprint(\"‚úÖ Pipeline & callbacks defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T09:01:16.800892Z","iopub.execute_input":"2025-12-29T09:01:16.801040Z","iopub.status.idle":"2025-12-29T09:01:16.815244Z","shell.execute_reply.started":"2025-12-29T09:01:16.801026Z","shell.execute_reply":"2025-12-29T09:01:16.814329Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Pipeline & callbacks defined\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## üöÄ 8. Main Training Function","metadata":{}},{"cell_type":"code","source":"def train_cognivue():\n    print(\"\\n\" + \"=\"*70)\n    print(\"üß† CogniVue Training Pipeline\")\n    print(\"=\"*70)\n    \n    # Load ONLY training data\n    print(\"\\nüìä Loading data...\")\n    train_result = load_preprocessed_data('train')\n    \n    if train_result is None:\n        print(\"\\n‚ùå Data loading failed!\")\n        return None\n    \n    train_data, train_labels, train_meta = train_result\n    \n    # =====================================================\n    # SPLIT TRAIN DATA INTO TRAIN/VAL (80/20)\n    # =====================================================\n    print(\"\\n‚úÇÔ∏è Splitting data into train/val...\")\n    \n    num_samples = len(train_data[0])\n    indices = np.arange(num_samples)\n    np.random.seed(42)  # For reproducibility\n    np.random.shuffle(indices)\n    \n    # 80% train, 20% val\n    split_idx = int(0.8 * num_samples)\n    train_idx = indices[:split_idx]\n    val_idx = indices[split_idx:]\n    \n    # Split X data\n    train_X = (\n        train_data[0][train_idx],  # X_eeg\n        train_data[1][train_idx],  # X_bp\n        train_data[2][train_idx]   # X_task\n    )\n    val_X = (\n        train_data[0][val_idx],\n        train_data[1][val_idx],\n        train_data[2][val_idx]\n    )\n    \n    # Split y data\n    train_y = (\n        train_labels[0][train_idx],  # y_channel\n        train_labels[1][train_idx],  # y_region\n        train_labels[2][train_idx],  # y_band\n        train_labels[3][train_idx]   # y_state\n    )\n    val_y = (\n        train_labels[0][val_idx],\n        train_labels[1][val_idx],\n        train_labels[2][val_idx],\n        train_labels[3][val_idx]\n    )\n    \n    print(f\"  ‚úÖ Train samples: {len(train_idx):,}\")\n    print(f\"  ‚úÖ Val samples: {len(val_idx):,}\")\n    \n    # Get dimensions from data\n    NUM_CHANNELS = train_meta['num_channels']\n    BANDPOWER_INPUT_DIM = train_meta['bandpower_dim']\n    \n    # Determine NUM_OUTPUT_CHANNELS from labels\n    NUM_OUTPUT_CHANNELS = train_labels[0].max() + 1\n    \n    print(f\"\\nüîç Model dimensions:\")\n    print(f\"   Input channels: {NUM_CHANNELS}\")\n    print(f\"   Bandpower dim: {BANDPOWER_INPUT_DIM}\")\n    print(f\"   Output channels: {NUM_OUTPUT_CHANNELS}\")\n    \n    # Create datasets\n    print(f\"\\nüîÑ Creating TF datasets...\")\n    train_ds = create_tf_dataset(train_X, train_y, is_train=True)\n    val_ds = create_tf_dataset(val_X, val_y, is_train=False)\n    \n    steps_per_epoch = len(train_idx) // BATCH_SIZE\n    total_steps = steps_per_epoch * EPOCHS\n    warmup_steps = steps_per_epoch * WARMUP_EPOCHS\n    \n    print(f\"   Steps/epoch: {steps_per_epoch:,}\")\n    print(f\"   Total steps: {total_steps:,}\")\n    \n    # Build model\n    print(f\"\\nÔøΩÔ∏è Building model...\")\n    \n    with strategy.scope():\n        model = create_model(NUM_CHANNELS, BANDPOWER_INPUT_DIM, NUM_OUTPUT_CHANNELS)\n        \n        print(f\"   Parameters: {model.count_params():,}\")\n        \n        lr_schedule = WarmupCosineDecay(INITIAL_LR, warmup_steps, total_steps)\n        \n        optimizer = tf.keras.optimizers.AdamW(\n            learning_rate=lr_schedule,\n            weight_decay=WEIGHT_DECAY,\n            clipnorm=GRADIENT_CLIP_NORM\n        )\n        \n        loss_weights = {'channel': 0.4, 'region': 0.4, 'band': 0.1, 'state': 0.1}\n        model.compile(\n    optimizer=optimizer,\n    loss={\n        'channel': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        'region': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        'band': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        'state': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    },\n    loss_weights={\n        'channel': 0.4,\n        'region': 0.4,\n        'band': 0.1,\n        'state': 0.1\n    },\n    metrics={\n        'channel': ['accuracy'],\n        'region': ['accuracy'],\n        'band': ['accuracy'],\n        'state': ['accuracy']\n    }\n)\n    print(f\"   ‚úÖ Compiled\")\n    \n    # Callbacks\n    callbacks = [\n        ProgressLogger(),\n        LearningRateLogger(),\n        tf.keras.callbacks.ModelCheckpoint(\n            filepath=os.path.join(CHECKPOINT_DIR, 'best_model.keras'),\n            monitor='val_loss',\n            save_best_only=True,\n            verbose=1\n        ),\n        PeriodicCheckpoint(save_freq=SAVE_CHECKPOINT_EVERY),\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=EARLY_STOPPING_PATIENCE,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        tf.keras.callbacks.TensorBoard(log_dir=LOGS_DIR)\n    ]\n    \n    # Train\n    print(f\"\\nüöÄ Starting training...\")\n    print(f\"‚è∞ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n    \n    try:\n        history = model.fit(\n            train_ds,\n            epochs=EPOCHS,\n            validation_data=val_ds,\n            callbacks=callbacks,\n            verbose=1\n        )\n        \n        print(\"\\n\" + \"=\"*70)\n        print(\"‚úÖ TRAINING COMPLETE!\")\n        print(\"=\"*70)\n        print(f\"\\nüíæ Saved to: {CHECKPOINT_DIR}\")\n        \n        # Save final\n        model.save(os.path.join(CHECKPOINT_DIR, 'final_model.keras'))\n        print(f\"   - final_model.keras\")\n        print(f\"   - best_model.keras\")\n        \n        return history\n        \n    except KeyboardInterrupt:\n        print(\"\\n‚ö†Ô∏è Training interrupted!\")\n        model.save(os.path.join(CHECKPOINT_DIR, 'interrupted.keras'))\n        print(f\"   üíæ Saved: interrupted.keras\")\n        return None\n        \n    except Exception as e:\n        print(f\"\\n‚ùå Training failed: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None\n\nprint(\"‚úÖ Training function ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T09:01:16.815830Z","iopub.execute_input":"2025-12-29T09:01:16.816007Z","iopub.status.idle":"2025-12-29T09:01:16.831155Z","shell.execute_reply.started":"2025-12-29T09:01:16.815992Z","shell.execute_reply":"2025-12-29T09:01:16.830299Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Training function ready\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## ‚ñ∂Ô∏è 9. Run Training","metadata":{}},{"cell_type":"code","source":"history = train_cognivue()\n\nif history:\n    print(\"\\nüìä Training Summary:\")\n    print(f\"   Best val_loss: {min(history.history['val_loss']):.4f}\")\n    print(f\"   Final region acc: {history.history['region_accuracy'][-1]:.4f}\")\n    print(f\"\\nüí° Next: Click 'Save Version' to commit checkpoints!\")\nelse:\n    print(\"\\n‚ö†Ô∏è Training did not complete successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T09:01:16.831775Z","iopub.execute_input":"2025-12-29T09:01:16.831927Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nüß† CogniVue Training Pipeline\n======================================================================\n\nüìä Loading data...\n\nüìÅ Loading train data from: /kaggle/input/preprocessed-cog-eeg-dataset/processed/train/train_data.pkl\n  ‚úÖ Loaded 21,538 samples\n\n  üìä Data format:\n     X shape: (58, 256) (channels, time)\n     bp shape: (58, 5) (channels, bands)\n     Channels: 58\n\n  üîÑ Converting to arrays...\n  ‚úÖ Final shapes:\n     X_eeg: (21538, 256, 58) (N, time, channels)\n     X_bp: (21538, 290) (N, features)\n     X_task: (21538,)\n     Labels: (21538,) each\n\n‚úÇÔ∏è Splitting data into train/val...\n  ‚úÖ Train samples: 17,230\n  ‚úÖ Val samples: 4,308\n\nüîç Model dimensions:\n   Input channels: 58\n   Bandpower dim: 290\n   Output channels: 58\n\nüîÑ Creating TF datasets...\n   Steps/epoch: 538\n   Total steps: 10,760\n\nÔøΩÔ∏è Building model...\n   Parameters: 4,837,162\n   ‚úÖ Compiled\n\nüöÄ Starting training...\n‚è∞ 2025-12-29 09:01:31\n\n\n======================================================================\nüìÖ Epoch 1/20\n======================================================================\nEpoch 1/20\n\u001b[1m216/538\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m14:28\u001b[0m 3s/step - band_accuracy: 0.0041 - band_loss: 14.4425 - channel_accuracy: 0.0128 - channel_loss: 9.4788 - loss: 9.2571 - region_accuracy: 0.1389 - region_loss: 7.0630 - state_accuracy: 0.0077 - state_loss: 11.9611","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"10: Save Training Results & Metrics","metadata":{}},{"cell_type":"code","source":"if history:\n    print(\"\\nüìù Saving training results...\")\n    \n    # Convert history to JSON-serializable format\n    history_dict = {\n        key: [float(val) for val in values] \n        for key, values in history.history.items()\n    }\n    \n    # Save training history\n    history_path = os.path.join(RESULTS_DIR, 'training_history.json')\n    with open(history_path, 'w') as f:\n        json.dump(history_dict, f, indent=2)\n    print(f\"  ‚úÖ Saved: training_history.json\")\n    \n    # Get model dimensions from loaded data\n    train_result = load_preprocessed_data('train')\n    if train_result:\n        _, _, train_meta = train_result\n        NUM_CHANNELS_USED = train_meta['num_channels']\n    else:\n        NUM_CHANNELS_USED = \"unknown\"\n    \n    # Save training configuration\n    config = {\n        'model_architecture': {\n            'name': 'CogniVue_Transformer',\n            'num_input_channels': NUM_CHANNELS_USED,\n            'd_model': D_MODEL,\n            'num_layers': NUM_LAYERS,\n            'num_heads': NUM_HEADS,\n            'ff_dim': FF_DIM,\n            'dropout': DROPOUT,\n            'window_size': WINDOW_SIZE_SAMPLES\n        },\n        'training_params': {\n            'epochs_trained': len(history.history['loss']),\n            'total_epochs': EPOCHS,\n            'batch_size': BATCH_SIZE,\n            'initial_lr': INITIAL_LR,\n            'warmup_epochs': WARMUP_EPOCHS,\n            'weight_decay': WEIGHT_DECAY,\n            'gradient_clip_norm': GRADIENT_CLIP_NORM\n        },\n        'output_tasks': {\n            'num_output_channels': NUM_OUTPUT_REGIONS,\n            'num_regions': NUM_OUTPUT_REGIONS,\n            'num_bands': NUM_OUTPUT_BANDS,\n            'num_states': NUM_OUTPUT_STATES\n        },\n        'final_metrics': {\n            'best_val_loss': float(min(history.history['val_loss'])),\n            'final_train_loss': float(history.history['loss'][-1]),\n            'final_val_loss': float(history.history['val_loss'][-1]),\n            'final_region_accuracy': float(history.history['region_accuracy'][-1]),\n            'final_val_region_accuracy': float(history.history['val_region_accuracy'][-1])\n        },\n        'training_info': {\n            'completed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n            'tensorflow_version': tf.__version__,\n            'accelerator': 'TPU' if 'TPU' in str(strategy.__class__) else 'CPU/GPU'\n        }\n    }\n    \n    config_path = os.path.join(RESULTS_DIR, 'training_config.json')\n    with open(config_path, 'w') as f:\n        json.dump(config, f, indent=2)\n    print(f\"  ‚úÖ Saved: training_config.json\")\n    \n    # Create a summary markdown file\n    summary_md = f\"\"\"# CogniVue Training Summary\n\n**Training Completed:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n## Model Architecture\n- **Model:** CogniVue Transformer\n- **Input Channels:** {NUM_CHANNELS_USED}\n- **Model Dimension:** {D_MODEL}\n- **Transformer Layers:** {NUM_LAYERS}\n- **Attention Heads:** {NUM_HEADS}\n- **Feedforward Dim:** {FF_DIM}\n- **Dropout:** {DROPOUT}\n\n## Training Configuration\n- **Epochs:** {len(history.history['loss'])}/{EPOCHS}\n- **Batch Size:** {BATCH_SIZE}\n- **Initial LR:** {INITIAL_LR}\n- **Warmup Epochs:** {WARMUP_EPOCHS}\n- **Weight Decay:** {WEIGHT_DECAY}\n\n## Final Performance\n- **Best Val Loss:** {min(history.history['val_loss']):.4f}\n- **Final Train Loss:** {history.history['loss'][-1]:.4f}\n- **Final Val Loss:** {history.history['val_loss'][-1]:.4f}\n- **Final Region Accuracy:** {history.history['region_accuracy'][-1]:.4f}\n- **Final Val Region Accuracy:** {history.history['val_region_accuracy'][-1]:.4f}\n\n## Output Files\n- `checkpoints/best_model.keras` - Best model weights\n- `checkpoints/final_model.keras` - Final model weights\n- `checkpoints/checkpoint_epoch_*.keras` - Periodic checkpoints\n- `results/training_history.json` - Loss and metrics per epoch\n- `results/training_config.json` - Full configuration\n- `logs/` - TensorBoard logs\n\"\"\"\n    \n    summary_path = os.path.join(RESULTS_DIR, 'TRAINING_SUMMARY.md')\n    with open(summary_path, 'w') as f:\n        f.write(summary_md)\n    print(f\"  ‚úÖ Saved: TRAINING_SUMMARY.md\")\n    \n    print(\"\\n‚úÖ All results saved!\")\n    print(f\"\\nüìÇ Saved files:\")\n    print(f\"   {RESULTS_DIR}/\")\n    print(f\"   ‚îú‚îÄ‚îÄ training_history.json\")\n    print(f\"   ‚îú‚îÄ‚îÄ training_config.json\")\n    print(f\"   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\")\n    print(f\"\\n   {CHECKPOINT_DIR}/\")\n    print(f\"   ‚îú‚îÄ‚îÄ best_model.keras\")\n    print(f\"   ‚îú‚îÄ‚îÄ final_model.keras\")\n    print(f\"   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\")\n    \nelse:\n    print(\"\\n‚ö†Ô∏è No training history to save\")\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"11: Package & Download All Outputs","metadata":{}},{"cell_type":"code","source":"\n# ============================================================\n# Section 11: Package & Download All Outputs\n# ============================================================\n\nimport zipfile\nfrom pathlib import Path\n\nprint(\"\\nüì¶ Creating download package...\")\nprint(\"=\" * 70)\n\n# Create zip filename with timestamp\ntimestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\nzip_filename = f\"cognivue_training_outputs_{timestamp}.zip\"\nzip_path = os.path.join(WORKING_DIR, zip_filename)\n\ntry:\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        \n        # Add all files from results directory\n        print(\"\\nüìä Adding results...\")\n        if os.path.exists(RESULTS_DIR):\n            for file in os.listdir(RESULTS_DIR):\n                file_path = os.path.join(RESULTS_DIR, file)\n                if os.path.isfile(file_path):\n                    arcname = os.path.join('results', file)\n                    zipf.write(file_path, arcname)\n                    print(f\"  ‚úÖ {file}\")\n        \n        # Add all checkpoint files\n        print(\"\\nüîñ Adding checkpoints...\")\n        if os.path.exists(CHECKPOINT_DIR):\n            for file in os.listdir(CHECKPOINT_DIR):\n                file_path = os.path.join(CHECKPOINT_DIR, file)\n                if os.path.isfile(file_path):\n                    arcname = os.path.join('checkpoints', file)\n                    zipf.write(file_path, arcname)\n                    file_size_mb = os.path.getsize(file_path) / (1024 * 1024)\n                    print(f\"  ‚úÖ {file} ({file_size_mb:.1f} MB)\")\n        \n        # Add TensorBoard logs (optional - can be large)\n        print(\"\\nüìà Adding TensorBoard logs...\")\n        if os.path.exists(LOGS_DIR):\n            log_count = 0\n            for root, dirs, files in os.walk(LOGS_DIR):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    arcname = os.path.join('logs', os.path.relpath(file_path, LOGS_DIR))\n                    zipf.write(file_path, arcname)\n                    log_count += 1\n            print(f\"  ‚úÖ Added {log_count} log files\")\n    \n    # Get final zip size\n    zip_size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\"‚úÖ PACKAGE CREATED SUCCESSFULLY!\")\n    print(\"=\" * 70)\n    print(f\"\\nüì¶ Zip file: {zip_filename}\")\n    print(f\"üìè Size: {zip_size_mb:.1f} MB\")\n    print(f\"üìç Location: {zip_path}\")\n    \n    print(\"\\nüì• To download:\")\n    print(\"   1. Go to the 'Output' tab (top right)\")\n    print(\"   2. Click 'Save Version' to commit outputs\")\n    print(f\"   3. Download '{zip_filename}'\")\n    print(\"\\nüí° Or click the download icon next to the file in the Output tab\")\n    \n    # List contents\n    print(\"\\nüìã Package contents:\")\n    with zipfile.ZipFile(zip_path, 'r') as zipf:\n        file_list = zipf.namelist()\n        print(f\"   Total files: {len(file_list)}\")\n        print(\"\\n   Structure:\")\n        print(\"   ‚îú‚îÄ‚îÄ results/\")\n        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ training_history.json\")\n        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ training_config.json\")\n        print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\")\n        print(\"   ‚îú‚îÄ‚îÄ checkpoints/\")\n        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ best_model.keras\")\n        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ final_model.keras\")\n        print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\")\n        print(\"   ‚îî‚îÄ‚îÄ logs/\")\n        print(\"       ‚îî‚îÄ‚îÄ TensorBoard logs\")\n    \n    print(\"\\n\" + \"=\" * 70)\n    \nexcept Exception as e:\n    print(f\"\\n‚ùå Error creating zip: {e}\")\n    import traceback\n    traceback.print_exc()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}