{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14303666,"sourceType":"datasetVersion","datasetId":9130899},{"sourceId":14304760,"sourceType":"datasetVersion","datasetId":9131518},{"sourceId":14314794,"sourceType":"datasetVersion","datasetId":9138239}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/axha241419/preprocessing?scriptVersionId=288851252\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# COG-BCI Dataset Preprocessing & Windowing\n\n**Purpose**: Convert raw COG-BCI `.set` files to processed `.pkl` files ready for training.\n\nThis notebook:\n- Loads raw COG-BCI `.set` files (BIDS format)\n- **Detects and interpolates bad channels** via abnormal variance\n- Applies preprocessing (band-pass filter, notch filter, average reference, resampling)\n- Creates 1-second windows with 0.25s hop\n- **Rejects artifact-contaminated windows** via amplitude thresholding\n- Computes band-power features (delta, theta, alpha, beta, gamma)\n- Computes **next-second labels** for prediction tasks\n- Performs subject-wise train/val/test splits\n- Computes and saves training normalization statistics\n- Saves processed data as `.pkl` files for training pipeline","metadata":{}},{"cell_type":"markdown","source":"## 1. Install Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install mne pandas scipy numpy\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Configuration","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport pickle\nimport numpy as np\nimport pandas as pd\n\n\n# -------- NumPy compatibility patches - MUST run BEFORE importing MNE --------\n# Patch 1: np.trapz (removed in NumPy 2.0)\nif not hasattr(np, \"trapz\"):\n    def _trapz(y, x=None, dx=1.0, axis=-1):\n        y = np.asarray(y)\n        if x is None:\n            return dx * (y[..., 1:] + y[..., :-1]).sum(axis=axis) / 2.0\n        else:\n            x = np.asarray(x)\n            dx = np.diff(x, axis=axis)\n            return (dx * (y[..., 1:] + y[..., :-1]) / 2.0).sum(axis=axis)\n    np.trapz = _trapz\n\n# Patch 2: np.in1d (removed in NumPy 2.0, replaced by np.isin)\nif not hasattr(np, \"in1d\"):\n    def _in1d(ar1, ar2, assume_unique=False, invert=False):\n        return np.isin(ar1, ar2, assume_unique=assume_unique, invert=invert)\n    np.in1d = _in1d\n\n# NOW import MNE and scipy\nimport mne\nfrom scipy.signal import welch\n\n\n# Configuration\n# Point to all three dataset directories\nRAW_DATA_DIRS = [\n    \"/kaggle/input/cognivue-raw-data\",\n    \"/kaggle/input/cog-eeg-dataset\",\n    \"/kaggle/input/cog-eeg-dataset-3\"\n]\n\nprint(\"Dataset directories:\")\nfor d in RAW_DATA_DIRS:\n    print(f\"  - {d}\")\n    \nSUBJECT_SPLITS_CSV = \"/kaggle/input/cog-config/subject_splits.csv\"\n\nPROCESSED_DIR = \"/kaggle/working/data/processed\"\nos.makedirs(PROCESSED_DIR, exist_ok=True)\nfor split in [\"train\", \"val\", \"test\"]:\n    os.makedirs(os.path.join(PROCESSED_DIR, split), exist_ok=True)\nDONE_FLAGS_DIR = os.path.join(PROCESSED_DIR, \"done_flags\")\nos.makedirs(DONE_FLAGS_DIR, exist_ok=True)\n\nTRAIN_STATS_PATH = os.path.join(PROCESSED_DIR, \"train_stats.json\")\n\n# --- SAMPLING & WINDOWING ---\nRAW_SAMPLING_RATE = 512\nPROCESSED_SAMPLING_RATE = 256\nWINDOW_SIZE_SEC = 1.0\nHOP_SIZE_SEC = 0.25\nWINDOW_SIZE_SAMPLES = int(WINDOW_SIZE_SEC * PROCESSED_SAMPLING_RATE)  # 256\nHOP_SIZE_SAMPLES = int(HOP_SIZE_SEC * PROCESSED_SAMPLING_RATE)        # 64\n\nNUM_CHANNELS = 58\n\n# --- ARTIFACT REJECTION & BAD CHANNEL THRESHOLDS ---\nARTIFACT_THRESHOLD_UV = 100.0  # Microvolts - reject windows exceeding this amplitude\nBAD_CHANNEL_STD_THRESHOLD = 5.0  # Standard deviations from mean variance for bad channel detection\n\n# --- FREQUENCY BANDS ---\nFREQUENCY_BANDS = {\n    \"delta\": (1, 4),\n    \"theta\": (4, 8),\n    \"alpha\": (8, 13),\n    \"beta\":  (13, 30),\n    \"gamma\": (30, 45),\n}\n\n# --- TASK ID MAPPING (BIDS task labels) ---\nTASK_NAME_TO_ID = {\n    \"nback\": 0,\n    \"matb\": 1,\n    \"pvt\":  2,\n    \"flanker\": 3,\n}\n\n# --- CHANNEL -> REGION MAP ---\nCHANNEL_TO_REGION = {\n    \"Fp1\": \"frontal\", \"Fp2\": \"frontal\", \"AF3\": \"frontal\", \"AF4\": \"frontal\",\n    \"AF7\": \"frontal\", \"AF8\": \"frontal\", \"F1\": \"frontal\", \"F2\": \"frontal\",\n    \"F3\": \"frontal\", \"F4\": \"frontal\", \"F5\": \"frontal\", \"F6\": \"frontal\",\n    \"F7\": \"frontal\", \"F8\": \"frontal\", \"Fz\": \"fronto-central\", \"FC1\": \"fronto-central\",\n    \"FC2\": \"fronto-central\", \"FC3\": \"fronto-central\", \"FC4\": \"fronto-central\",\n    \"FC5\": \"fronto-central\", \"FC6\": \"fronto-central\", \"FCz\": \"fronto-central\",\n    \"C1\": \"central\", \"C2\": \"central\", \"C3\": \"central\", \"C4\": \"central\",\n    \"C5\": \"central\", \"C6\": \"central\", \"Cz\": \"central\", \"T7\": \"temporal-left\",\n    \"TP7\": \"temporal-left\", \"FT7\": \"temporal-left\", \"T8\": \"temporal-right\",\n    \"TP8\": \"temporal-right\", \"FT8\": \"temporal-right\", \"CP1\": \"parietal\",\n    \"CP2\": \"parietal\", \"CP3\": \"parietal\", \"CP4\": \"parietal\", \"CP5\": \"parietal\",\n    \"CP6\": \"parietal\", \"CPz\": \"parietal\", \"P1\": \"parietal\", \"P2\": \"parietal\",\n    \"P3\": \"parietal\", \"P4\": \"parietal\", \"P5\": \"parietal\", \"P6\": \"parietal\",\n    \"P7\": \"parietal\", \"P8\": \"parietal\", \"Pz\": \"parietal\", \"PO3\": \"parietal\",\n    \"PO4\": \"parietal\", \"PO7\": \"parietal\", \"PO8\": \"parietal\", \"POz\": \"parietal\",\n    \"O1\": \"occipital\", \"O2\": \"occipital\", \"Oz\": \"occipital\",\n}\n\nREGIONS = {\n    \"frontal\": 0, \"fronto-central\": 1, \"central\": 2,\n    \"temporal-left\": 3, \"temporal-right\": 4,\n    \"parietal\": 5, \"occipital\": 6,\n}\n\nCHANNEL_TO_REGION_ID = {ch: REGIONS.get(reg, 0) for ch, reg in CHANNEL_TO_REGION.items()}\nCHANNEL_NAMES = list(CHANNEL_TO_REGION.keys())\nCHANNEL_INDEX = {ch: i for i, ch in enumerate(CHANNEL_NAMES)}\n\nprint(f\"Configuration loaded:\")\nprint(f\"  - Artifact threshold: {ARTIFACT_THRESHOLD_UV} ¬µV\")\nprint(f\"  - Bad channel detection: {BAD_CHANNEL_STD_THRESHOLD} std from mean variance\")\nprint(f\"  - Window size: {WINDOW_SIZE_SEC}s ({WINDOW_SIZE_SAMPLES} samples)\")\nprint(f\"  - Hop size: {HOP_SIZE_SEC}s ({HOP_SIZE_SAMPLES} samples)\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## 2.5 Performance Optimization\n\n# Enable parallel processing\nimport os\nos.environ['MNE_LOGGING_LEVEL'] = 'WARNING'  # Reduce logging overhead\nos.environ['OMP_NUM_THREADS'] = '4'  # OpenMP threads\nos.environ['MKL_NUM_THREADS'] = '4'  # Intel MKL threads\n\n# Use all available CPU cores\nN_JOBS = -1  # -1 = use all available cores (4 on Kaggle CPU)\n\nprint(f\"Parallel processing enabled: using {os.cpu_count()} CPU cores\")\nprint(f\"MNE will use n_jobs={N_JOBS} for filtering and resampling\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Subject Split Loading","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def load_subject_splits(csv_path):\n    \"\"\"\n    CSV format:\n    subject_id,split\n    sub-01,train\n    sub-02,train\n    ...\n    sub-26,test\n    \"\"\"\n    df = pd.read_csv(csv_path)\n    mapping = {}\n    for _, row in df.iterrows():\n        mapping[row[\"subject_id\"]] = row[\"split\"]  # \"train\" / \"val\" / \"test\"\n    return mapping\n\nSUBJECT_SPLITS = load_subject_splits(SUBJECT_SPLITS_CSV)\nprint(\"Subject splits:\", SUBJECT_SPLITS)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Preprocessing Functions","metadata":{}},{"cell_type":"code","source":"def detect_and_interpolate_bad_channels(raw):\n    \"\"\"\n    Detect bad channels via abnormal variance and interpolate from neighbors.\n    Returns the Raw object with bad channels interpolated.\n    \"\"\"\n    # Get data for variance calculation\n    data = raw.get_data(picks='eeg')\n    \n    # Compute variance per channel\n    variances = np.var(data, axis=1)\n    \n    # Find outliers (channels with variance > threshold * std from mean)\n    mean_var = np.mean(variances)\n    std_var = np.std(variances)\n    threshold = mean_var + BAD_CHANNEL_STD_THRESHOLD * std_var\n    \n    bad_indices = np.where(variances > threshold)[0]\n    \n    if len(bad_indices) > 0:\n        bad_ch_names = [raw.ch_names[i] for i in bad_indices]\n        print(f\"  Detected {len(bad_ch_names)} bad channels: {bad_ch_names}\")\n        raw.info['bads'] = bad_ch_names\n        raw.interpolate_bads(reset_bads=True, verbose=False)\n    \n    return raw\n\ndef preprocess_raw(raw):\n    \"\"\"\n    Band-pass 1‚Äì40, notch at 60/120/180, detect/interpolate bad channels,\n    average reference, resample 512‚Üí256.\n    **OPTIMIZED with parallel processing**\n    \"\"\"\n    # Apply filters first (OPTIMIZED - added n_jobs)\n    raw.filter(l_freq=1, h_freq=40, method=\"fir\", phase=\"zero\", \n               n_jobs=N_JOBS, verbose=False)\n    raw.notch_filter(freqs=[60, 120, 180], n_jobs=N_JOBS, verbose=False)\n    \n    # Detect and interpolate bad channels\n    raw = detect_and_interpolate_bad_channels(raw)\n    \n    # Apply average reference and resample (OPTIMIZED - added n_jobs)\n    raw.set_eeg_reference(\"average\", projection=False, verbose=False)\n    if raw.info[\"sfreq\"] != PROCESSED_SAMPLING_RATE:\n        raw.resample(PROCESSED_SAMPLING_RATE, n_jobs=N_JOBS, verbose=False)\n    return raw\n\ndef compute_bandpower(window_data, sfreq):\n    \"\"\"\n    window_data: shape (n_channels, n_samples) in volts\n    returns: (n_channels, 5) log-power features\n    \"\"\"\n    n_channels, n_samples = window_data.shape\n    bp_features = np.zeros((n_channels, len(FREQUENCY_BANDS)), dtype=np.float32)\n\n    for ch in range(n_channels):\n        # If this channel is all zeros or NaNs, give default low power\n        if not np.any(np.isfinite(window_data[ch])) or not np.any(window_data[ch]):\n            bp_features[ch, :] = -10.0\n            continue\n\n        freqs, psd = welch(window_data[ch], fs=sfreq, nperseg=n_samples)\n\n        # Clean PSD: remove NaNs and negatives\n        psd = np.nan_to_num(psd, nan=0.0)\n        psd[psd < 0] = 0.0\n\n        for i, (band, (low, high)) in enumerate(FREQUENCY_BANDS.items()):\n            idx = np.logical_and(freqs >= low, freqs <= high)\n\n            # If no freq in band, use default value\n            if not np.any(idx):\n                bp_features[ch, i] = -10.0\n                continue\n\n            band_vals = psd[idx]\n\n            # If all zero after masking, avoid log10(0)\n            if not np.any(band_vals):\n                bp_features[ch, i] = -10.0\n                continue\n\n            mean_psd = float(np.mean(band_vals))\n            bp_features[ch, i] = np.log10(mean_psd + 1e-10).astype(np.float32)\n\n    return bp_features\n\ndef compute_dominant_labels(bandpower, channel_names):\n    \"\"\"\n    bandpower: (n_channels, 5) for one window\n    channel_names: list of actual channel names in this recording\n    returns: dict with y_channel, y_region, y_band, y_state\n    \"\"\"\n    total_power_ch = np.sum(bandpower, axis=1)       # over bands\n    dom_ch_idx = int(np.argmax(total_power_ch))\n    \n    # Get the actual channel name from the available channels\n    if dom_ch_idx < len(channel_names):\n        dom_ch_name = channel_names[dom_ch_idx]\n        region_id = CHANNEL_TO_REGION_ID.get(dom_ch_name, 0)\n    else:\n        dom_ch_name = channel_names[0] if channel_names else \"unknown\"\n        region_id = 0\n\n    total_power_band = np.sum(bandpower, axis=0)     # over channels\n    dom_band_idx = int(np.argmax(total_power_band))\n\n    theta = float(total_power_band[1])\n    alpha = float(total_power_band[2])\n    beta  = float(total_power_band[3])\n    delta = float(total_power_band[0])\n\n    state_id = 3  # neutral\n    if alpha > 1e-10:\n        ratio_theta_alpha = theta / alpha\n        ratio_beta_alpha = beta / alpha\n        if (1.0 <= ratio_theta_alpha <= 1.5) and (ratio_beta_alpha > 1.2):\n            state_id = 0  # Focused\n        elif ratio_theta_alpha > 1.5:\n            state_id = 1  # Drift\n        elif (delta + theta) > 2 * alpha:\n            state_id = 2  # Drowsy\n\n    return {\n        \"y_channel\": dom_ch_idx,\n        \"y_region\": region_id,\n        \"y_band\": dom_band_idx,\n        \"y_state\": state_id,\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Window Creation with Artifact Rejection & Next-Second Labels","metadata":{}},{"cell_type":"code","source":" def create_windows_from_raw(raw, task_id, subject_id, split_name):\n    \"\"\"\n    raw: preprocessed MNE Raw, sfreq=256, EEG channels\n    task_id: int\n    split_name: \"train\"/\"val\"/\"test\"\n\n    Returns list of sample dicts:\n    {\n        \"X\":   np.array (n_channels, 256) raw window\n        \"bp\":  np.array (n_channels, 5) bandpower for same window\n        \"task_idx\": int\n        y_channel, y_region, y_band, y_state from NEXT window\n    }\n    \"\"\"\n    data = raw.get_data(picks=\"eeg\")  # (n_channels, n_samples)\n    n_channels, n_samples = data.shape\n    channel_names = [ch for ch in raw.ch_names if ch in CHANNEL_TO_REGION]\n\n    samples = []\n    artifacts_rejected = 0\n    bad_bp_rejected = 0\n    start = 0\n\n    while start + WINDOW_SIZE_SAMPLES * 2 <= n_samples:\n        # current window [t, t+1]\n        w_cur = data[:, start: start + WINDOW_SIZE_SAMPLES]\n        # next window [t+1, t+2] for labels\n        w_next = data[:, start + WINDOW_SIZE_SAMPLES: start + 2 * WINDOW_SIZE_SAMPLES]\n\n        # 1) Artifact rejection (amplitude)\n        max_amplitude_uv = np.abs(w_cur).max() * 1e6\n        if max_amplitude_uv > ARTIFACT_THRESHOLD_UV:\n            artifacts_rejected += 1\n            start += HOP_SIZE_SAMPLES\n            continue\n\n        # 2) Bandpower computation with safety\n        bp_cur = compute_bandpower(w_cur, PROCESSED_SAMPLING_RATE).astype(np.float32)\n        bp_next = compute_bandpower(w_next, PROCESSED_SAMPLING_RATE)\n\n        # If bandpower is completely default (all -10) for either window, skip\n        if not np.any(bp_cur > -9.9) or not np.any(bp_next > -9.9):\n            bad_bp_rejected += 1\n            start += HOP_SIZE_SAMPLES\n            continue\n\n        # 3) Labels from next window\n        labels = compute_dominant_labels(bp_next, channel_names)\n\n        sample = {\n            \"X\": w_cur.astype(np.float32),  # (n_channels, 256)\n            \"bp\": bp_cur,\n            \"task_idx\": int(task_id),\n            \"y_channel\": labels[\"y_channel\"],\n            \"y_region\": labels[\"y_region\"],\n            \"y_band\": labels[\"y_band\"],\n            \"y_state\": labels[\"y_state\"],\n            \"subject_id\": subject_id,\n            \"split\": split_name,\n            \"n_channels\": n_channels,\n            \"channel_names\": channel_names,\n        }\n        samples.append(sample)\n\n        start += HOP_SIZE_SAMPLES\n\n    if artifacts_rejected > 0:\n        print(f\" Rejected {artifacts_rejected} artifact-contaminated windows\")\n    if bad_bp_rejected > 0:\n        print(f\" Rejected {bad_bp_rejected} windows due to invalid bandpower\")\n\n    return samples\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Scan Raw Files (BIDS) and Process All Subjects","metadata":{}},{"cell_type":"code","source":"def parse_bids_info_from_path(path):\n    \"\"\"\n    Your paths look like:\n      /kaggle/input/cog-eeg-dataset-3/sub-21/ses-S1/eeg/zeroBACK.set\n      /kaggle/input/cog-eeg-dataset-3/sub-21/ses-S1/eeg/MATBeasy.set\n      /kaggle/input/cog-eeg-dataset-3/sub-21/ses-S1/eeg/Flanker.set\n      /kaggle/input/cog-eeg-dataset-3/sub-21/ses-S1/eeg/PVT.set\n    etc.\n\n    Returns:\n      subject_id: \"sub-21\"\n      task_name: one of \"nback\", \"matb\", \"flanker\", \"pvt\"\n                 (used with TASK_NAME_TO_ID)\n    \"\"\"\n    parts = path.split(os.sep)\n\n    # subject folder: first part that starts with \"sub-\"\n    subject_id = next(p for p in parts if p.startswith(\"sub-\"))\n\n    # file name without extension, e.g. \"zeroBACK\", \"MATBeasy\", \"Flanker\"\n    fname = os.path.splitext(os.path.basename(path))[0]\n    task_lower = fname.lower()\n\n    # Map your filenames to the 4 task families\n    if \"back\" in task_lower:          # zeroBACK / oneBACK / twoBACK\n        task_name = \"nback\"\n    elif \"matb\" in task_lower:        # MATBeasy / MATBmed / MATBdiff\n        task_name = \"matb\"\n    elif \"flanker\" in task_lower:\n        task_name = \"flanker\"\n    elif \"pvt\" in task_lower:\n        task_name = \"pvt\"\n    else:\n        # Unknown task; caller will skip this file\n        task_name = None\n\n    return subject_id, task_name\n\ndef find_all_eeg_files(raw_dirs):\n    \"\"\"\n    Scan multiple directories for .set files\n    raw_dirs: list of directory paths\n    \"\"\"\n    all_files = []\n    for raw_dir in raw_dirs:\n        pattern = os.path.join(raw_dir, \"**\", \"*.set\")\n        files = glob.glob(pattern, recursive=True)\n        all_files.extend(files)\n        print(f\"  Found {len(files)} files in {os.path.basename(raw_dir)}\")\n    return all_files\n\n# Call with list of directories\nall_files = find_all_eeg_files(RAW_DATA_DIRS)\nprint(f\"\\nTotal EEG files across all datasets: {len(all_files)}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. First Pass: Build All Samples in Memory to Compute Train Mean/Std","metadata":{}},{"cell_type":"code","source":"\n#  First Pass with Progress Tracking (RESUMABLE)\n\n\nfrom tqdm import tqdm\nimport time\n\nall_samples = []\nskipped_files = []\nprocessing_stats = {\n    'total_files': len(all_files),\n    'processed': 0,\n    'skipped': 0,\n    'total_windows': 0,\n    'start_time': time.time()\n}\n\nprint(f\"Processing {len(all_files)} files...\\n\")\n\nfor idx, path in enumerate(tqdm(all_files, desc=\"Processing files\")):\n    subject_id, task_name = parse_bids_info_from_path(path)\n\n    # ---------- per-file checkpoint ----------\n    flag_name = f\"{os.path.basename(path).replace('.set','')}_{subject_id}.done\"\n    flag_path = os.path.join(DONE_FLAGS_DIR, flag_name)\n    if os.path.exists(flag_path):\n        # already successfully processed in a previous run\n        continue\n    # ----------------------------------------\n\n    if subject_id not in SUBJECT_SPLITS:\n        skipped_files.append({'path': path, 'subject': subject_id, 'reason': 'not_in_splits'})\n        processing_stats['skipped'] += 1\n        continue\n\n    split_name = SUBJECT_SPLITS[subject_id]\n\n    if task_name is None or task_name not in TASK_NAME_TO_ID:\n        skipped_files.append({'path': path, 'subject': subject_id, 'reason': 'unknown_task'})\n        processing_stats['skipped'] += 1\n        continue\n\n    task_id = TASK_NAME_TO_ID[task_name]\n\n    # Only print every 10th file to reduce clutter\n    if idx % 10 == 0:\n        print(f\"\\n[{idx+1}/{len(all_files)}] {os.path.basename(path)} | {subject_id} | {task_name} | {split_name}\")\n\n    try:\n        raw = mne.io.read_raw_eeglab(path, preload=True, verbose=False)\n\n        available_channels = [ch for ch in CHANNEL_NAMES if ch in raw.ch_names]\n        missing_channels = [ch for ch in CHANNEL_NAMES if ch not in raw.ch_names]\n\n        if len(available_channels) < 50:\n            skipped_files.append({\n                'path': path,\n                'subject': subject_id,\n                'reason': f'insufficient_channels_{len(available_channels)}'\n            })\n            processing_stats['skipped'] += 1\n            continue\n\n        raw.pick(available_channels)\n        raw = preprocess_raw(raw)\n        subject_samples = create_windows_from_raw(raw, task_id, subject_id, split_name)\n        all_samples.extend(subject_samples)\n\n        processing_stats['processed'] += 1\n        processing_stats['total_windows'] += len(subject_samples)\n\n        # mark this file as successfully processed\n        with open(flag_path, \"w\") as f:\n            f.write(str(len(subject_samples)))\n\n        # Print summary every 10 files\n        if idx % 10 == 0:\n            elapsed = time.time() - processing_stats['start_time']\n            rate = processing_stats['processed'] / elapsed if elapsed > 0 else 0\n            print(f\" ‚úì {len(subject_samples)} windows | Total: {processing_stats['total_windows']} | Rate: {rate:.2f} files/sec\")\n\n    except Exception as e:\n        print(f\" ‚úó ERROR: {str(e)[:80]}\")\n        skipped_files.append({'path': path, 'subject': subject_id, 'reason': str(e)[:100]})\n        processing_stats['skipped'] += 1\n        continue\n\n# Final summary\nelapsed_total = time.time() - processing_stats['start_time']\nprint(f\"\\n{'='*70}\")\nprint(\"PROCESSING COMPLETE\")\nprint(f\" Total time: {elapsed_total/60:.1f} minutes ({elapsed_total:.0f} seconds)\")\nprint(f\" Files processed: {processing_stats['processed']}/{processing_stats['total_files']}\")\nprint(f\" Files skipped: {processing_stats['skipped']}\")\nprint(f\" Total windows generated: {processing_stats['total_windows']}\")\nif processing_stats['processed'] > 0:\n    print(f\" Average rate: {processing_stats['processed']/elapsed_total:.2f} files/sec\")\n    print(f\" Average time per file: {elapsed_total/processing_stats['processed']:.1f} seconds\")\nprint(f\"{'='*70}\\n\")\n\nif len(skipped_files) > 0:\n    print(\"Skipped files breakdown:\")\n    skip_reasons = {}\n    for sf in skipped_files:\n        reason = sf['reason'].split('_')[0]\n        skip_reasons[reason] = skip_reasons.get(reason, 0) + 1\n    for reason, count in skip_reasons.items():\n        print(f\" - {reason}: {count} files\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## for debugging","metadata":{}},{"cell_type":"code","source":"\"\"\"# DEBUG: inspect shapes of all TRAIN windows\ntrain_windows = [s[\"X\"] for s in all_samples if s[\"split\"] == \"train\"]\nprint(\"Total train windows:\", len(train_windows))\n\nshape_counts = {}\nfor w in train_windows:\n    shape_counts[w.shape] = shape_counts.get(w.shape, 0) + 1\n\nprint(\"Unique shapes and counts:\")\nfor shp, cnt in shape_counts.items():\n    print(f\"  {shp}: {cnt}\")\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"print(\"Total samples in all_samples:\", len(all_samples))\nprint(\"Train samples:\", sum(1 for s in all_samples if s[\"split\"] == \"train\"))\nprint(\"Val samples:\",   sum(1 for s in all_samples if s[\"split\"] == \"val\"))\nprint(\"Test samples:\",  sum(1 for s in all_samples if s[\"split\"] == \"test\"))\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Compute Train-Set Mean / Std Per Channel ","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# SECTION 8: Compute Train-Set Mean / Std Per Channel\n# ============================================================================\n\nimport json\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"SECTION 8: COMPUTING TRAIN STATISTICS\")\nprint(\"=\"*70)\n\n# Check what we have in all_samples\ntrain_count = sum(1 for s in all_samples if s[\"split\"] == \"train\")\nval_count = sum(1 for s in all_samples if s[\"split\"] == \"val\")\ntest_count = sum(1 for s in all_samples if s[\"split\"] == \"test\")\n\nprint(f\"\\nTotal windows collected:\")\nprint(f\"  Train: {train_count:,}\")\nprint(f\"  Val:   {val_count:,}\")\nprint(f\"  Test:  {test_count:,}\")\nprint(f\"  TOTAL: {len(all_samples):,}\\n\")\n\nif train_count == 0:\n    raise RuntimeError(\n        \"No training samples found! Check that subjects 01-20 are being processed.\"\n    )\n\n# Extract training windows\nprint(\"Computing statistics from training data...\")\ntrain_windows = [s[\"X\"] for s in all_samples if s[\"split\"] == \"train\"]\n\n# Filter by expected shape\nEXPECTED_SHAPE = (NUM_CHANNELS, WINDOW_SIZE_SAMPLES)\nfiltered_train_windows = [w for w in train_windows if w.shape == EXPECTED_SHAPE]\ndropped = len(train_windows) - len(filtered_train_windows)\n\nprint(f\"  Using {len(filtered_train_windows):,} windows for statistics\")\nif dropped > 0:\n    print(f\"  Dropped {dropped} windows with incorrect shape\")\n\nif len(filtered_train_windows) == 0:\n    raise RuntimeError(\n        f\"No train windows with expected shape {EXPECTED_SHAPE}. \"\n        f\"Check NUM_CHANNELS={NUM_CHANNELS} and WINDOW_SIZE_SAMPLES={WINDOW_SIZE_SAMPLES}\"\n    )\n\n# Stack windows: (N, n_channels, 256)\ntrain_windows_np = np.stack(filtered_train_windows, axis=0)\nprint(f\"  Stacked shape: {train_windows_np.shape}\")\n\n# Flatten time dimension: (n_channels, N*256)\nflat = train_windows_np.transpose(1, 0, 2).reshape(train_windows_np.shape[1], -1)\n\n# Compute statistics\ntrain_mean = flat.mean(axis=1).astype(np.float32)\ntrain_std = flat.std(axis=1).astype(np.float32)\ntrain_std[train_std < 1e-6] = 1.0  # Avoid division by zero\n\nprint(f\"  ‚úì Computed mean shape: {train_mean.shape}\")\nprint(f\"  ‚úì Computed std shape: {train_std.shape}\")\n\n# Save stats\nstats = {\n    \"channel_names\": CHANNEL_NAMES,\n    \"mean\": train_mean.tolist(),\n    \"std\": train_std.tolist(),\n}\nwith open(TRAIN_STATS_PATH, \"w\") as f:\n    json.dump(stats, f)\n\nprint(f\"  ‚úì Saved stats to: {TRAIN_STATS_PATH}\")\nprint(\"=\"*70 + \"\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9. Apply Normalization and Save Split-Wise PKL Files","metadata":{}},{"cell_type":"code","source":"def normalize_window(window, mean, std):\n    \"\"\"\n    window: (n_channels, 256)\n    mean/std: (n_channels,)\n    z-score per channel\n    \"\"\"\n    n_ch = window.shape[0]\n    return (window - mean[:n_ch, None]) / std[:n_ch, None]\n\n\nsplit_samples = {\"train\": [], \"val\": [], \"test\": []}\n\nEXPECTED_CHANNELS = train_mean.shape[0]  # should be 58\nskipped_bad_shape = 0\n\nfor s in all_samples:\n    w = s[\"X\"]  # (n_channels, 256)\n\n    # Skip windows whose channel count does not match the stats\n    if w.shape[0] != EXPECTED_CHANNELS:\n        skipped_bad_shape += 1\n        continue\n\n    norm_w = normalize_window(w, train_mean, train_std).astype(np.float32)\n    s[\"X\"] = norm_w\n    split_samples[s[\"split\"]].append(s)\n\nprint(f\"Kept {sum(len(v) for v in split_samples.values())} samples after normalization; \"\n      f\"skipped {skipped_bad_shape} with mismatched channels.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# 10. FINAL STEP: SAVE PROCESSED SAMPLES TO PKL FILES","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# SECTION 10: SAVE PROCESSED SAMPLES TO .PKL FILES\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"SAVING PROCESSED SAMPLES\")\nprint(\"=\"*70)\n\nfor split_name in [\"train\", \"val\", \"test\"]:\n    samples = split_samples.get(split_name, [])\n    \n    if len(samples) == 0:\n        print(f\"\\n‚ö†Ô∏è  {split_name.upper()}: No samples found - SKIPPING\")\n        continue\n    \n    # Create output directory\n    output_dir = os.path.join(PROCESSED_DIR, split_name)\n    os.makedirs(output_dir, exist_ok=True)\n    output_path = os.path.join(output_dir, f\"{split_name}_data.pkl\")\n    \n    # Save to pickle\n    print(f\"\\nüì¶ {split_name.upper()}:\")\n    print(f\"   Saving {len(samples):,} samples...\")\n    \n    with open(output_path, \"wb\") as f:\n        pickle.dump(samples, f)\n    \n    file_size_mb = os.path.getsize(output_path) / (1024 * 1024)\n    \n    print(f\"   ‚úì Saved successfully\")\n    print(f\"   ‚úì File: {output_path}\")\n    print(f\"   ‚úì Size: {file_size_mb:.2f} MB\")\n    \n    # Show sample info\n    if len(samples) > 0:\n        sample = samples[0]\n        print(f\"   ‚úì Sample format:\")\n        print(f\"      - X shape: {sample['X'].shape} (normalized EEG)\")\n        print(f\"      - bp shape: {sample['bp'].shape} (bandpower features)\")\n        print(f\"      - Subjects: {len(set(s['subject_id'] for s in samples))} unique\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚úÖ PROCESSING COMPLETE!\")\nprint(\"=\"*70)\n\n# Final summary\ntotal_samples = sum(len(v) for v in split_samples.values())\nprint(f\"\\nüìä FINAL SUMMARY:\")\nprint(f\"   Total samples: {total_samples:,}\")\nprint(f\"   Train samples: {len(split_samples.get('train', [])):,}\")\nprint(f\"   Val samples: {len(split_samples.get('val', [])):,}\")\nprint(f\"   Test samples: {len(split_samples.get('test', [])):,}\")\nprint(f\"\\nüìÅ Output files saved to: {PROCESSED_DIR}\")\nprint(f\"   - train_data.pkl\")\nprint(f\"   - val_data.pkl\")\nprint(f\"   - test_data.pkl\")\nprint(f\"   - train_stats.json\")\nprint(\"\\n‚úì Ready to download from Kaggle Output!\")\nprint(\"=\"*70 + \"\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 11. Verification","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# SECTION 11: FINAL VERIFICATION\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"VERIFICATION CHECK\")\nprint(\"=\"*70)\n\nverification_passed = True\n\n# Check train_stats.json\nprint(\"\\n1. Train Statistics:\")\nif os.path.exists(TRAIN_STATS_PATH):\n    size_kb = os.path.getsize(TRAIN_STATS_PATH) / 1024\n    print(f\"   ‚úì train_stats.json exists ({size_kb:.2f} KB)\")\nelse:\n    print(f\"   ‚úó train_stats.json MISSING!\")\n    verification_passed = False\n\n# Check .pkl files\nprint(\"\\n2. Processed Data Files:\")\nfor split_name in [\"train\", \"val\", \"test\"]:\n    pkl_path = os.path.join(PROCESSED_DIR, split_name, f\"{split_name}_data.pkl\")\n    if os.path.exists(pkl_path):\n        size_mb = os.path.getsize(pkl_path) / (1024*1024)\n        print(f\"   ‚úì {split_name}_data.pkl exists ({size_mb:.2f} MB)\")\n    else:\n        print(f\"   ‚úó {split_name}_data.pkl MISSING!\")\n        verification_passed = False\n\n# Check done flags\nprint(\"\\n3. Processing Flags:\")\ndone_count = len(glob.glob(os.path.join(DONE_FLAGS_DIR, \"*.done\")))\nprint(f\"   ‚úì {done_count} files marked as processed\")\n\nprint(\"\\n\" + \"=\"*70)\nif verification_passed:\n    print(\"‚úÖ‚úÖ‚úÖ ALL CHECKS PASSED - READY TO DOWNLOAD! ‚úÖ‚úÖ‚úÖ\")\nelse:\n    print(\"‚ùå‚ùå‚ùå VERIFICATION FAILED - CHECK ERRORS ABOVE ‚ùå‚ùå‚ùå\")\nprint(\"=\"*70 + \"\\n\")\n```\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}