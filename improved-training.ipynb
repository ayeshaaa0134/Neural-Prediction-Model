{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047b24f7",
   "metadata": {
    "papermill": {
     "duration": 0.004499,
     "end_time": "2025-12-30T13:25:46.202120",
     "exception": false,
     "start_time": "2025-12-30T13:25:46.197621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  CogniVue: Training\n",
    "\n",
    "** FULLY COMPATIBLE with your preprocessing notebook!**\n",
    "\n",
    "This notebook:\n",
    "-  Loads data from single `.pkl` files per split\n",
    "-  Handles variable channel count (typically 58 channels)\n",
    "-  Correctly transposes X from `(n_ch, 256)` to `(256, n_ch)`\n",
    "-  Robust checkpointing and error handling\n",
    "-  Resume training from interruptions\n",
    "-  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd5a5f8",
   "metadata": {
    "papermill": {
     "duration": 0.003343,
     "end_time": "2025-12-30T13:25:46.209208",
     "exception": false,
     "start_time": "2025-12-30T13:25:46.205865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "226badb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T13:25:46.217061Z",
     "iopub.status.busy": "2025-12-30T13:25:46.216835Z",
     "iopub.status.idle": "2025-12-30T13:26:59.402021Z",
     "shell.execute_reply": "2025-12-30T13:26:59.401047Z"
    },
    "papermill": {
     "duration": 73.191179,
     "end_time": "2025-12-30T13:26:59.403859",
     "exception": false,
     "start_time": "2025-12-30T13:25:46.212680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 13:25:47.685869: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767101147.859144      24 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767101147.909682      24 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767101148.313569      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767101148.313602      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767101148.313605      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767101148.313607      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\r\n",
      "Collecting tensorflow\r\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\r\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\r\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.5)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\r\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\r\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\r\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\r\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\r\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (14.2.0)\r\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\r\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.17.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.6.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\r\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\r\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tensorboard, tensorflow\r\n",
      "  Attempting uninstall: tensorboard\r\n",
      "    Found existing installation: tensorboard 2.19.0\r\n",
      "    Uninstalling tensorboard-2.19.0:\r\n",
      "      Successfully uninstalled tensorboard-2.19.0\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.19.0\r\n",
      "    Uninstalling tensorflow-2.19.0:\r\n",
      "      Successfully uninstalled tensorflow-2.19.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.20.0 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.20.0 which is incompatible.\r\n",
      "tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.20.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed tensorboard-2.20.0 tensorflow-2.20.0\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60cd11e",
   "metadata": {
    "papermill": {
     "duration": 0.009569,
     "end_time": "2025-12-30T13:26:59.422403",
     "exception": false,
     "start_time": "2025-12-30T13:26:59.412834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4589fe57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T13:26:59.441867Z",
     "iopub.status.busy": "2025-12-30T13:26:59.440744Z",
     "iopub.status.idle": "2025-12-30T13:26:59.450519Z",
     "shell.execute_reply": "2025-12-30T13:26:59.449711Z"
    },
    "papermill": {
     "duration": 0.021007,
     "end_time": "2025-12-30T13:26:59.451909",
     "exception": false,
     "start_time": "2025-12-30T13:26:59.430902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "\n",
      " Paths configured:\n",
      "  Input: /kaggle/input/processed\n",
      "  Checkpoints: /kaggle/working/checkpoints\n",
      "  Results: /kaggle/working/results\n",
      "\n",
      "üîß Configuration:\n",
      "  Model: 6 layers, 8 heads, D_MODEL=256\n",
      "  Training: 100 epochs, LR=5e-05\n",
      "  Checkpointing: every 2 epochs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# =====================================================\n",
    "# PATHS CONFIGURATION\n",
    "# =====================================================\n",
    "\n",
    "# UPDATE THIS to match your dataset name!\n",
    "DATASET_NAME = \"preprocessed-cog-eeg-dataset\"  \n",
    "\n",
    "# Input paths\n",
    "DATA_INPUT_DIR = f\"/kaggle/input/processed\"\n",
    "\n",
    "# Output paths\n",
    "WORKING_DIR = \"/kaggle/working\"\n",
    "CHECKPOINT_DIR = os.path.join(WORKING_DIR, \"checkpoints\")\n",
    "RESULTS_DIR = os.path.join(WORKING_DIR, \"results\")\n",
    "LOGS_DIR = os.path.join(WORKING_DIR, \"logs\")\n",
    "\n",
    "for d in [CHECKPOINT_DIR, RESULTS_DIR, LOGS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(f\"\\n Paths configured:\")\n",
    "print(f\"  Input: {DATA_INPUT_DIR}\")\n",
    "print(f\"  Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"  Results: {RESULTS_DIR}\")\n",
    "\n",
    "# =====================================================\n",
    "# DATA CONSTANTS (from preprocessing)\n",
    "# =====================================================\n",
    "\n",
    "WINDOW_SIZE_SAMPLES = 256\n",
    "NUM_BANDS = 5  # delta, theta, alpha, beta, gamma\n",
    "NUM_TASKS = 4  # N-back, MATB-II, PVT, Flanker\n",
    "\n",
    "# Output classes\n",
    "NUM_OUTPUT_REGIONS = 7\n",
    "NUM_OUTPUT_BANDS = 5\n",
    "NUM_OUTPUT_STATES = 4\n",
    "\n",
    "# Note: NUM_CHANNELS and NUM_OUTPUT_CHANNELS will be determined from data!\n",
    "\n",
    "# =====================================================\n",
    "# MODEL HYPERPARAMETERS\n",
    "# =====================================================\n",
    "\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 6\n",
    "NUM_HEADS = 8\n",
    "FF_DIM = 1024\n",
    "DROPOUT = 0.25\n",
    "\n",
    "BANDPOWER_HIDDEN_DIM = 128\n",
    "BANDPOWER_OUTPUT_DIM = 128\n",
    "TASK_EMBEDDING_DIM = 16\n",
    "\n",
    "# =====================================================\n",
    "# TRAINING HYPERPARAMETERS\n",
    "# =====================================================\n",
    "\n",
    "EPOCHS = 100\n",
    "INITIAL_LR = 5e-5\n",
    "WARMUP_EPOCHS = 15\n",
    "WEIGHT_DECAY = 0.02\n",
    "GRADIENT_CLIP_NORM = 1.0\n",
    "\n",
    "SAVE_CHECKPOINT_EVERY = 2\n",
    "EARLY_STOPPING_PATIENCE = 20\n",
    "\n",
    "MIN_LR = 1e-6\n",
    "LABEL_SMOOTHING = 0.1\n",
    "\n",
    "print(f\"\\nüîß Configuration:\")\n",
    "print(f\"  Model: {NUM_LAYERS} layers, {NUM_HEADS} heads, D_MODEL={D_MODEL}\")\n",
    "print(f\"  Training: {EPOCHS} epochs, LR={INITIAL_LR}\")\n",
    "print(f\"  Checkpointing: every {SAVE_CHECKPOINT_EVERY} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda4069",
   "metadata": {
    "papermill": {
     "duration": 0.008607,
     "end_time": "2025-12-30T13:26:59.469256",
     "exception": false,
     "start_time": "2025-12-30T13:26:59.460649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  3. TPU Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d67219c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T13:26:59.487852Z",
     "iopub.status.busy": "2025-12-30T13:26:59.487647Z",
     "iopub.status.idle": "2025-12-30T13:27:00.288946Z",
     "shell.execute_reply": "2025-12-30T13:27:00.287772Z"
    },
    "papermill": {
     "duration": 0.812542,
     "end_time": "2025-12-30T13:27:00.290619",
     "exception": false,
     "start_time": "2025-12-30T13:26:59.478077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ GPU T4 x2 INITIALIZATION\n",
      "======================================================================\n",
      "\n",
      "TensorFlow version: 2.19.0\n",
      "\n",
      "üìä Creating GPU strategy...\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "‚úÖ Strategy: MirroredStrategy\n",
      "   GPUs detected: 2\n",
      "\n",
      "üéÆ GPU devices:\n",
      "   1. /physical_device:GPU:0\n",
      "   2. /physical_device:GPU:1\n",
      "\n",
      "üì¶ Batch Configuration:\n",
      "   Per-GPU batch: 32\n",
      "   Global batch: 64\n",
      "\n",
      "======================================================================\n",
      "‚úÖ GPU READY FOR TRAINING\n",
      "======================================================================\n",
      "\n",
      "üí° Next: Create model in strategy scope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1767101220.250864      24 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1767101220.251542      24 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üöÄ GPU T4 x2 INITIALIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nTensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Create GPU strategy\n",
    "print(\"\\nüìä Creating GPU strategy...\")\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "num_replicas = strategy.num_replicas_in_sync\n",
    "print(f\"‚úÖ Strategy: {strategy.__class__.__name__}\")\n",
    "print(f\"   GPUs detected: {num_replicas}\")\n",
    "\n",
    "# List GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"\\nüéÆ GPU devices:\")\n",
    "for i, gpu in enumerate(gpus):\n",
    "    print(f\"   {i+1}. {gpu.name}\")\n",
    "\n",
    "# Batch size configuration\n",
    "BATCH_SIZE_PER_REPLICA = 32  # Reduce to 16 if you get OOM errors\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * num_replicas\n",
    "\n",
    "print(f\"\\nüì¶ Batch Configuration:\")\n",
    "print(f\"   Per-GPU batch: {BATCH_SIZE_PER_REPLICA}\")\n",
    "print(f\"   Global batch: {BATCH_SIZE}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ GPU READY FOR TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Make variables global\n",
    "globals()['strategy'] = strategy\n",
    "globals()['BATCH_SIZE'] = BATCH_SIZE\n",
    "\n",
    "print(\"\\nüí° Next: Create model in strategy scope\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04abc8e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T13:27:00.310754Z",
     "iopub.status.busy": "2025-12-30T13:27:00.310227Z",
     "iopub.status.idle": "2025-12-30T13:27:00.316302Z",
     "shell.execute_reply": "2025-12-30T13:27:00.315599Z"
    },
    "papermill": {
     "duration": 0.017502,
     "end_time": "2025-12-30T13:27:00.317696",
     "exception": false,
     "start_time": "2025-12-30T13:27:00.300194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Auto-save callback ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# AUTO-SAVE CALLBACK (Add this BEFORE training section)\n",
    "# ============================================================\n",
    "\n",
    "class AutoSaveCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Custom callback to create marker files for auto-committing\"\"\"\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Create a marker file every epoch\n",
    "        # Kaggle auto-commits when new files appear\n",
    "        marker_path = f\"/kaggle/working/progress_epoch_{epoch+1}.txt\"\n",
    "        with open(marker_path, 'w') as f:\n",
    "            f.write(f\"Completed epoch {epoch+1}/{EPOCHS}\\n\")\n",
    "            f.write(f\"Loss: {logs.get('loss', 0):.4f}\\n\")\n",
    "            f.write(f\"Val Loss: {logs.get('val_loss', 0):.4f}\\n\")\n",
    "            f.write(f\"Timestamp: {datetime.now()}\\n\")\n",
    "        \n",
    "        print(f\"   Progress saved: progress_epoch_{epoch+1}.txt\")\n",
    "\n",
    "print(\" Auto-save callback ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f1f32",
   "metadata": {
    "papermill": {
     "duration": 0.00974,
     "end_time": "2025-12-30T13:27:00.337235",
     "exception": false,
     "start_time": "2025-12-30T13:27:00.327495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  4. Data Loading (Compatible with Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a07cd23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T13:27:00.358722Z",
     "iopub.status.busy": "2025-12-30T13:27:00.358452Z",
     "iopub.status.idle": "2025-12-30T13:27:00.369300Z",
     "shell.execute_reply": "2025-12-30T13:27:00.368445Z"
    },
    "papermill": {
     "duration": 0.023959,
     "end_time": "2025-12-30T13:27:00.370883",
     "exception": false,
     "start_time": "2025-12-30T13:27:00.346924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data loading function defined\n"
     ]
    }
   ],
   "source": [
    "def load_preprocessed_data(split='train'):\n",
    "    \"\"\"\n",
    "    Load preprocessed .pkl file (matches preprocessing output format).\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (X, y, metadata) where:\n",
    "        X = (X_eeg, X_bp, X_task)\n",
    "        y = (y_channel, y_region, y_band, y_state)\n",
    "        metadata = dict with num_channels, etc.\n",
    "    \"\"\"\n",
    "    pkl_path = os.path.join(DATA_INPUT_DIR, split, f\"{split}_data.pkl\")\n",
    "    \n",
    "    print(f\"\\n Loading {split} data from: {pkl_path}\")\n",
    "    \n",
    "    if not os.path.exists(pkl_path):\n",
    "        print(f\"   File not found!\")\n",
    "        print(f\"   Check that dataset is attached and DATASET_NAME is correct\")\n",
    "        return None\n",
    "    \n",
    "    # Load pickle file\n",
    "    try:\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            samples = pickle.load(f)\n",
    "        \n",
    "        print(f\"   Loaded {len(samples):,} samples\")\n",
    "        \n",
    "        if len(samples) == 0:\n",
    "            print(f\"   No samples in file!\")\n",
    "            return None\n",
    "        \n",
    "        # Inspect first sample to get dimensions\n",
    "        sample = samples[0]\n",
    "        X_shape = sample['X'].shape  # Should be (n_channels, 256)\n",
    "        bp_shape = sample['bp'].shape  # Should be (n_channels, 5)\n",
    "        \n",
    "        num_channels = X_shape[0]\n",
    "        \n",
    "        print(f\"\\n  Data format:\")\n",
    "        print(f\"     X shape: {X_shape} (channels, time)\")\n",
    "        print(f\"     bp shape: {bp_shape} (channels, bands)\")\n",
    "        print(f\"     Channels: {num_channels}\")\n",
    "        \n",
    "        # Extract arrays\n",
    "        print(f\"\\n   Converting to arrays...\")\n",
    "        \n",
    "        # X: Transpose from (n_channels, 256) to (256, n_channels)\n",
    "        X_eeg = np.array([s['X'].T for s in samples], dtype=np.float32)\n",
    "        \n",
    "        # bp: Flatten from (n_channels, 5) to (n_channels*5,)\n",
    "        X_bp = np.array([s['bp'].flatten() for s in samples], dtype=np.float32)\n",
    "        \n",
    "        # task_idx\n",
    "        X_task = np.array([s['task_idx'] for s in samples], dtype=np.int32)\n",
    "        \n",
    "        # Labels\n",
    "        y_channel = np.array([s['y_channel'] for s in samples], dtype=np.int32)\n",
    "        y_region = np.array([s['y_region'] for s in samples], dtype=np.int32)\n",
    "        y_band = np.array([s['y_band'] for s in samples], dtype=np.int32)\n",
    "        y_state = np.array([s['y_state'] for s in samples], dtype=np.int32)\n",
    "        \n",
    "        print(f\"   Final shapes:\")\n",
    "        print(f\"     X_eeg: {X_eeg.shape} (N, time, channels)\")\n",
    "        print(f\"     X_bp: {X_bp.shape} (N, features)\")\n",
    "        print(f\"     X_task: {X_task.shape}\")\n",
    "        print(f\"     Labels: {y_channel.shape} each\")\n",
    "        \n",
    "        metadata = {\n",
    "            'num_channels': num_channels,\n",
    "            'num_samples': len(samples),\n",
    "            'bandpower_dim': X_bp.shape[1]\n",
    "        }\n",
    "        \n",
    "        return (X_eeg, X_bp, X_task), (y_channel, y_region, y_band, y_state), metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error loading data: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "print(\" Data loading function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5018bca5",
   "metadata": {
    "papermill": {
     "duration": 0.01027,
     "end_time": "2025-12-30T13:27:00.391176",
     "exception": false,
     "start_time": "2025-12-30T13:27:00.380906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  5. Model Architecture (Flexible Channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b97bea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T13:27:00.412591Z",
     "iopub.status.busy": "2025-12-30T13:27:00.412366Z",
     "iopub.status.idle": "2025-12-30T13:27:00.426633Z",
     "shell.execute_reply": "2025-12-30T13:27:00.425764Z"
    },
    "papermill": {
     "duration": 0.02679,
     "end_time": "2025-12-30T13:27:00.428083",
     "exception": false,
     "start_time": "2025-12-30T13:27:00.401293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model architecture defined\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# SECTION 5: MODEL ARCHITECTURE (WITH IMPROVEMENTS)\n",
    "# =====================================================\n",
    "\n",
    "def create_model(num_channels, bandpower_input_dim, num_output_channels):\n",
    "    \"\"\"\n",
    "    Create EEG Transformer with flexible channel dimensions.\n",
    "    \n",
    "    Args:\n",
    "        num_channels: Number of EEG channels (e.g., 58)\n",
    "        bandpower_input_dim: Bandpower feature dimension (num_channels * 5)\n",
    "        num_output_channels: Number of output classes for channel prediction\n",
    "    \"\"\"\n",
    "    # Inputs\n",
    "    eeg_input = tf.keras.Input(shape=(WINDOW_SIZE_SAMPLES, num_channels), name='eeg')\n",
    "    bp_input = tf.keras.Input(shape=(bandpower_input_dim,), name='bp')\n",
    "    task_input = tf.keras.Input(shape=(1,), dtype='int32', name='task')\n",
    "    \n",
    "    # ==================== EEG STREAM ====================\n",
    "    x = tf.keras.layers.Dense(D_MODEL, name='eeg_projection')(eeg_input)\n",
    "    \n",
    "    # Positional encoding\n",
    "    positions = tf.range(start=0, limit=WINDOW_SIZE_SAMPLES, delta=1)\n",
    "    pos_emb = tf.keras.layers.Embedding(\n",
    "        input_dim=WINDOW_SIZE_SAMPLES,\n",
    "        output_dim=D_MODEL,\n",
    "        name='positional_embedding'\n",
    "    )(positions)\n",
    "    x = x + pos_emb\n",
    "    \n",
    "    # Transformer layers\n",
    "    for i in range(NUM_LAYERS):\n",
    "        attn = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=NUM_HEADS,\n",
    "            key_dim=D_MODEL // NUM_HEADS,\n",
    "            dropout=DROPOUT,\n",
    "            name=f'mha_{i}'\n",
    "        )(x, x)\n",
    "        x = tf.keras.layers.Add(name=f'add_attn_{i}')([x, attn])\n",
    "        x = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=f'ln_attn_{i}')(x)\n",
    "        \n",
    "        ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(FF_DIM, activation='gelu'),  # ‚ú® CHANGED: relu ‚Üí gelu\n",
    "            tf.keras.layers.Dense(D_MODEL),\n",
    "            tf.keras.layers.Dropout(DROPOUT)\n",
    "        ], name=f'ffn_{i}')\n",
    "        \n",
    "        ffn_out = ffn(x)\n",
    "        x = tf.keras.layers.Add(name=f'add_ffn_{i}')([x, ffn_out])\n",
    "        x = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=f'ln_ffn_{i}')(x)\n",
    "    \n",
    "    eeg_emb = tf.keras.layers.GlobalAveragePooling1D(name='eeg_pool')(x)\n",
    "    eeg_emb = tf.keras.layers.Dropout(DROPOUT)(eeg_emb)  # ‚ú® ADDED: dropout after pooling\n",
    "    \n",
    "    # ==================== BANDPOWER STREAM ====================\n",
    "    bp_x = tf.keras.layers.Dense(BANDPOWER_HIDDEN_DIM, activation='gelu', name='bp_hidden')(bp_input)  # ‚ú® CHANGED: relu ‚Üí gelu\n",
    "    bp_x = tf.keras.layers.Dropout(DROPOUT)(bp_x)  # ‚ú® ADDED: dropout\n",
    "    bp_emb = tf.keras.layers.Dense(BANDPOWER_OUTPUT_DIM, activation='gelu', name='bp_output')(bp_x)  # ‚ú® CHANGED: relu ‚Üí gelu\n",
    "    bp_emb = tf.keras.layers.Dropout(DROPOUT)(bp_emb)  # ‚ú® ADDED: dropout\n",
    "    \n",
    "    # ==================== TASK STREAM ====================\n",
    "    task_emb = tf.keras.layers.Embedding(NUM_TASKS, TASK_EMBEDDING_DIM, name='task_emb')(task_input)\n",
    "    task_emb = tf.keras.layers.Flatten(name='task_flatten')(task_emb)\n",
    "    \n",
    "    # ==================== FUSION ====================\n",
    "    fused = tf.keras.layers.Concatenate(name='fusion')([eeg_emb, bp_emb, task_emb])\n",
    "    fused = tf.keras.layers.Dense(D_MODEL, activation='gelu', name='fusion_dense')(fused)  # ‚ú® ADDED: fusion processing\n",
    "    fused = tf.keras.layers.Dropout(DROPOUT)(fused)  # ‚ú® ADDED: dropout after fusion\n",
    "    \n",
    "    # ==================== MULTI-TASK HEADS ====================\n",
    "    out_channel = tf.keras.layers.Dense(num_output_channels, name='channel')(fused)\n",
    "    out_region = tf.keras.layers.Dense(NUM_OUTPUT_REGIONS, name='region')(fused)\n",
    "    out_band = tf.keras.layers.Dense(NUM_OUTPUT_BANDS, name='band')(fused)\n",
    "    out_state = tf.keras.layers.Dense(NUM_OUTPUT_STATES, name='state')(fused)\n",
    "    \n",
    "    model = tf.keras.Model(\n",
    "        inputs=[eeg_input, bp_input, task_input],\n",
    "        outputs={\n",
    "            'channel': out_channel,\n",
    "            'region': out_region,\n",
    "            'band': out_band,\n",
    "            'state': out_state\n",
    "        },\n",
    "        name='CogniVue_Transformer'\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Model architecture defined\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed2704b",
   "metadata": {
    "papermill": {
     "duration": 0.010231,
     "end_time": "2025-12-30T13:27:00.448407",
     "exception": false,
     "start_time": "2025-12-30T13:27:00.438176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  6. Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74961126",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T13:27:00.470020Z",
     "iopub.status.busy": "2025-12-30T13:27:00.469564Z",
     "iopub.status.idle": "2025-12-30T13:27:00.476671Z",
     "shell.execute_reply": "2025-12-30T13:27:00.476013Z"
    },
    "papermill": {
     "duration": 0.019723,
     "end_time": "2025-12-30T13:27:00.478271",
     "exception": false,
     "start_time": "2025-12-30T13:27:00.458548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LR schedule defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================================================\n",
    "# SECTION 6: LEARNING RATE SCHEDULE (WITH IMPROVEMENTS)\n",
    "# =====================================================\n",
    "\n",
    "class WarmupCosineDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_learning_rate, warmup_steps, total_steps, min_lr=1e-6):  # ‚ú® ADDED: min_lr parameter\n",
    "        super().__init__()\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.min_lr = min_lr  # ‚ú® ADDED: store min_lr\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n",
    "        total_steps = tf.cast(self.total_steps, tf.float32)\n",
    "        \n",
    "        warmup_lr = (step / warmup_steps) * self.initial_learning_rate\n",
    "        \n",
    "        decay_steps = total_steps - warmup_steps\n",
    "        decay_step = step - warmup_steps\n",
    "        cosine_decay = 0.5 * (1 + tf.cos(tf.constant(np.pi) * decay_step / decay_steps))\n",
    "        decay_lr = (self.initial_learning_rate - self.min_lr) * cosine_decay + self.min_lr  # ‚ú® CHANGED: add min_lr floor\n",
    "        \n",
    "        return tf.cond(\n",
    "            step < warmup_steps,\n",
    "            lambda: warmup_lr,\n",
    "            lambda: decay_lr\n",
    "        )\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"initial_learning_rate\": self.initial_learning_rate,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"total_steps\": self.total_steps,\n",
    "            \"min_lr\": self.min_lr,  # ‚ú® ADDED: include min_lr in config\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ LR schedule defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b52c235",
   "metadata": {
    "papermill": {
     "duration": 0.010211,
     "end_time": "2025-12-30T13:27:00.498824",
     "exception": false,
     "start_time": "2025-12-30T13:27:00.488613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  7. Data Pipeline & Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7acefd03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T13:27:00.519255Z",
     "iopub.status.busy": "2025-12-30T13:27:00.518787Z",
     "iopub.status.idle": "2025-12-30T13:27:00.527907Z",
     "shell.execute_reply": "2025-12-30T13:27:00.527194Z"
    },
    "papermill": {
     "duration": 0.020358,
     "end_time": "2025-12-30T13:27:00.529170",
     "exception": false,
     "start_time": "2025-12-30T13:27:00.508812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pipeline & callbacks defined\n"
     ]
    }
   ],
   "source": [
    "def create_tf_dataset(X, y, is_train=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {'eeg': X[0], 'bp': X[1], 'task': X[2]},\n",
    "        {'channel': y[0], 'region': y[1], 'band': y[2], 'state': y[3]}\n",
    "    ))\n",
    "    \n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    \n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "class PeriodicCheckpoint(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_freq=5):\n",
    "        super().__init__()\n",
    "        self.save_freq = save_freq\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.save_freq == 0:\n",
    "            filepath = os.path.join(CHECKPOINT_DIR, f\"checkpoint_epoch_{epoch+1:03d}.keras\")\n",
    "            self.model.save(filepath)\n",
    "            print(f\"\\n   Saved checkpoint: {os.path.basename(filepath)}\")\n",
    "\n",
    "\n",
    "class LearningRateLogger(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.learning_rate\n",
    "        if hasattr(lr, '__call__'):\n",
    "            lr_value = lr(self.model.optimizer.iterations)\n",
    "        else:\n",
    "            lr_value = lr\n",
    "        lr_float = float(tf.keras.backend.get_value(lr_value))\n",
    "        if logs is not None:\n",
    "            logs['learning_rate'] = lr_float\n",
    "        print(f\"\\n   LR = {lr_float:.6f}\")\n",
    "\n",
    "\n",
    "class ProgressLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.epoch_start = None\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start = time.time()\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\" Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"{'='*70}\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        elapsed = time.time() - self.epoch_start\n",
    "        print(f\"\\n Epoch {epoch+1} done in {elapsed:.1f}s\")\n",
    "        if logs:\n",
    "            print(f\"   Loss: {logs.get('loss', 0):.4f} | Val Loss: {logs.get('val_loss', 0):.4f}\")\n",
    "            print(f\"   Region Acc: {logs.get('region_accuracy', 0):.4f} | Val: {logs.get('val_region_accuracy', 0):.4f}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(\" Pipeline & callbacks defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45605fe",
   "metadata": {
    "papermill": {
     "duration": 0.008934,
     "end_time": "2025-12-30T13:27:00.547111",
     "exception": false,
     "start_time": "2025-12-30T13:27:00.538177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  8. Main Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa5223cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T13:27:00.566432Z",
     "iopub.status.busy": "2025-12-30T13:27:00.566184Z",
     "iopub.status.idle": "2025-12-30T13:27:00.580629Z",
     "shell.execute_reply": "2025-12-30T13:27:00.579908Z"
    },
    "papermill": {
     "duration": 0.025921,
     "end_time": "2025-12-30T13:27:00.582004",
     "exception": false,
     "start_time": "2025-12-30T13:27:00.556083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training function ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================================================\n",
    "# SECTION 8: MAIN TRAINING FUNCTION (WITH IMPROVEMENTS)\n",
    "# =====================================================\n",
    "\n",
    "def train_cognivue():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üß† CogniVue Training Pipeline\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load ONLY training data\n",
    "    print(\"\\nüìÇ Loading data...\")\n",
    "    train_result = load_preprocessed_data('train')\n",
    "    \n",
    "    if train_result is None:\n",
    "        print(\"\\n‚ùå Data loading failed!\")\n",
    "        return None\n",
    "    \n",
    "    train_data, train_labels, train_meta = train_result\n",
    "    \n",
    "    # =====================================================\n",
    "    # SPLIT TRAIN DATA INTO TRAIN/VAL (80/20)\n",
    "    # =====================================================\n",
    "    print(\"\\n‚úÇÔ∏è Splitting data into train/val...\")\n",
    "    \n",
    "    num_samples = len(train_data[0])\n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # 80% train, 20% val\n",
    "    split_idx = int(0.8 * num_samples)\n",
    "    train_idx = indices[:split_idx]\n",
    "    val_idx = indices[split_idx:]\n",
    "    \n",
    "    # Split X data\n",
    "    train_X = (\n",
    "        train_data[0][train_idx],  # X_eeg\n",
    "        train_data[1][train_idx],  # X_bp\n",
    "        train_data[2][train_idx]   # X_task\n",
    "    )\n",
    "    val_X = (\n",
    "        train_data[0][val_idx],\n",
    "        train_data[1][val_idx],\n",
    "        train_data[2][val_idx]\n",
    "    )\n",
    "    \n",
    "    # Split y data\n",
    "    train_y = (\n",
    "        train_labels[0][train_idx],  # y_channel\n",
    "        train_labels[1][train_idx],  # y_region\n",
    "        train_labels[2][train_idx],  # y_band\n",
    "        train_labels[3][train_idx]   # y_state\n",
    "    )\n",
    "    val_y = (\n",
    "        train_labels[0][val_idx],\n",
    "        train_labels[1][val_idx],\n",
    "        train_labels[2][val_idx],\n",
    "        train_labels[3][val_idx]\n",
    "    )\n",
    "    \n",
    "    print(f\"   Train samples: {len(train_idx):,}\")\n",
    "    print(f\"   Val samples: {len(val_idx):,}\")\n",
    "    \n",
    "    # Get dimensions from data\n",
    "    NUM_CHANNELS = train_meta['num_channels']\n",
    "    BANDPOWER_INPUT_DIM = train_meta['bandpower_dim']\n",
    "    \n",
    "    # Determine NUM_OUTPUT_CHANNELS from labels\n",
    "    NUM_OUTPUT_CHANNELS = train_labels[0].max() + 1\n",
    "    \n",
    "    print(f\"\\nüìä Model dimensions:\")\n",
    "    print(f\"   Input channels: {NUM_CHANNELS}\")\n",
    "    print(f\"   Bandpower dim: {BANDPOWER_INPUT_DIM}\")\n",
    "    print(f\"   Output channels: {NUM_OUTPUT_CHANNELS}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    print(f\"\\nüîÑ Creating TF datasets...\")\n",
    "    train_ds = create_tf_dataset(train_X, train_y, is_train=True)\n",
    "    val_ds = create_tf_dataset(val_X, val_y, is_train=False)\n",
    "    \n",
    "    steps_per_epoch = len(train_idx) // BATCH_SIZE\n",
    "    total_steps = steps_per_epoch * EPOCHS\n",
    "    warmup_steps = steps_per_epoch * WARMUP_EPOCHS\n",
    "    \n",
    "    print(f\"   Steps/epoch: {steps_per_epoch:,}\")\n",
    "    print(f\"   Total steps: {total_steps:,}\")\n",
    "    \n",
    "    # Build model\n",
    "    print(f\"\\nüèóÔ∏è Building model...\")\n",
    "    \n",
    "    with strategy.scope():\n",
    "        model = create_model(NUM_CHANNELS, BANDPOWER_INPUT_DIM, NUM_OUTPUT_CHANNELS)\n",
    "        \n",
    "        print(f\"   Parameters: {model.count_params():,}\")\n",
    "        \n",
    "        lr_schedule = WarmupCosineDecay(INITIAL_LR, warmup_steps, total_steps, MIN_LR)  # ‚ú® CHANGED: added MIN_LR\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=lr_schedule,\n",
    "            weight_decay=WEIGHT_DECAY,\n",
    "            clipnorm=GRADIENT_CLIP_NORM\n",
    "        )\n",
    "        \n",
    "        loss_weights = {'channel': 0.35, 'region': 0.35, 'band': 0.15, 'state': 0.15}  # ‚ú® CHANGED: rebalanced weights\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss={\n",
    "                'channel': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # ‚ú® ADDED: label_smoothing\n",
    "                'region': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # ‚ú® ADDED: label_smoothing\n",
    "                'band': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),    # ‚ú® ADDED: label_smoothing\n",
    "                'state': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)   # ‚ú® ADDED: label_smoothing\n",
    "            },\n",
    "            loss_weights=loss_weights,\n",
    "            metrics={\n",
    "                'channel': ['accuracy'],\n",
    "                'region': ['accuracy'],\n",
    "                'band': ['accuracy'],\n",
    "                'state': ['accuracy']\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    print(f\"   ‚úÖ Compiled\")\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        ProgressLogger(),\n",
    "        LearningRateLogger(),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(CHECKPOINT_DIR, 'best_model.keras'),\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=EARLY_STOPPING_PATIENCE,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=LOGS_DIR)\n",
    "    ]\n",
    "    \n",
    "    # Train\n",
    "    print(f\"\\nüöÄ Starting training...\")\n",
    "    print(f\"‚è∞ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    \n",
    "    try:\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=val_ds,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nüìÅ Saved to: {CHECKPOINT_DIR}\")\n",
    "        \n",
    "        # Save final\n",
    "        model.save(os.path.join(CHECKPOINT_DIR, 'final_model.keras'))\n",
    "        print(f\"   - final_model.keras\")\n",
    "        print(f\"   - best_model.keras\")\n",
    "        \n",
    "        return history\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚ö†Ô∏è Training interrupted!\")\n",
    "        model.save(os.path.join(CHECKPOINT_DIR, 'interrupted.keras'))\n",
    "        print(f\"   üíæ Saved: interrupted.keras\")\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Training failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Training function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806bbf55",
   "metadata": {
    "papermill": {
     "duration": 0.009333,
     "end_time": "2025-12-30T13:27:00.600339",
     "exception": false,
     "start_time": "2025-12-30T13:27:00.591006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  9. Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eceab00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T13:27:00.619613Z",
     "iopub.status.busy": "2025-12-30T13:27:00.619391Z",
     "iopub.status.idle": "2025-12-30T14:19:20.581123Z",
     "shell.execute_reply": "2025-12-30T14:19:20.580209Z"
    },
    "papermill": {
     "duration": 3139.973324,
     "end_time": "2025-12-30T14:19:20.582841",
     "exception": false,
     "start_time": "2025-12-30T13:27:00.609517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üß† CogniVue Training Pipeline\n",
      "======================================================================\n",
      "\n",
      "üìÇ Loading data...\n",
      "\n",
      " Loading train data from: /kaggle/input/processed/train/train_data.pkl\n",
      "   Loaded 21,538 samples\n",
      "\n",
      "  Data format:\n",
      "     X shape: (58, 256) (channels, time)\n",
      "     bp shape: (58, 5) (channels, bands)\n",
      "     Channels: 58\n",
      "\n",
      "   Converting to arrays...\n",
      "   Final shapes:\n",
      "     X_eeg: (21538, 256, 58) (N, time, channels)\n",
      "     X_bp: (21538, 290) (N, features)\n",
      "     X_task: (21538,)\n",
      "     Labels: (21538,) each\n",
      "\n",
      "‚úÇÔ∏è Splitting data into train/val...\n",
      "   Train samples: 17,230\n",
      "   Val samples: 4,308\n",
      "\n",
      "üìä Model dimensions:\n",
      "   Input channels: 58\n",
      "   Bandpower dim: 290\n",
      "   Output channels: 58\n",
      "\n",
      "üîÑ Creating TF datasets...\n",
      "   Steps/epoch: 269\n",
      "   Total steps: 26,900\n",
      "\n",
      "üèóÔ∏è Building model...\n",
      "   Parameters: 4,929,162\n",
      "   ‚úÖ Compiled\n",
      "\n",
      "üöÄ Starting training...\n",
      "‚è∞ 2025-12-30 13:27:15\n",
      "\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "\n",
      "======================================================================\n",
      " Epoch 1/100\n",
      "======================================================================\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:Collective all_reduce tensors: 112 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce IndexedSlices: 1 all_reduces, num_devices =2, group_size = 2, implementation = CommunicationImplementation.NCCL\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - band_accuracy: 0.0647 - band_loss: 7.0812 - channel_accuracy: 0.0086 - channel_loss: 13.1031 - loss: 8.7104 - region_accuracy: 0.0828 - region_loss: 7.3265 - state_accuracy: 0.2629 - state_loss: 3.3188\n",
      " Epoch 1 done in 108.6s\n",
      "   Loss: 7.7737 | Val Loss: 2.7894\n",
      "   Region Acc: 0.1463 | Val: 0.9174\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000003\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 2.78938, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 278ms/step - band_accuracy: 0.0648 - band_loss: 7.0777 - channel_accuracy: 0.0086 - channel_loss: 13.1004 - loss: 8.7069 - region_accuracy: 0.0831 - region_loss: 7.3212 - state_accuracy: 0.2631 - state_loss: 3.3177 - val_band_accuracy: 0.0371 - val_band_loss: 1.2171 - val_channel_accuracy: 0.0259 - val_channel_loss: 6.8733 - val_loss: 2.7894 - val_region_accuracy: 0.9174 - val_region_loss: 0.4175 - val_state_accuracy: 1.0000 - val_state_loss: 0.3668 - learning_rate: 3.3333e-06\n",
      "\n",
      "======================================================================\n",
      " Epoch 2/100\n",
      "======================================================================\n",
      "Epoch 2/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - band_accuracy: 0.4480 - band_loss: 2.1775 - channel_accuracy: 0.0233 - channel_loss: 8.4652 - loss: 4.0697 - region_accuracy: 0.5866 - region_loss: 1.6027 - state_accuracy: 0.5433 - state_loss: 1.4619\n",
      " Epoch 2 done in 76.7s\n",
      "   Loss: 3.1841 | Val Loss: 1.1116\n",
      "   Region Acc: 0.6933 | Val: 0.9174\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000007\n",
      "\n",
      "Epoch 2: val_loss improved from 2.78938 to 1.11157, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 285ms/step - band_accuracy: 0.4487 - band_loss: 2.1747 - channel_accuracy: 0.0234 - channel_loss: 8.4592 - loss: 4.0664 - region_accuracy: 0.5870 - region_loss: 1.6012 - state_accuracy: 0.5437 - state_loss: 1.4602 - val_band_accuracy: 0.9674 - val_band_loss: 0.2310 - val_channel_accuracy: 0.1702 - val_channel_loss: 2.5225 - val_loss: 1.1116 - val_region_accuracy: 0.9174 - val_region_loss: 0.5409 - val_state_accuracy: 1.0000 - val_state_loss: 0.0316 - learning_rate: 6.6667e-06\n",
      "\n",
      "======================================================================\n",
      " Epoch 3/100\n",
      "======================================================================\n",
      "Epoch 3/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - band_accuracy: 0.9042 - band_loss: 0.4263 - channel_accuracy: 0.1455 - channel_loss: 3.6731 - loss: 1.6326 - region_accuracy: 0.8521 - region_loss: 0.6954 - state_accuracy: 0.9067 - state_loss: 0.2648\n",
      " Epoch 3 done in 77.5s\n",
      "   Loss: 1.4767 | Val Loss: 0.9762\n",
      "   Region Acc: 0.8703 | Val: 0.9174\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000010\n",
      "\n",
      "Epoch 3: val_loss improved from 1.11157 to 0.97618, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 288ms/step - band_accuracy: 0.9043 - band_loss: 0.4261 - channel_accuracy: 0.1455 - channel_loss: 3.6719 - loss: 1.6321 - region_accuracy: 0.8522 - region_loss: 0.6951 - state_accuracy: 0.9068 - state_loss: 0.2645 - val_band_accuracy: 0.9674 - val_band_loss: 0.1933 - val_channel_accuracy: 0.1740 - val_channel_loss: 2.3057 - val_loss: 0.9762 - val_region_accuracy: 0.9174 - val_region_loss: 0.3848 - val_state_accuracy: 1.0000 - val_state_loss: 0.0366 - learning_rate: 1.0000e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 4/100\n",
      "======================================================================\n",
      "Epoch 4/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - band_accuracy: 0.9537 - band_loss: 0.2763 - channel_accuracy: 0.1844 - channel_loss: 2.7534 - loss: 1.1918 - region_accuracy: 0.9015 - region_loss: 0.4942 - state_accuracy: 0.9890 - state_loss: 0.0910\n",
      " Epoch 4 done in 77.3s\n",
      "   Loss: 1.1479 | Val Loss: 0.8893\n",
      "   Region Acc: 0.9023 | Val: 0.9174\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000013\n",
      "\n",
      "Epoch 4: val_loss improved from 0.97618 to 0.88929, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 287ms/step - band_accuracy: 0.9537 - band_loss: 0.2763 - channel_accuracy: 0.1844 - channel_loss: 2.7531 - loss: 1.1916 - region_accuracy: 0.9015 - region_loss: 0.4942 - state_accuracy: 0.9890 - state_loss: 0.0909 - val_band_accuracy: 0.9674 - val_band_loss: 0.1730 - val_channel_accuracy: 0.3284 - val_channel_loss: 2.1243 - val_loss: 0.8893 - val_region_accuracy: 0.9174 - val_region_loss: 0.3284 - val_state_accuracy: 1.0000 - val_state_loss: 0.0326 - learning_rate: 1.3333e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 5/100\n",
      "======================================================================\n",
      "Epoch 5/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - band_accuracy: 0.9614 - band_loss: 0.2314 - channel_accuracy: 0.2437 - channel_loss: 2.3514 - loss: 1.0044 - region_accuracy: 0.9123 - region_loss: 0.3933 - state_accuracy: 0.9985 - state_loss: 0.0602\n",
      " Epoch 5 done in 77.5s\n",
      "   Loss: 0.9407 | Val Loss: 0.7300\n",
      "   Region Acc: 0.9207 | Val: 0.9321\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000017\n",
      "\n",
      "Epoch 5: val_loss improved from 0.88929 to 0.73002, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 288ms/step - band_accuracy: 0.9614 - band_loss: 0.2314 - channel_accuracy: 0.2439 - channel_loss: 2.3510 - loss: 1.0041 - region_accuracy: 0.9123 - region_loss: 0.3931 - state_accuracy: 0.9985 - state_loss: 0.0602 - val_band_accuracy: 0.9674 - val_band_loss: 0.1249 - val_channel_accuracy: 0.4265 - val_channel_loss: 1.7580 - val_loss: 0.7300 - val_region_accuracy: 0.9321 - val_region_loss: 0.2668 - val_state_accuracy: 1.0000 - val_state_loss: 0.0174 - learning_rate: 1.6667e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 6/100\n",
      "======================================================================\n",
      "Epoch 6/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - band_accuracy: 0.9565 - band_loss: 0.1775 - channel_accuracy: 0.4059 - channel_loss: 1.8962 - loss: 0.7982 - region_accuracy: 0.9312 - region_loss: 0.2895 - state_accuracy: 1.0000 - state_loss: 0.0439\n",
      " Epoch 6 done in 77.8s\n",
      "   Loss: 0.7797 | Val Loss: 0.6731\n",
      "   Region Acc: 0.9322 | Val: 0.9340\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000020\n",
      "\n",
      "Epoch 6: val_loss improved from 0.73002 to 0.67310, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 289ms/step - band_accuracy: 0.9565 - band_loss: 0.1775 - channel_accuracy: 0.4060 - channel_loss: 1.8960 - loss: 0.7981 - region_accuracy: 0.9312 - region_loss: 0.2895 - state_accuracy: 1.0000 - state_loss: 0.0439 - val_band_accuracy: 0.9674 - val_band_loss: 0.1151 - val_channel_accuracy: 0.4771 - val_channel_loss: 1.6154 - val_loss: 0.6731 - val_region_accuracy: 0.9340 - val_region_loss: 0.2527 - val_state_accuracy: 1.0000 - val_state_loss: 0.0135 - learning_rate: 2.0000e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 7/100\n",
      "======================================================================\n",
      "Epoch 7/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - band_accuracy: 0.9587 - band_loss: 0.1564 - channel_accuracy: 0.4522 - channel_loss: 1.7351 - loss: 0.7240 - region_accuracy: 0.9377 - region_loss: 0.2526 - state_accuracy: 1.0000 - state_loss: 0.0318\n",
      " Epoch 7 done in 77.3s\n",
      "   Loss: 0.7139 | Val Loss: 0.6424\n",
      "   Region Acc: 0.9365 | Val: 0.9373\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000023\n",
      "\n",
      "Epoch 7: val_loss improved from 0.67310 to 0.64242, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 287ms/step - band_accuracy: 0.9588 - band_loss: 0.1564 - channel_accuracy: 0.4522 - channel_loss: 1.7350 - loss: 0.7239 - region_accuracy: 0.9377 - region_loss: 0.2527 - state_accuracy: 1.0000 - state_loss: 0.0318 - val_band_accuracy: 0.9674 - val_band_loss: 0.1128 - val_channel_accuracy: 0.5021 - val_channel_loss: 1.5306 - val_loss: 0.6424 - val_region_accuracy: 0.9373 - val_region_loss: 0.2519 - val_state_accuracy: 1.0000 - val_state_loss: 0.0109 - learning_rate: 2.3333e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 8/100\n",
      "======================================================================\n",
      "Epoch 8/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - band_accuracy: 0.9569 - band_loss: 0.1544 - channel_accuracy: 0.4867 - channel_loss: 1.6314 - loss: 0.6879 - region_accuracy: 0.9369 - region_loss: 0.2566 - state_accuracy: 1.0000 - state_loss: 0.0264\n",
      " Epoch 8 done in 77.7s\n",
      "   Loss: 0.6765 | Val Loss: 0.6267\n",
      "   Region Acc: 0.9356 | Val: 0.9363\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000027\n",
      "\n",
      "Epoch 8: val_loss improved from 0.64242 to 0.62673, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 289ms/step - band_accuracy: 0.9569 - band_loss: 0.1544 - channel_accuracy: 0.4867 - channel_loss: 1.6313 - loss: 0.6879 - region_accuracy: 0.9369 - region_loss: 0.2566 - state_accuracy: 1.0000 - state_loss: 0.0264 - val_band_accuracy: 0.9669 - val_band_loss: 0.1047 - val_channel_accuracy: 0.5182 - val_channel_loss: 1.4992 - val_loss: 0.6267 - val_region_accuracy: 0.9363 - val_region_loss: 0.2440 - val_state_accuracy: 1.0000 - val_state_loss: 0.0061 - learning_rate: 2.6667e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 9/100\n",
      "======================================================================\n",
      "Epoch 9/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - band_accuracy: 0.9580 - band_loss: 0.1460 - channel_accuracy: 0.5033 - channel_loss: 1.5751 - loss: 0.6625 - region_accuracy: 0.9353 - region_loss: 0.2459 - state_accuracy: 1.0000 - state_loss: 0.0218\n",
      " Epoch 9 done in 77.4s\n",
      "   Loss: 0.6505 | Val Loss: 0.6316\n",
      "   Region Acc: 0.9374 | Val: 0.9282\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000030\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.62673\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 284ms/step - band_accuracy: 0.9580 - band_loss: 0.1459 - channel_accuracy: 0.5033 - channel_loss: 1.5750 - loss: 0.6625 - region_accuracy: 0.9354 - region_loss: 0.2459 - state_accuracy: 1.0000 - state_loss: 0.0218 - val_band_accuracy: 0.9674 - val_band_loss: 0.1030 - val_channel_accuracy: 0.5254 - val_channel_loss: 1.5046 - val_loss: 0.6316 - val_region_accuracy: 0.9282 - val_region_loss: 0.2538 - val_state_accuracy: 1.0000 - val_state_loss: 0.0050 - learning_rate: 3.0000e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 10/100\n",
      "======================================================================\n",
      "Epoch 10/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - band_accuracy: 0.9595 - band_loss: 0.1354 - channel_accuracy: 0.5063 - channel_loss: 1.5374 - loss: 0.6462 - region_accuracy: 0.9366 - region_loss: 0.2439 - state_accuracy: 1.0000 - state_loss: 0.0163\n",
      " Epoch 10 done in 77.4s\n",
      "   Loss: 0.6326 | Val Loss: 0.6068\n",
      "   Region Acc: 0.9385 | Val: 0.9391\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000033\n",
      "\n",
      "Epoch 10: val_loss improved from 0.62673 to 0.60679, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 288ms/step - band_accuracy: 0.9595 - band_loss: 0.1354 - channel_accuracy: 0.5063 - channel_loss: 1.5373 - loss: 0.6462 - region_accuracy: 0.9366 - region_loss: 0.2439 - state_accuracy: 1.0000 - state_loss: 0.0163 - val_band_accuracy: 0.9671 - val_band_loss: 0.1035 - val_channel_accuracy: 0.5266 - val_channel_loss: 1.4510 - val_loss: 0.6068 - val_region_accuracy: 0.9391 - val_region_loss: 0.2370 - val_state_accuracy: 1.0000 - val_state_loss: 0.0031 - learning_rate: 3.3333e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 11/100\n",
      "======================================================================\n",
      "Epoch 11/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - band_accuracy: 0.9599 - band_loss: 0.1309 - channel_accuracy: 0.5160 - channel_loss: 1.4880 - loss: 0.6208 - region_accuracy: 0.9360 - region_loss: 0.2238 - state_accuracy: 1.0000 - state_loss: 0.0136\n",
      " Epoch 11 done in 77.4s\n",
      "   Loss: 0.6204 | Val Loss: 0.5984\n",
      "   Region Acc: 0.9363 | Val: 0.9303\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000037\n",
      "\n",
      "Epoch 11: val_loss improved from 0.60679 to 0.59838, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 288ms/step - band_accuracy: 0.9599 - band_loss: 0.1309 - channel_accuracy: 0.5160 - channel_loss: 1.4880 - loss: 0.6208 - region_accuracy: 0.9360 - region_loss: 0.2238 - state_accuracy: 1.0000 - state_loss: 0.0136 - val_band_accuracy: 0.9634 - val_band_loss: 0.1086 - val_channel_accuracy: 0.5273 - val_channel_loss: 1.4281 - val_loss: 0.5984 - val_region_accuracy: 0.9303 - val_region_loss: 0.2327 - val_state_accuracy: 1.0000 - val_state_loss: 0.0053 - learning_rate: 3.6667e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 12/100\n",
      "======================================================================\n",
      "Epoch 12/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - band_accuracy: 0.9624 - band_loss: 0.1192 - channel_accuracy: 0.5286 - channel_loss: 1.4401 - loss: 0.6010 - region_accuracy: 0.9394 - region_loss: 0.2214 - state_accuracy: 1.0000 - state_loss: 0.0107\n",
      " Epoch 12 done in 77.3s\n",
      "   Loss: 0.6053 | Val Loss: 0.5896\n",
      "   Region Acc: 0.9394 | Val: 0.9338\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000040\n",
      "\n",
      "Epoch 12: val_loss improved from 0.59838 to 0.58956, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 287ms/step - band_accuracy: 0.9624 - band_loss: 0.1192 - channel_accuracy: 0.5286 - channel_loss: 1.4401 - loss: 0.6010 - region_accuracy: 0.9394 - region_loss: 0.2214 - state_accuracy: 1.0000 - state_loss: 0.0107 - val_band_accuracy: 0.9678 - val_band_loss: 0.0980 - val_channel_accuracy: 0.5333 - val_channel_loss: 1.4149 - val_loss: 0.5896 - val_region_accuracy: 0.9338 - val_region_loss: 0.2264 - val_state_accuracy: 1.0000 - val_state_loss: 0.0026 - learning_rate: 4.0000e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 13/100\n",
      "======================================================================\n",
      "Epoch 13/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - band_accuracy: 0.9621 - band_loss: 0.1224 - channel_accuracy: 0.5249 - channel_loss: 1.4304 - loss: 0.5993 - region_accuracy: 0.9388 - region_loss: 0.2255 - state_accuracy: 1.0000 - state_loss: 0.0095\n",
      " Epoch 13 done in 77.4s\n",
      "   Loss: 0.5957 | Val Loss: 0.5803\n",
      "   Region Acc: 0.9406 | Val: 0.9370\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000043\n",
      "\n",
      "Epoch 13: val_loss improved from 0.58956 to 0.58034, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 287ms/step - band_accuracy: 0.9621 - band_loss: 0.1224 - channel_accuracy: 0.5249 - channel_loss: 1.4303 - loss: 0.5993 - region_accuracy: 0.9388 - region_loss: 0.2255 - state_accuracy: 1.0000 - state_loss: 0.0095 - val_band_accuracy: 0.9681 - val_band_loss: 0.0973 - val_channel_accuracy: 0.5329 - val_channel_loss: 1.4035 - val_loss: 0.5803 - val_region_accuracy: 0.9370 - val_region_loss: 0.2117 - val_state_accuracy: 1.0000 - val_state_loss: 0.0028 - learning_rate: 4.3333e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 14/100\n",
      "======================================================================\n",
      "Epoch 14/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - band_accuracy: 0.9618 - band_loss: 0.1210 - channel_accuracy: 0.5268 - channel_loss: 1.4189 - loss: 0.5931 - region_accuracy: 0.9377 - region_loss: 0.2200 - state_accuracy: 1.0000 - state_loss: 0.0091\n",
      " Epoch 14 done in 77.3s\n",
      "   Loss: 0.5888 | Val Loss: 0.5711\n",
      "   Region Acc: 0.9403 | Val: 0.9361\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000047\n",
      "\n",
      "Epoch 14: val_loss improved from 0.58034 to 0.57113, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 287ms/step - band_accuracy: 0.9618 - band_loss: 0.1210 - channel_accuracy: 0.5268 - channel_loss: 1.4189 - loss: 0.5931 - region_accuracy: 0.9377 - region_loss: 0.2200 - state_accuracy: 1.0000 - state_loss: 0.0091 - val_band_accuracy: 0.9690 - val_band_loss: 0.0973 - val_channel_accuracy: 0.5310 - val_channel_loss: 1.3676 - val_loss: 0.5711 - val_region_accuracy: 0.9361 - val_region_loss: 0.2216 - val_state_accuracy: 1.0000 - val_state_loss: 0.0020 - learning_rate: 4.6667e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 15/100\n",
      "======================================================================\n",
      "Epoch 15/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - band_accuracy: 0.9593 - band_loss: 0.1217 - channel_accuracy: 0.5388 - channel_loss: 1.3937 - loss: 0.5851 - region_accuracy: 0.9360 - region_loss: 0.2222 - state_accuracy: 1.0000 - state_loss: 0.0083\n",
      " Epoch 15 done in 77.4s\n",
      "   Loss: 0.5781 | Val Loss: 0.5713\n",
      "   Region Acc: 0.9391 | Val: 0.9387\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000050\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.57113\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 284ms/step - band_accuracy: 0.9593 - band_loss: 0.1217 - channel_accuracy: 0.5388 - channel_loss: 1.3936 - loss: 0.5850 - region_accuracy: 0.9360 - region_loss: 0.2222 - state_accuracy: 1.0000 - state_loss: 0.0083 - val_band_accuracy: 0.9683 - val_band_loss: 0.0963 - val_channel_accuracy: 0.5392 - val_channel_loss: 1.3803 - val_loss: 0.5713 - val_region_accuracy: 0.9387 - val_region_loss: 0.2099 - val_state_accuracy: 1.0000 - val_state_loss: 0.0017 - learning_rate: 5.0000e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 16/100\n",
      "======================================================================\n",
      "Epoch 16/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - band_accuracy: 0.9624 - band_loss: 0.1213 - channel_accuracy: 0.5346 - channel_loss: 1.3777 - loss: 0.5741 - region_accuracy: 0.9402 - region_loss: 0.2082 - state_accuracy: 1.0000 - state_loss: 0.0058\n",
      " Epoch 16 done in 76.3s\n",
      "   Loss: 0.5696 | Val Loss: 0.5645\n",
      "   Region Acc: 0.9406 | Val: 0.9389\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000050\n",
      "\n",
      "Epoch 16: val_loss improved from 0.57113 to 0.56450, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 283ms/step - band_accuracy: 0.9624 - band_loss: 0.1212 - channel_accuracy: 0.5346 - channel_loss: 1.3777 - loss: 0.5741 - region_accuracy: 0.9402 - region_loss: 0.2082 - state_accuracy: 1.0000 - state_loss: 0.0058 - val_band_accuracy: 0.9692 - val_band_loss: 0.0967 - val_channel_accuracy: 0.5457 - val_channel_loss: 1.3603 - val_loss: 0.5645 - val_region_accuracy: 0.9389 - val_region_loss: 0.2104 - val_state_accuracy: 1.0000 - val_state_loss: 0.0015 - learning_rate: 4.9983e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 17/100\n",
      "======================================================================\n",
      "Epoch 17/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - band_accuracy: 0.9636 - band_loss: 0.1125 - channel_accuracy: 0.5517 - channel_loss: 1.3256 - loss: 0.5512 - region_accuracy: 0.9454 - region_loss: 0.1988 - state_accuracy: 1.0000 - state_loss: 0.0050\n",
      " Epoch 17 done in 77.2s\n",
      "   Loss: 0.5571 | Val Loss: 0.5694\n",
      "   Region Acc: 0.9451 | Val: 0.9338\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000050\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.56450\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 284ms/step - band_accuracy: 0.9636 - band_loss: 0.1125 - channel_accuracy: 0.5517 - channel_loss: 1.3257 - loss: 0.5512 - region_accuracy: 0.9454 - region_loss: 0.1988 - state_accuracy: 1.0000 - state_loss: 0.0050 - val_band_accuracy: 0.9692 - val_band_loss: 0.1000 - val_channel_accuracy: 0.5254 - val_channel_loss: 1.3686 - val_loss: 0.5694 - val_region_accuracy: 0.9338 - val_region_loss: 0.2142 - val_state_accuracy: 1.0000 - val_state_loss: 0.0029 - learning_rate: 4.9933e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 18/100\n",
      "======================================================================\n",
      "Epoch 18/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - band_accuracy: 0.9642 - band_loss: 0.1146 - channel_accuracy: 0.5468 - channel_loss: 1.3307 - loss: 0.5557 - region_accuracy: 0.9418 - region_loss: 0.2056 - state_accuracy: 1.0000 - state_loss: 0.0053\n",
      " Epoch 18 done in 76.2s\n",
      "   Loss: 0.5481 | Val Loss: 0.5619\n",
      "   Region Acc: 0.9426 | Val: 0.9394\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000050\n",
      "\n",
      "Epoch 18: val_loss improved from 0.56450 to 0.56191, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 283ms/step - band_accuracy: 0.9642 - band_loss: 0.1146 - channel_accuracy: 0.5468 - channel_loss: 1.3307 - loss: 0.5557 - region_accuracy: 0.9418 - region_loss: 0.2055 - state_accuracy: 1.0000 - state_loss: 0.0053 - val_band_accuracy: 0.9683 - val_band_loss: 0.0971 - val_channel_accuracy: 0.5424 - val_channel_loss: 1.3521 - val_loss: 0.5619 - val_region_accuracy: 0.9394 - val_region_loss: 0.2114 - val_state_accuracy: 1.0000 - val_state_loss: 9.3127e-04 - learning_rate: 4.9850e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 19/100\n",
      "======================================================================\n",
      "Epoch 19/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - band_accuracy: 0.9648 - band_loss: 0.1090 - channel_accuracy: 0.5500 - channel_loss: 1.3182 - loss: 0.5440 - region_accuracy: 0.9468 - region_loss: 0.1877 - state_accuracy: 1.0000 - state_loss: 0.0037\n",
      " Epoch 19 done in 77.1s\n",
      "   Loss: 0.5427 | Val Loss: 0.5582\n",
      "   Region Acc: 0.9451 | Val: 0.9382\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000050\n",
      "\n",
      "Epoch 19: val_loss improved from 0.56191 to 0.55823, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 286ms/step - band_accuracy: 0.9648 - band_loss: 0.1090 - channel_accuracy: 0.5500 - channel_loss: 1.3182 - loss: 0.5440 - region_accuracy: 0.9468 - region_loss: 0.1877 - state_accuracy: 1.0000 - state_loss: 0.0037 - val_band_accuracy: 0.9692 - val_band_loss: 0.0953 - val_channel_accuracy: 0.5464 - val_channel_loss: 1.3496 - val_loss: 0.5582 - val_region_accuracy: 0.9382 - val_region_loss: 0.2040 - val_state_accuracy: 1.0000 - val_state_loss: 0.0013 - learning_rate: 4.9733e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 20/100\n",
      "======================================================================\n",
      "Epoch 20/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - band_accuracy: 0.9642 - band_loss: 0.1095 - channel_accuracy: 0.5584 - channel_loss: 1.2799 - loss: 0.5329 - region_accuracy: 0.9426 - region_loss: 0.1939 - state_accuracy: 1.0000 - state_loss: 0.0042\n",
      " Epoch 20 done in 77.1s\n",
      "   Loss: 0.5320 | Val Loss: 0.5522\n",
      "   Region Acc: 0.9438 | Val: 0.9359\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000050\n",
      "\n",
      "Epoch 20: val_loss improved from 0.55823 to 0.55219, saving model to /kaggle/working/checkpoints/best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 286ms/step - band_accuracy: 0.9642 - band_loss: 0.1095 - channel_accuracy: 0.5584 - channel_loss: 1.2799 - loss: 0.5329 - region_accuracy: 0.9426 - region_loss: 0.1939 - state_accuracy: 1.0000 - state_loss: 0.0042 - val_band_accuracy: 0.9681 - val_band_loss: 0.0965 - val_channel_accuracy: 0.5457 - val_channel_loss: 1.3309 - val_loss: 0.5522 - val_region_accuracy: 0.9359 - val_region_loss: 0.2051 - val_state_accuracy: 1.0000 - val_state_loss: 8.7768e-04 - learning_rate: 4.9583e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 21/100\n",
      "======================================================================\n",
      "Epoch 21/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - band_accuracy: 0.9653 - band_loss: 0.1087 - channel_accuracy: 0.5618 - channel_loss: 1.2745 - loss: 0.5289 - region_accuracy: 0.9460 - region_loss: 0.1888 - state_accuracy: 1.0000 - state_loss: 0.0031\n",
      " Epoch 21 done in 76.8s\n",
      "   Loss: 0.5258 | Val Loss: 0.5523\n",
      "   Region Acc: 0.9453 | Val: 0.9405\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000049\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 282ms/step - band_accuracy: 0.9653 - band_loss: 0.1087 - channel_accuracy: 0.5618 - channel_loss: 1.2744 - loss: 0.5289 - region_accuracy: 0.9460 - region_loss: 0.1888 - state_accuracy: 1.0000 - state_loss: 0.0031 - val_band_accuracy: 0.9685 - val_band_loss: 0.0957 - val_channel_accuracy: 0.5492 - val_channel_loss: 1.3323 - val_loss: 0.5523 - val_region_accuracy: 0.9405 - val_region_loss: 0.2043 - val_state_accuracy: 1.0000 - val_state_loss: 8.7341e-04 - learning_rate: 4.9400e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 22/100\n",
      "======================================================================\n",
      "Epoch 22/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - band_accuracy: 0.9632 - band_loss: 0.1085 - channel_accuracy: 0.5760 - channel_loss: 1.2335 - loss: 0.5112 - region_accuracy: 0.9459 - region_loss: 0.1793 - state_accuracy: 1.0000 - state_loss: 0.0027\n",
      " Epoch 22 done in 76.5s\n",
      "   Loss: 0.5153 | Val Loss: 0.5571\n",
      "   Region Acc: 0.9461 | Val: 0.9352\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000049\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 281ms/step - band_accuracy: 0.9632 - band_loss: 0.1084 - channel_accuracy: 0.5760 - channel_loss: 1.2336 - loss: 0.5112 - region_accuracy: 0.9459 - region_loss: 0.1793 - state_accuracy: 1.0000 - state_loss: 0.0027 - val_band_accuracy: 0.9662 - val_band_loss: 0.0992 - val_channel_accuracy: 0.5562 - val_channel_loss: 1.3335 - val_loss: 0.5571 - val_region_accuracy: 0.9352 - val_region_loss: 0.2154 - val_state_accuracy: 1.0000 - val_state_loss: 5.4989e-04 - learning_rate: 4.9185e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 23/100\n",
      "======================================================================\n",
      "Epoch 23/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - band_accuracy: 0.9641 - band_loss: 0.1035 - channel_accuracy: 0.5803 - channel_loss: 1.2186 - loss: 0.5043 - region_accuracy: 0.9445 - region_loss: 0.1769 - state_accuracy: 1.0000 - state_loss: 0.0023\n",
      " Epoch 23 done in 76.5s\n",
      "   Loss: 0.5039 | Val Loss: 0.5622\n",
      "   Region Acc: 0.9477 | Val: 0.9387\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000049\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 281ms/step - band_accuracy: 0.9641 - band_loss: 0.1035 - channel_accuracy: 0.5803 - channel_loss: 1.2186 - loss: 0.5043 - region_accuracy: 0.9445 - region_loss: 0.1769 - state_accuracy: 1.0000 - state_loss: 0.0023 - val_band_accuracy: 0.9694 - val_band_loss: 0.0956 - val_channel_accuracy: 0.5541 - val_channel_loss: 1.3438 - val_loss: 0.5622 - val_region_accuracy: 0.9387 - val_region_loss: 0.2214 - val_state_accuracy: 1.0000 - val_state_loss: 3.5567e-04 - learning_rate: 4.8937e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 24/100\n",
      "======================================================================\n",
      "Epoch 24/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - band_accuracy: 0.9660 - band_loss: 0.1011 - channel_accuracy: 0.5857 - channel_loss: 1.2021 - loss: 0.4957 - region_accuracy: 0.9509 - region_loss: 0.1699 - state_accuracy: 1.0000 - state_loss: 0.0021\n",
      " Epoch 24 done in 76.4s\n",
      "   Loss: 0.4932 | Val Loss: 0.5540\n",
      "   Region Acc: 0.9505 | Val: 0.9377\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000049\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 281ms/step - band_accuracy: 0.9660 - band_loss: 0.1011 - channel_accuracy: 0.5857 - channel_loss: 1.2021 - loss: 0.4957 - region_accuracy: 0.9509 - region_loss: 0.1699 - state_accuracy: 1.0000 - state_loss: 0.0021 - val_band_accuracy: 0.9685 - val_band_loss: 0.0953 - val_channel_accuracy: 0.5576 - val_channel_loss: 1.3348 - val_loss: 0.5540 - val_region_accuracy: 0.9377 - val_region_loss: 0.2068 - val_state_accuracy: 1.0000 - val_state_loss: 7.6381e-04 - learning_rate: 4.8657e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 25/100\n",
      "======================================================================\n",
      "Epoch 25/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - band_accuracy: 0.9667 - band_loss: 0.0986 - channel_accuracy: 0.5912 - channel_loss: 1.1801 - loss: 0.4864 - region_accuracy: 0.9484 - region_loss: 0.1664 - state_accuracy: 1.0000 - state_loss: 0.0024\n",
      " Epoch 25 done in 76.6s\n",
      "   Loss: 0.4835 | Val Loss: 0.5631\n",
      "   Region Acc: 0.9502 | Val: 0.9368\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000048\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 281ms/step - band_accuracy: 0.9667 - band_loss: 0.0986 - channel_accuracy: 0.5912 - channel_loss: 1.1801 - loss: 0.4864 - region_accuracy: 0.9484 - region_loss: 0.1664 - state_accuracy: 1.0000 - state_loss: 0.0024 - val_band_accuracy: 0.9676 - val_band_loss: 0.0942 - val_channel_accuracy: 0.5578 - val_channel_loss: 1.3474 - val_loss: 0.5631 - val_region_accuracy: 0.9368 - val_region_loss: 0.2207 - val_state_accuracy: 1.0000 - val_state_loss: 5.3293e-04 - learning_rate: 4.8346e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 26/100\n",
      "======================================================================\n",
      "Epoch 26/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - band_accuracy: 0.9682 - band_loss: 0.0974 - channel_accuracy: 0.5969 - channel_loss: 1.1556 - loss: 0.4762 - region_accuracy: 0.9507 - region_loss: 0.1626 - state_accuracy: 1.0000 - state_loss: 0.0017\n",
      " Epoch 26 done in 76.6s\n",
      "   Loss: 0.4737 | Val Loss: 0.5553\n",
      "   Region Acc: 0.9516 | Val: 0.9340\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000048\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 282ms/step - band_accuracy: 0.9682 - band_loss: 0.0974 - channel_accuracy: 0.5969 - channel_loss: 1.1555 - loss: 0.4762 - region_accuracy: 0.9507 - region_loss: 0.1626 - state_accuracy: 1.0000 - state_loss: 0.0017 - val_band_accuracy: 0.9692 - val_band_loss: 0.0946 - val_channel_accuracy: 0.5590 - val_channel_loss: 1.3302 - val_loss: 0.5553 - val_region_accuracy: 0.9340 - val_region_loss: 0.2154 - val_state_accuracy: 1.0000 - val_state_loss: 6.9407e-04 - learning_rate: 4.8003e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 27/100\n",
      "======================================================================\n",
      "Epoch 27/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - band_accuracy: 0.9685 - band_loss: 0.0950 - channel_accuracy: 0.6051 - channel_loss: 1.1269 - loss: 0.4600 - region_accuracy: 0.9552 - region_loss: 0.1460 - state_accuracy: 1.0000 - state_loss: 0.0017\n",
      " Epoch 27 done in 76.3s\n",
      "   Loss: 0.4581 | Val Loss: 0.5677\n",
      "   Region Acc: 0.9550 | Val: 0.9342\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000048\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 280ms/step - band_accuracy: 0.9685 - band_loss: 0.0950 - channel_accuracy: 0.6051 - channel_loss: 1.1268 - loss: 0.4600 - region_accuracy: 0.9552 - region_loss: 0.1460 - state_accuracy: 1.0000 - state_loss: 0.0017 - val_band_accuracy: 0.9676 - val_band_loss: 0.0954 - val_channel_accuracy: 0.5450 - val_channel_loss: 1.3685 - val_loss: 0.5677 - val_region_accuracy: 0.9342 - val_region_loss: 0.2124 - val_state_accuracy: 1.0000 - val_state_loss: 4.1974e-04 - learning_rate: 4.7630e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 28/100\n",
      "======================================================================\n",
      "Epoch 28/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - band_accuracy: 0.9689 - band_loss: 0.0956 - channel_accuracy: 0.6172 - channel_loss: 1.0973 - loss: 0.4473 - region_accuracy: 0.9565 - region_loss: 0.1392 - state_accuracy: 1.0000 - state_loss: 0.0014\n",
      " Epoch 28 done in 76.3s\n",
      "   Loss: 0.4472 | Val Loss: 0.5582\n",
      "   Region Acc: 0.9571 | Val: 0.9389\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000047\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 280ms/step - band_accuracy: 0.9688 - band_loss: 0.0956 - channel_accuracy: 0.6172 - channel_loss: 1.0972 - loss: 0.4473 - region_accuracy: 0.9565 - region_loss: 0.1392 - state_accuracy: 1.0000 - state_loss: 0.0014 - val_band_accuracy: 0.9671 - val_band_loss: 0.0956 - val_channel_accuracy: 0.5560 - val_channel_loss: 1.3385 - val_loss: 0.5582 - val_region_accuracy: 0.9389 - val_region_loss: 0.2151 - val_state_accuracy: 1.0000 - val_state_loss: 3.0566e-04 - learning_rate: 4.7226e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 29/100\n",
      "======================================================================\n",
      "Epoch 29/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - band_accuracy: 0.9662 - band_loss: 0.0942 - channel_accuracy: 0.6252 - channel_loss: 1.0670 - loss: 0.4352 - region_accuracy: 0.9587 - region_loss: 0.1354 - state_accuracy: 1.0000 - state_loss: 0.0017\n",
      " Epoch 29 done in 76.7s\n",
      "   Loss: 0.4347 | Val Loss: 0.5632\n",
      "   Region Acc: 0.9579 | Val: 0.9389\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000047\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 282ms/step - band_accuracy: 0.9662 - band_loss: 0.0942 - channel_accuracy: 0.6252 - channel_loss: 1.0670 - loss: 0.4352 - region_accuracy: 0.9587 - region_loss: 0.1354 - state_accuracy: 1.0000 - state_loss: 0.0017 - val_band_accuracy: 0.9694 - val_band_loss: 0.0954 - val_channel_accuracy: 0.5546 - val_channel_loss: 1.3563 - val_loss: 0.5632 - val_region_accuracy: 0.9389 - val_region_loss: 0.2118 - val_state_accuracy: 1.0000 - val_state_loss: 2.1018e-04 - learning_rate: 4.6793e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 30/100\n",
      "======================================================================\n",
      "Epoch 30/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - band_accuracy: 0.9678 - band_loss: 0.0939 - channel_accuracy: 0.6333 - channel_loss: 1.0312 - loss: 0.4193 - region_accuracy: 0.9606 - region_loss: 0.1261 - state_accuracy: 1.0000 - state_loss: 0.0012\n",
      " Epoch 30 done in 76.2s\n",
      "   Loss: 0.4194 | Val Loss: 0.5559\n",
      "   Region Acc: 0.9603 | Val: 0.9391\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000046\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 280ms/step - band_accuracy: 0.9678 - band_loss: 0.0939 - channel_accuracy: 0.6333 - channel_loss: 1.0312 - loss: 0.4193 - region_accuracy: 0.9606 - region_loss: 0.1261 - state_accuracy: 1.0000 - state_loss: 0.0012 - val_band_accuracy: 0.9704 - val_band_loss: 0.0947 - val_channel_accuracy: 0.5599 - val_channel_loss: 1.3280 - val_loss: 0.5559 - val_region_accuracy: 0.9391 - val_region_loss: 0.2196 - val_state_accuracy: 1.0000 - val_state_loss: 3.8761e-04 - learning_rate: 4.6330e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 31/100\n",
      "======================================================================\n",
      "Epoch 31/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - band_accuracy: 0.9720 - band_loss: 0.0827 - channel_accuracy: 0.6446 - channel_loss: 0.9954 - loss: 0.4026 - region_accuracy: 0.9627 - region_loss: 0.1190 - state_accuracy: 1.0000 - state_loss: 0.0013\n",
      " Epoch 31 done in 76.2s\n",
      "   Loss: 0.4051 | Val Loss: 0.5725\n",
      "   Region Acc: 0.9615 | Val: 0.9361\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000046\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 280ms/step - band_accuracy: 0.9720 - band_loss: 0.0827 - channel_accuracy: 0.6446 - channel_loss: 0.9954 - loss: 0.4026 - region_accuracy: 0.9627 - region_loss: 0.1190 - state_accuracy: 1.0000 - state_loss: 0.0013 - val_band_accuracy: 0.9678 - val_band_loss: 0.0941 - val_channel_accuracy: 0.5543 - val_channel_loss: 1.3730 - val_loss: 0.5725 - val_region_accuracy: 0.9361 - val_region_loss: 0.2220 - val_state_accuracy: 1.0000 - val_state_loss: 6.5759e-04 - learning_rate: 4.5840e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 32/100\n",
      "======================================================================\n",
      "Epoch 32/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - band_accuracy: 0.9717 - band_loss: 0.0850 - channel_accuracy: 0.6657 - channel_loss: 0.9477 - loss: 0.3841 - region_accuracy: 0.9651 - region_loss: 0.1129 - state_accuracy: 1.0000 - state_loss: 0.0012\n",
      " Epoch 32 done in 76.4s\n",
      "   Loss: 0.3898 | Val Loss: 0.5791\n",
      "   Region Acc: 0.9648 | Val: 0.9382\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000045\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 281ms/step - band_accuracy: 0.9716 - band_loss: 0.0850 - channel_accuracy: 0.6657 - channel_loss: 0.9477 - loss: 0.3841 - region_accuracy: 0.9651 - region_loss: 0.1129 - state_accuracy: 1.0000 - state_loss: 0.0012 - val_band_accuracy: 0.9720 - val_band_loss: 0.0974 - val_channel_accuracy: 0.5613 - val_channel_loss: 1.3865 - val_loss: 0.5791 - val_region_accuracy: 0.9382 - val_region_loss: 0.2261 - val_state_accuracy: 1.0000 - val_state_loss: 1.9504e-04 - learning_rate: 4.5321e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 33/100\n",
      "======================================================================\n",
      "Epoch 33/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - band_accuracy: 0.9707 - band_loss: 0.0860 - channel_accuracy: 0.6686 - channel_loss: 0.9254 - loss: 0.3724 - region_accuracy: 0.9673 - region_loss: 0.1014 - state_accuracy: 1.0000 - state_loss: 0.0011\n",
      " Epoch 33 done in 76.0s\n",
      "   Loss: 0.3782 | Val Loss: 0.5784\n",
      "   Region Acc: 0.9682 | Val: 0.9368\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000045\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 279ms/step - band_accuracy: 0.9707 - band_loss: 0.0860 - channel_accuracy: 0.6686 - channel_loss: 0.9255 - loss: 0.3724 - region_accuracy: 0.9673 - region_loss: 0.1014 - state_accuracy: 1.0000 - state_loss: 0.0011 - val_band_accuracy: 0.9699 - val_band_loss: 0.0940 - val_channel_accuracy: 0.5574 - val_channel_loss: 1.3825 - val_loss: 0.5784 - val_region_accuracy: 0.9368 - val_region_loss: 0.2295 - val_state_accuracy: 1.0000 - val_state_loss: 3.4328e-04 - learning_rate: 4.4775e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 34/100\n",
      "======================================================================\n",
      "Epoch 34/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - band_accuracy: 0.9705 - band_loss: 0.0844 - channel_accuracy: 0.6937 - channel_loss: 0.8779 - loss: 0.3531 - region_accuracy: 0.9694 - region_loss: 0.0944 - state_accuracy: 1.0000 - state_loss: 9.5234e-04\n",
      " Epoch 34 done in 76.1s\n",
      "   Loss: 0.3617 | Val Loss: 0.6001\n",
      "   Region Acc: 0.9696 | Val: 0.9340\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000044\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 280ms/step - band_accuracy: 0.9705 - band_loss: 0.0844 - channel_accuracy: 0.6937 - channel_loss: 0.8780 - loss: 0.3532 - region_accuracy: 0.9694 - region_loss: 0.0944 - state_accuracy: 1.0000 - state_loss: 9.5242e-04 - val_band_accuracy: 0.9715 - val_band_loss: 0.0935 - val_channel_accuracy: 0.5452 - val_channel_loss: 1.4339 - val_loss: 0.6001 - val_region_accuracy: 0.9340 - val_region_loss: 0.2406 - val_state_accuracy: 1.0000 - val_state_loss: 2.0457e-04 - learning_rate: 4.4203e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 35/100\n",
      "======================================================================\n",
      "Epoch 35/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - band_accuracy: 0.9723 - band_loss: 0.0821 - channel_accuracy: 0.6895 - channel_loss: 0.8747 - loss: 0.3486 - region_accuracy: 0.9715 - region_loss: 0.0860 - state_accuracy: 1.0000 - state_loss: 7.2742e-04\n",
      " Epoch 35 done in 76.5s\n",
      "   Loss: 0.3487 | Val Loss: 0.6222\n",
      "   Region Acc: 0.9696 | Val: 0.9314\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000044\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 281ms/step - band_accuracy: 0.9723 - band_loss: 0.0821 - channel_accuracy: 0.6895 - channel_loss: 0.8746 - loss: 0.3486 - region_accuracy: 0.9715 - region_loss: 0.0860 - state_accuracy: 1.0000 - state_loss: 7.2764e-04 - val_band_accuracy: 0.9697 - val_band_loss: 0.0949 - val_channel_accuracy: 0.5606 - val_channel_loss: 1.4575 - val_loss: 0.6222 - val_region_accuracy: 0.9314 - val_region_loss: 0.2796 - val_state_accuracy: 1.0000 - val_state_loss: 2.5780e-04 - learning_rate: 4.3606e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 36/100\n",
      "======================================================================\n",
      "Epoch 36/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - band_accuracy: 0.9736 - band_loss: 0.0788 - channel_accuracy: 0.7087 - channel_loss: 0.8237 - loss: 0.3296 - region_accuracy: 0.9740 - region_loss: 0.0839 - state_accuracy: 1.0000 - state_loss: 8.8042e-04\n",
      " Epoch 36 done in 76.1s\n",
      "   Loss: 0.3333 | Val Loss: 0.6237\n",
      "   Region Acc: 0.9742 | Val: 0.9398\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000043\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 279ms/step - band_accuracy: 0.9736 - band_loss: 0.0788 - channel_accuracy: 0.7086 - channel_loss: 0.8238 - loss: 0.3297 - region_accuracy: 0.9740 - region_loss: 0.0839 - state_accuracy: 1.0000 - state_loss: 8.8012e-04 - val_band_accuracy: 0.9718 - val_band_loss: 0.0941 - val_channel_accuracy: 0.5679 - val_channel_loss: 1.4890 - val_loss: 0.6237 - val_region_accuracy: 0.9398 - val_region_loss: 0.2526 - val_state_accuracy: 1.0000 - val_state_loss: 1.6298e-04 - learning_rate: 4.2983e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 37/100\n",
      "======================================================================\n",
      "Epoch 37/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - band_accuracy: 0.9755 - band_loss: 0.0791 - channel_accuracy: 0.7137 - channel_loss: 0.7941 - loss: 0.3139 - region_accuracy: 0.9766 - region_loss: 0.0685 - state_accuracy: 1.0000 - state_loss: 8.2650e-04\n",
      " Epoch 37 done in 76.2s\n",
      "   Loss: 0.3195 | Val Loss: 0.6429\n",
      "   Region Acc: 0.9739 | Val: 0.9377\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000042\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 280ms/step - band_accuracy: 0.9755 - band_loss: 0.0791 - channel_accuracy: 0.7137 - channel_loss: 0.7941 - loss: 0.3139 - region_accuracy: 0.9766 - region_loss: 0.0685 - state_accuracy: 1.0000 - state_loss: 8.2625e-04 - val_band_accuracy: 0.9718 - val_band_loss: 0.0932 - val_channel_accuracy: 0.5590 - val_channel_loss: 1.5206 - val_loss: 0.6429 - val_region_accuracy: 0.9377 - val_region_loss: 0.2762 - val_state_accuracy: 1.0000 - val_state_loss: 1.6916e-04 - learning_rate: 4.2337e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 38/100\n",
      "======================================================================\n",
      "Epoch 38/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - band_accuracy: 0.9712 - band_loss: 0.0815 - channel_accuracy: 0.7300 - channel_loss: 0.7618 - loss: 0.3033 - region_accuracy: 0.9768 - region_loss: 0.0696 - state_accuracy: 1.0000 - state_loss: 6.3432e-04\n",
      " Epoch 38 done in 76.2s\n",
      "   Loss: 0.3071 | Val Loss: 0.6343\n",
      "   Region Acc: 0.9770 | Val: 0.9389\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000042\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 280ms/step - band_accuracy: 0.9712 - band_loss: 0.0815 - channel_accuracy: 0.7300 - channel_loss: 0.7619 - loss: 0.3033 - region_accuracy: 0.9768 - region_loss: 0.0696 - state_accuracy: 1.0000 - state_loss: 6.3416e-04 - val_band_accuracy: 0.9704 - val_band_loss: 0.0955 - val_channel_accuracy: 0.5513 - val_channel_loss: 1.5118 - val_loss: 0.6343 - val_region_accuracy: 0.9389 - val_region_loss: 0.2595 - val_state_accuracy: 1.0000 - val_state_loss: 2.1189e-04 - learning_rate: 4.1668e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 39/100\n",
      "======================================================================\n",
      "Epoch 39/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - band_accuracy: 0.9715 - band_loss: 0.0844 - channel_accuracy: 0.7427 - channel_loss: 0.7240 - loss: 0.2871 - region_accuracy: 0.9805 - region_loss: 0.0599 - state_accuracy: 1.0000 - state_loss: 7.6859e-04\n",
      " Epoch 39 done in 76.5s\n",
      "   Loss: 0.2869 | Val Loss: 0.6771\n",
      "   Region Acc: 0.9796 | Val: 0.9394\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000041\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 281ms/step - band_accuracy: 0.9715 - band_loss: 0.0844 - channel_accuracy: 0.7427 - channel_loss: 0.7240 - loss: 0.2871 - region_accuracy: 0.9805 - region_loss: 0.0599 - state_accuracy: 1.0000 - state_loss: 7.6778e-04 - val_band_accuracy: 0.9715 - val_band_loss: 0.0993 - val_channel_accuracy: 0.5564 - val_channel_loss: 1.5998 - val_loss: 0.6771 - val_region_accuracy: 0.9394 - val_region_loss: 0.2921 - val_state_accuracy: 1.0000 - val_state_loss: 9.6780e-05 - learning_rate: 4.0977e-05\n",
      "\n",
      "======================================================================\n",
      " Epoch 40/100\n",
      "======================================================================\n",
      "Epoch 40/100\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - band_accuracy: 0.9728 - band_loss: 0.0787 - channel_accuracy: 0.7540 - channel_loss: 0.6871 - loss: 0.2720 - region_accuracy: 0.9822 - region_loss: 0.0561 - state_accuracy: 1.0000 - state_loss: 5.7411e-04\n",
      " Epoch 40 done in 76.7s\n",
      "   Loss: 0.2793 | Val Loss: 0.6812\n",
      "   Region Acc: 0.9811 | Val: 0.9438\n",
      "======================================================================\n",
      "\n",
      "\n",
      "   LR = 0.000040\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.55219\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 282ms/step - band_accuracy: 0.9728 - band_loss: 0.0787 - channel_accuracy: 0.7540 - channel_loss: 0.6872 - loss: 0.2720 - region_accuracy: 0.9822 - region_loss: 0.0561 - state_accuracy: 1.0000 - state_loss: 5.7394e-04 - val_band_accuracy: 0.9727 - val_band_loss: 0.0992 - val_channel_accuracy: 0.5520 - val_channel_loss: 1.6161 - val_loss: 0.6812 - val_region_accuracy: 0.9438 - val_region_loss: 0.2876 - val_state_accuracy: 1.0000 - val_state_loss: 5.9154e-05 - learning_rate: 4.0265e-05\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\n",
      "======================================================================\n",
      "‚úÖ TRAINING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üìÅ Saved to: /kaggle/working/checkpoints\n",
      "   - final_model.keras\n",
      "   - best_model.keras\n",
      "\n",
      " Training Summary:\n",
      "   Best val_loss: 0.5522\n",
      "   Final region acc: 0.9811\n",
      "\n",
      " Next: Click 'Save Version' to commit checkpoints!\n"
     ]
    }
   ],
   "source": [
    "history = train_cognivue()\n",
    "\n",
    "if history:\n",
    "    print(\"\\n Training Summary:\")\n",
    "    print(f\"   Best val_loss: {min(history.history['val_loss']):.4f}\")\n",
    "    print(f\"   Final region acc: {history.history['region_accuracy'][-1]:.4f}\")\n",
    "    print(f\"\\n Next: Click 'Save Version' to commit checkpoints!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Training did not complete successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c58ae1",
   "metadata": {
    "papermill": {
     "duration": 0.495859,
     "end_time": "2025-12-30T14:19:21.570220",
     "exception": false,
     "start_time": "2025-12-30T14:19:21.074361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "10: Save Training Results & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7814517f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T14:19:22.637043Z",
     "iopub.status.busy": "2025-12-30T14:19:22.636766Z",
     "iopub.status.idle": "2025-12-30T14:19:24.544085Z",
     "shell.execute_reply": "2025-12-30T14:19:24.543138Z"
    },
    "papermill": {
     "duration": 2.406656,
     "end_time": "2025-12-30T14:19:24.545640",
     "exception": false,
     "start_time": "2025-12-30T14:19:22.138984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saving training results...\n",
      "   Saved: training_history.json\n",
      "\n",
      " Loading train data from: /kaggle/input/processed/train/train_data.pkl\n",
      "   Loaded 21,538 samples\n",
      "\n",
      "  Data format:\n",
      "     X shape: (58, 256) (channels, time)\n",
      "     bp shape: (58, 5) (channels, bands)\n",
      "     Channels: 58\n",
      "\n",
      "   Converting to arrays...\n",
      "   Final shapes:\n",
      "     X_eeg: (21538, 256, 58) (N, time, channels)\n",
      "     X_bp: (21538, 290) (N, features)\n",
      "     X_task: (21538,)\n",
      "     Labels: (21538,) each\n",
      "   Saved: training_config.json\n",
      "   Saved: TRAINING_SUMMARY.md\n",
      "\n",
      " All results saved!\n",
      "\n",
      " Saved files:\n",
      "   /kaggle/working/results/\n",
      "   ‚îú‚îÄ‚îÄ training_history.json\n",
      "   ‚îú‚îÄ‚îÄ training_config.json\n",
      "   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\n",
      "\n",
      "   /kaggle/working/checkpoints/\n",
      "   ‚îú‚îÄ‚îÄ best_model.keras\n",
      "   ‚îú‚îÄ‚îÄ final_model.keras\n",
      "   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\n"
     ]
    }
   ],
   "source": [
    "if history:\n",
    "    print(\"\\n Saving training results...\")\n",
    "    \n",
    "    # Convert history to JSON-serializable format\n",
    "    history_dict = {\n",
    "        key: [float(val) for val in values] \n",
    "        for key, values in history.history.items()\n",
    "    }\n",
    "    \n",
    "    # Save training history\n",
    "    history_path = os.path.join(RESULTS_DIR, 'training_history.json')\n",
    "    with open(history_path, 'w') as f:\n",
    "        json.dump(history_dict, f, indent=2)\n",
    "    print(f\"   Saved: training_history.json\")\n",
    "    \n",
    "    # Get model dimensions from loaded data\n",
    "    train_result = load_preprocessed_data('train')\n",
    "    if train_result:\n",
    "        _, _, train_meta = train_result\n",
    "        NUM_CHANNELS_USED = train_meta['num_channels']\n",
    "    else:\n",
    "        NUM_CHANNELS_USED = \"unknown\"\n",
    "    \n",
    "    # Save training configuration\n",
    "    config = {\n",
    "        'model_architecture': {\n",
    "            'name': 'CogniVue_Transformer',\n",
    "            'num_input_channels': NUM_CHANNELS_USED,\n",
    "            'd_model': D_MODEL,\n",
    "            'num_layers': NUM_LAYERS,\n",
    "            'num_heads': NUM_HEADS,\n",
    "            'ff_dim': FF_DIM,\n",
    "            'dropout': DROPOUT,\n",
    "            'window_size': WINDOW_SIZE_SAMPLES\n",
    "        },\n",
    "        'training_params': {\n",
    "            'epochs_trained': len(history.history['loss']),\n",
    "            'total_epochs': EPOCHS,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'initial_lr': INITIAL_LR,\n",
    "            'warmup_epochs': WARMUP_EPOCHS,\n",
    "            'weight_decay': WEIGHT_DECAY,\n",
    "            'gradient_clip_norm': GRADIENT_CLIP_NORM\n",
    "        },\n",
    "        'output_tasks': {\n",
    "            'num_output_channels': NUM_OUTPUT_REGIONS,\n",
    "            'num_regions': NUM_OUTPUT_REGIONS,\n",
    "            'num_bands': NUM_OUTPUT_BANDS,\n",
    "            'num_states': NUM_OUTPUT_STATES\n",
    "        },\n",
    "        'final_metrics': {\n",
    "            'best_val_loss': float(min(history.history['val_loss'])),\n",
    "            'final_train_loss': float(history.history['loss'][-1]),\n",
    "            'final_val_loss': float(history.history['val_loss'][-1]),\n",
    "            'final_region_accuracy': float(history.history['region_accuracy'][-1]),\n",
    "            'final_val_region_accuracy': float(history.history['val_region_accuracy'][-1])\n",
    "        },\n",
    "        'training_info': {\n",
    "            'completed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'tensorflow_version': tf.__version__,\n",
    "            'accelerator': 'TPU' if 'TPU' in str(strategy.__class__) else 'CPU/GPU'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config_path = os.path.join(RESULTS_DIR, 'training_config.json')\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    print(f\"   Saved: training_config.json\")\n",
    "    \n",
    "    # Create a summary markdown file\n",
    "    summary_md = f\"\"\"# CogniVue Training Summary\n",
    "\n",
    "**Training Completed:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Model Architecture\n",
    "- **Model:** CogniVue Transformer\n",
    "- **Input Channels:** {NUM_CHANNELS_USED}\n",
    "- **Model Dimension:** {D_MODEL}\n",
    "- **Transformer Layers:** {NUM_LAYERS}\n",
    "- **Attention Heads:** {NUM_HEADS}\n",
    "- **Feedforward Dim:** {FF_DIM}\n",
    "- **Dropout:** {DROPOUT}\n",
    "\n",
    "## Training Configuration\n",
    "- **Epochs:** {len(history.history['loss'])}/{EPOCHS}\n",
    "- **Batch Size:** {BATCH_SIZE}\n",
    "- **Initial LR:** {INITIAL_LR}\n",
    "- **Warmup Epochs:** {WARMUP_EPOCHS}\n",
    "- **Weight Decay:** {WEIGHT_DECAY}\n",
    "\n",
    "## Final Performance\n",
    "- **Best Val Loss:** {min(history.history['val_loss']):.4f}\n",
    "- **Final Train Loss:** {history.history['loss'][-1]:.4f}\n",
    "- **Final Val Loss:** {history.history['val_loss'][-1]:.4f}\n",
    "- **Final Region Accuracy:** {history.history['region_accuracy'][-1]:.4f}\n",
    "- **Final Val Region Accuracy:** {history.history['val_region_accuracy'][-1]:.4f}\n",
    "\n",
    "## Output Files\n",
    "- `checkpoints/best_model.keras` - Best model weights\n",
    "- `checkpoints/final_model.keras` - Final model weights\n",
    "- `checkpoints/checkpoint_epoch_*.keras` - Periodic checkpoints\n",
    "- `results/training_history.json` - Loss and metrics per epoch\n",
    "- `results/training_config.json` - Full configuration\n",
    "- `logs/` - TensorBoard logs\n",
    "\"\"\"\n",
    "    \n",
    "    summary_path = os.path.join(RESULTS_DIR, 'TRAINING_SUMMARY.md')\n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write(summary_md)\n",
    "    print(f\"   Saved: TRAINING_SUMMARY.md\")\n",
    "    \n",
    "    print(\"\\n All results saved!\")\n",
    "    print(f\"\\n Saved files:\")\n",
    "    print(f\"   {RESULTS_DIR}/\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ training_history.json\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ training_config.json\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\")\n",
    "    print(f\"\\n   {CHECKPOINT_DIR}/\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ best_model.keras\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ final_model.keras\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No training history to save\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc0bdd",
   "metadata": {
    "papermill": {
     "duration": 0.573216,
     "end_time": "2025-12-30T14:19:25.611726",
     "exception": false,
     "start_time": "2025-12-30T14:19:25.038510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "11: Package & Download All Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f103c1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T14:19:26.593741Z",
     "iopub.status.busy": "2025-12-30T14:19:26.593448Z",
     "iopub.status.idle": "2025-12-30T14:19:32.802042Z",
     "shell.execute_reply": "2025-12-30T14:19:32.801146Z"
    },
    "papermill": {
     "duration": 6.7011,
     "end_time": "2025-12-30T14:19:32.803621",
     "exception": false,
     "start_time": "2025-12-30T14:19:26.102521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Creating download package...\n",
      "======================================================================\n",
      "\n",
      " Adding results...\n",
      "   training_config.json\n",
      "   training_history.json\n",
      "   TRAINING_SUMMARY.md\n",
      "\n",
      "üîñ Adding checkpoints...\n",
      "   final_model.keras (58.2 MB)\n",
      "   best_model.keras (58.2 MB)\n",
      "\n",
      " Adding TensorBoard logs...\n",
      "   Added 2 log files\n",
      "\n",
      "======================================================================\n",
      " PACKAGE CREATED SUCCESSFULLY!\n",
      "======================================================================\n",
      "\n",
      " Zip file: cognivue_training_outputs_20251230_141926.zip\n",
      " Size: 105.0 MB\n",
      " Location: /kaggle/working/cognivue_training_outputs_20251230_141926.zip\n",
      "\n",
      " To download:\n",
      "   1. Go to the 'Output' tab (top right)\n",
      "   2. Click 'Save Version' to commit outputs\n",
      "   3. Download 'cognivue_training_outputs_20251230_141926.zip'\n",
      "\n",
      " Or click the download icon next to the file in the Output tab\n",
      "\n",
      " Package contents:\n",
      "   Total files: 7\n",
      "\n",
      "   Structure:\n",
      "   ‚îú‚îÄ‚îÄ results/\n",
      "   ‚îÇ   ‚îú‚îÄ‚îÄ training_history.json\n",
      "   ‚îÇ   ‚îú‚îÄ‚îÄ training_config.json\n",
      "   ‚îÇ   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\n",
      "   ‚îú‚îÄ‚îÄ checkpoints/\n",
      "   ‚îÇ   ‚îú‚îÄ‚îÄ best_model.keras\n",
      "   ‚îÇ   ‚îú‚îÄ‚îÄ final_model.keras\n",
      "   ‚îÇ   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\n",
      "   ‚îî‚îÄ‚îÄ logs/\n",
      "       ‚îî‚îÄ‚îÄ TensorBoard logs\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# Section 11: Package & Download All Outputs\n",
    "# ============================================================\n",
    "\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n Creating download package...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create zip filename with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "zip_filename = f\"cognivue_training_outputs_{timestamp}.zip\"\n",
    "zip_path = os.path.join(WORKING_DIR, zip_filename)\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        \n",
    "        # Add all files from results directory\n",
    "        print(\"\\n Adding results...\")\n",
    "        if os.path.exists(RESULTS_DIR):\n",
    "            for file in os.listdir(RESULTS_DIR):\n",
    "                file_path = os.path.join(RESULTS_DIR, file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    arcname = os.path.join('results', file)\n",
    "                    zipf.write(file_path, arcname)\n",
    "                    print(f\"   {file}\")\n",
    "        \n",
    "        # Add all checkpoint files\n",
    "        print(\"\\nüîñ Adding checkpoints...\")\n",
    "        if os.path.exists(CHECKPOINT_DIR):\n",
    "            for file in os.listdir(CHECKPOINT_DIR):\n",
    "                file_path = os.path.join(CHECKPOINT_DIR, file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    arcname = os.path.join('checkpoints', file)\n",
    "                    zipf.write(file_path, arcname)\n",
    "                    file_size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "                    print(f\"   {file} ({file_size_mb:.1f} MB)\")\n",
    "        \n",
    "        # Add TensorBoard logs (optional - can be large)\n",
    "        print(\"\\n Adding TensorBoard logs...\")\n",
    "        if os.path.exists(LOGS_DIR):\n",
    "            log_count = 0\n",
    "            for root, dirs, files in os.walk(LOGS_DIR):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.join('logs', os.path.relpath(file_path, LOGS_DIR))\n",
    "                    zipf.write(file_path, arcname)\n",
    "                    log_count += 1\n",
    "            print(f\"   Added {log_count} log files\")\n",
    "    \n",
    "    # Get final zip size\n",
    "    zip_size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\" PACKAGE CREATED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\n Zip file: {zip_filename}\")\n",
    "    print(f\" Size: {zip_size_mb:.1f} MB\")\n",
    "    print(f\" Location: {zip_path}\")\n",
    "    \n",
    "    print(\"\\n To download:\")\n",
    "    print(\"   1. Go to the 'Output' tab (top right)\")\n",
    "    print(\"   2. Click 'Save Version' to commit outputs\")\n",
    "    print(f\"   3. Download '{zip_filename}'\")\n",
    "    print(\"\\n Or click the download icon next to the file in the Output tab\")\n",
    "    \n",
    "    # List contents\n",
    "    print(\"\\n Package contents:\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "        file_list = zipf.namelist()\n",
    "        print(f\"   Total files: {len(file_list)}\")\n",
    "        print(\"\\n   Structure:\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ results/\")\n",
    "        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ training_history.json\")\n",
    "        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ training_config.json\")\n",
    "        print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ checkpoints/\")\n",
    "        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ best_model.keras\")\n",
    "        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ final_model.keras\")\n",
    "        print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\")\n",
    "        print(\"   ‚îî‚îÄ‚îÄ logs/\")\n",
    "        print(\"       ‚îî‚îÄ‚îÄ TensorBoard logs\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error creating zip: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00e3491f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T14:19:33.869499Z",
     "iopub.status.busy": "2025-12-30T14:19:33.869116Z",
     "iopub.status.idle": "2025-12-30T14:19:33.873353Z",
     "shell.execute_reply": "2025-12-30T14:19:33.872623Z"
    },
    "papermill": {
     "duration": 0.580408,
     "end_time": "2025-12-30T14:19:33.874796",
     "exception": false,
     "start_time": "2025-12-30T14:19:33.294388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['results', 'cognivue_training_outputs_20251230_141926.zip', '__notebook__.ipynb', 'logs', 'checkpoints']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('/kaggle/working/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efa810c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T14:19:34.862913Z",
     "iopub.status.busy": "2025-12-30T14:19:34.862178Z",
     "iopub.status.idle": "2025-12-30T14:19:34.870234Z",
     "shell.execute_reply": "2025-12-30T14:19:34.869595Z"
    },
    "papermill": {
     "duration": 0.505415,
     "end_time": "2025-12-30T14:19:34.871684",
     "exception": false,
     "start_time": "2025-12-30T14:19:34.366269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "‚úÖ LATEST PACKAGE FOUND: cognivue_training_outputs_20251230_141926.zip\n",
      "Click the link below to download your results:\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='cognivue_training_outputs_20251230_141926.zip' target='_blank'>cognivue_training_outputs_20251230_141926.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/cognivue_training_outputs_20251230_141926.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "# 1. Search for any zip files starting with 'cognivue_training_outputs'\n",
    "zip_files = glob.glob('/kaggle/working/cognivue_training_outputs_*.zip')\n",
    "\n",
    "if zip_files:\n",
    "    # 2. Sort by newest (incase there are multiple)\n",
    "    latest_zip = max(zip_files, key=os.path.getctime)\n",
    "    relative_path = os.path.basename(latest_zip)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(f\"‚úÖ LATEST PACKAGE FOUND: {relative_path}\")\n",
    "    print(\"Click the link below to download your results:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 3. Display the dynamic link\n",
    "    display(FileLink(relative_path))\n",
    "else:\n",
    "    print(\"‚ùå No output zip files found in /kaggle/working/\")\n",
    "    print(\"Current directory contents:\", os.listdir('/kaggle/working/'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9143557,
     "sourceId": 14322899,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3234.731211,
   "end_time": "2025-12-30T14:19:38.615766",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-30T13:25:43.884555",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
