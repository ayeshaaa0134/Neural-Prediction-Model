{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"accelerator":"TPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":9143557,"sourceId":14322899,"sourceType":"datasetVersion"}],"dockerImageVersionId":31234,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"papermill":{"default_parameters":{},"duration":1958.843895,"end_time":"2025-12-29T22:42:57.364311","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-12-29T22:10:18.520416","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"633779b3","cell_type":"markdown","source":"#  CogniVue: Training\n\n** FULLY COMPATIBLE with your preprocessing notebook!**\n\nThis notebook:\n-  Loads data from single `.pkl` files per split\n-  Handles variable channel count (typically 58 channels)\n-  Correctly transposes X from `(n_ch, 256)` to `(256, n_ch)`\n-  Robust checkpointing and error handling\n-  Resume training from interruptions\n-  \n\n","metadata":{"papermill":{"duration":0.004525,"end_time":"2025-12-29T22:10:22.315115","exception":false,"start_time":"2025-12-29T22:10:22.310590","status":"completed"},"tags":[]}},{"id":"314c73c8","cell_type":"markdown","source":"##  1. Install Dependencies","metadata":{"papermill":{"duration":0.003303,"end_time":"2025-12-29T22:10:22.322210","exception":false,"start_time":"2025-12-29T22:10:22.318907","status":"completed"},"tags":[]}},{"id":"44945a54","cell_type":"markdown","source":"##  2. Configuration","metadata":{"papermill":{"duration":0.003488,"end_time":"2025-12-29T22:10:22.330362","exception":false,"start_time":"2025-12-29T22:10:22.326874","status":"completed"},"tags":[]}},{"id":"87a12f5f","cell_type":"code","source":"# =====================================================\n# MODEL HYPERPARAMETERS - IMPROVED FOR GENERALIZATION\n# =====================================================\n\nD_MODEL = 256\nNUM_LAYERS = 4  # REDUCED from 6 to prevent overfitting\nNUM_HEADS = 8\nFF_DIM = 512  # REDUCED from 1024 to prevent overfitting\nDROPOUT = 0.25  # INCREASED from 0.15 for better regularization\n\nBANDPOWER_HIDDEN_DIM = 128\nBANDPOWER_OUTPUT_DIM = 128\nTASK_EMBEDDING_DIM = 16\n\n# =====================================================\n# TRAINING HYPERPARAMETERS - IMPROVED\n# =====================================================\n\nEPOCHS = 100\nINITIAL_LR = 5e-5  # REDUCED from 1e-4 for more stable training\nWARMUP_EPOCHS = 5  # REDUCED from 10 for faster convergence\nWEIGHT_DECAY = 0.02  # INCREASED from 0.01 for stronger regularization\nGRADIENT_CLIP_NORM = 0.5  # REDUCED from 1.0 for more aggressive clipping\n\nSAVE_CHECKPOINT_EVERY = 2\nEARLY_STOPPING_PATIENCE = 20  # INCREASED from 15 to allow more training\n\nprint(f\"\\nConfiguration:\")\nprint(f\"  Model: {NUM_LAYERS} layers, {NUM_HEADS} heads, D_MODEL={D_MODEL}\")\nprint(f\"  FF_DIM={FF_DIM}, DROPOUT={DROPOUT}\")\nprint(f\"  Training: {EPOCHS} epochs, LR={INITIAL_LR}\")\nprint(f\"  Weight Decay: {WEIGHT_DECAY}, Gradient Clip: {GRADIENT_CLIP_NORM}\")\nprint(f\"  Checkpointing: every {SAVE_CHECKPOINT_EVERY} epochs\")","metadata":{"execution":{"iopub.status.busy":"2025-12-30T10:05:42.223158Z","iopub.execute_input":"2025-12-30T10:05:42.223528Z","iopub.status.idle":"2025-12-30T10:05:42.232598Z","shell.execute_reply.started":"2025-12-30T10:05:42.223463Z","shell.execute_reply":"2025-12-30T10:05:42.231288Z"},"papermill":{"duration":26.609625,"end_time":"2025-12-29T22:10:48.943339","exception":false,"start_time":"2025-12-29T22:10:22.333714","status":"completed"},"tags":[],"trusted":true},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_101/2737970318.py\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    print(f\"\\n√∞≈∏\"¬ß Configuration:\")\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '¬ß' (U+00A7)\n"],"ename":"SyntaxError","evalue":"invalid character '¬ß' (U+00A7) (2737970318.py, line 28)","output_type":"error"}],"execution_count":1},{"id":"e23541b2","cell_type":"markdown","source":"##  3. TPU Initialization","metadata":{"papermill":{"duration":0.003529,"end_time":"2025-12-29T22:10:48.950799","exception":false,"start_time":"2025-12-29T22:10:48.947270","status":"completed"},"tags":[]}},{"id":"9191e91b","cell_type":"code","source":"import tensorflow as tf\n\nprint(\"=\" * 70)\nprint(\"üöÄ GPU T4 x2 INITIALIZATION\")\nprint(\"=\" * 70)\n\nprint(f\"\\nTensorFlow version: {tf.__version__}\")\n\n# Create GPU strategy\nprint(\"\\nüìä Creating GPU strategy...\")\nstrategy = tf.distribute.MirroredStrategy()\n\nnum_replicas = strategy.num_replicas_in_sync\nprint(f\"‚úÖ Strategy: {strategy.__class__.__name__}\")\nprint(f\"   GPUs detected: {num_replicas}\")\n\n# List GPUs\ngpus = tf.config.list_physical_devices('GPU')\nprint(f\"\\nüéÆ GPU devices:\")\nfor i, gpu in enumerate(gpus):\n    print(f\"   {i+1}. {gpu.name}\")\n\n# Batch size configuration\nBATCH_SIZE_PER_REPLICA = 32  # Reduce to 16 if you get OOM errors\nBATCH_SIZE = BATCH_SIZE_PER_REPLICA * num_replicas\n\nprint(f\"\\nüì¶ Batch Configuration:\")\nprint(f\"   Per-GPU batch: {BATCH_SIZE_PER_REPLICA}\")\nprint(f\"   Global batch: {BATCH_SIZE}\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"‚úÖ GPU READY FOR TRAINING\")\nprint(\"=\" * 70)\n\n# Make variables global\nglobals()['strategy'] = strategy\nglobals()['BATCH_SIZE'] = BATCH_SIZE\n\nprint(\"\\nüí° Next: Create model in strategy scope\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-30T10:05:42.233554Z","iopub.status.idle":"2025-12-30T10:05:42.234104Z","shell.execute_reply.started":"2025-12-30T10:05:42.233895Z","shell.execute_reply":"2025-12-30T10:05:42.233919Z"},"papermill":{"duration":1.768889,"end_time":"2025-12-29T22:10:50.723200","exception":false,"start_time":"2025-12-29T22:10:48.954311","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"c32ccde3","cell_type":"code","source":"# ============================================================\n# AUTO-SAVE CALLBACK (Add this BEFORE training section)\n# ============================================================\n\nclass AutoSaveCallback(tf.keras.callbacks.Callback):\n    \"\"\"Custom callback to create marker files for auto-committing\"\"\"\n    \n    def on_epoch_end(self, epoch, logs=None):\n        # Create a marker file every epoch\n        # Kaggle auto-commits when new files appear\n        marker_path = f\"/kaggle/working/progress_epoch_{epoch+1}.txt\"\n        with open(marker_path, 'w') as f:\n            f.write(f\"Completed epoch {epoch+1}/{EPOCHS}\\n\")\n            f.write(f\"Loss: {logs.get('loss', 0):.4f}\\n\")\n            f.write(f\"Val Loss: {logs.get('val_loss', 0):.4f}\\n\")\n            f.write(f\"Timestamp: {datetime.now()}\\n\")\n        \n        print(f\"   Progress saved: progress_epoch_{epoch+1}.txt\")\n\nprint(\" Auto-save callback ready!\")","metadata":{"execution":{"iopub.status.busy":"2025-12-30T10:05:42.235135Z","iopub.status.idle":"2025-12-30T10:05:42.235417Z","shell.execute_reply.started":"2025-12-30T10:05:42.235300Z","shell.execute_reply":"2025-12-30T10:05:42.235316Z"},"papermill":{"duration":0.011707,"end_time":"2025-12-29T22:10:50.738962","exception":false,"start_time":"2025-12-29T22:10:50.727255","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"f8c8712d","cell_type":"markdown","source":"##  4. Data Loading (Compatible with Preprocessing)","metadata":{"papermill":{"duration":0.003698,"end_time":"2025-12-29T22:10:50.746467","exception":false,"start_time":"2025-12-29T22:10:50.742769","status":"completed"},"tags":[]}},{"id":"2bbf3153","cell_type":"code","source":"def load_preprocessed_data(split='train'):\n    \"\"\"\n    Load preprocessed .pkl file (matches preprocessing output format).\n    \n    Returns:\n        Tuple of (X, y, metadata) where:\n        X = (X_eeg, X_bp, X_task)\n        y = (y_channel, y_region, y_band, y_state)\n        metadata = dict with num_channels, etc.\n    \"\"\"\n    pkl_path = os.path.join(DATA_INPUT_DIR, split, f\"{split}_data.pkl\")\n    \n    print(f\"\\n Loading {split} data from: {pkl_path}\")\n    \n    if not os.path.exists(pkl_path):\n        print(f\"   File not found!\")\n        print(f\"   Check that dataset is attached and DATASET_NAME is correct\")\n        return None\n    \n    # Load pickle file\n    try:\n        with open(pkl_path, 'rb') as f:\n            samples = pickle.load(f)\n        \n        print(f\"   Loaded {len(samples):,} samples\")\n        \n        if len(samples) == 0:\n            print(f\"   No samples in file!\")\n            return None\n        \n        # Inspect first sample to get dimensions\n        sample = samples[0]\n        X_shape = sample['X'].shape  # Should be (n_channels, 256)\n        bp_shape = sample['bp'].shape  # Should be (n_channels, 5)\n        \n        num_channels = X_shape[0]\n        \n        print(f\"\\n  Data format:\")\n        print(f\"     X shape: {X_shape} (channels, time)\")\n        print(f\"     bp shape: {bp_shape} (channels, bands)\")\n        print(f\"     Channels: {num_channels}\")\n        \n        # Extract arrays\n        print(f\"\\n   Converting to arrays...\")\n        \n        # X: Transpose from (n_channels, 256) to (256, n_channels)\n        X_eeg = np.array([s['X'].T for s in samples], dtype=np.float32)\n        \n        # bp: Flatten from (n_channels, 5) to (n_channels*5,)\n        X_bp = np.array([s['bp'].flatten() for s in samples], dtype=np.float32)\n        \n        # task_idx\n        X_task = np.array([s['task_idx'] for s in samples], dtype=np.int32)\n        \n        # Labels\n        y_channel = np.array([s['y_channel'] for s in samples], dtype=np.int32)\n        y_region = np.array([s['y_region'] for s in samples], dtype=np.int32)\n        y_band = np.array([s['y_band'] for s in samples], dtype=np.int32)\n        y_state = np.array([s['y_state'] for s in samples], dtype=np.int32)\n        \n        print(f\"   Final shapes:\")\n        print(f\"     X_eeg: {X_eeg.shape} (N, time, channels)\")\n        print(f\"     X_bp: {X_bp.shape} (N, features)\")\n        print(f\"     X_task: {X_task.shape}\")\n        print(f\"     Labels: {y_channel.shape} each\")\n        \n        metadata = {\n            'num_channels': num_channels,\n            'num_samples': len(samples),\n            'bandpower_dim': X_bp.shape[1]\n        }\n        \n        return (X_eeg, X_bp, X_task), (y_channel, y_region, y_band, y_state), metadata\n        \n    except Exception as e:\n        print(f\"  ‚ùå Error loading data: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None\n\nprint(\" Data loading function defined\")","metadata":{"execution":{"iopub.status.busy":"2025-12-30T10:05:42.236295Z","iopub.status.idle":"2025-12-30T10:05:42.236675Z","shell.execute_reply.started":"2025-12-30T10:05:42.236468Z","shell.execute_reply":"2025-12-30T10:05:42.236489Z"},"papermill":{"duration":0.016009,"end_time":"2025-12-29T22:10:50.766407","exception":false,"start_time":"2025-12-29T22:10:50.750398","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"b33eb13c","cell_type":"markdown","source":"##  5. Model Architecture (Flexible Channels)","metadata":{"papermill":{"duration":0.003613,"end_time":"2025-12-29T22:10:50.773766","exception":false,"start_time":"2025-12-29T22:10:50.770153","status":"completed"},"tags":[]}},{"id":"fce499e4","cell_type":"code","source":"def create_model(num_channels, bandpower_input_dim, num_output_channels):\n    \"\"\"\n    Create EEG Transformer with improved regularization and stability.\n    \"\"\"\n    # Inputs\n    eeg_input = tf.keras.Input(shape=(WINDOW_SIZE_SAMPLES, num_channels), name='eeg')\n    bp_input = tf.keras.Input(shape=(bandpower_input_dim,), name='bp')\n    task_input = tf.keras.Input(shape=(1,), dtype='int32', name='task')\n    \n    # ==================== EEG STREAM ====================\n    x = tf.keras.layers.Dense(D_MODEL, name='eeg_projection')(eeg_input)\n    x = tf.keras.layers.LayerNormalization(epsilon=1e-6, name='eeg_ln')(x)  # ADDED\n    \n    # Positional encoding\n    positions = tf.range(start=0, limit=WINDOW_SIZE_SAMPLES, delta=1)\n    pos_emb = tf.keras.layers.Embedding(\n        input_dim=WINDOW_SIZE_SAMPLES,\n        output_dim=D_MODEL,\n        name='positional_embedding'\n    )(positions)\n    x = x + pos_emb\n    x = tf.keras.layers.Dropout(DROPOUT, name='pos_dropout')(x)  # ADDED\n    \n    # Transformer layers\n    for i in range(NUM_LAYERS):\n        # Pre-LayerNorm architecture (better stability)\n        x_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=f'ln_attn_pre_{i}')(x)\n        \n        attn = tf.keras.layers.MultiHeadAttention(\n            num_heads=NUM_HEADS,\n            key_dim=D_MODEL // NUM_HEADS,\n            dropout=DROPOUT,\n            name=f'mha_{i}'\n        )(x_norm, x_norm)\n        \n        attn = tf.keras.layers.Dropout(DROPOUT, name=f'attn_dropout_{i}')(attn)  # ADDED\n        x = tf.keras.layers.Add(name=f'add_attn_{i}')([x, attn])\n        \n        # FFN with Pre-LayerNorm\n        x_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=f'ln_ffn_pre_{i}')(x)\n        \n        ffn = tf.keras.Sequential([\n            tf.keras.layers.Dense(FF_DIM, activation='gelu', name=f'ffn_dense1_{i}'),  # CHANGED to GELU\n            tf.keras.layers.Dropout(DROPOUT, name=f'ffn_dropout1_{i}'),\n            tf.keras.layers.Dense(D_MODEL, name=f'ffn_dense2_{i}'),\n            tf.keras.layers.Dropout(DROPOUT, name=f'ffn_dropout2_{i}')\n        ], name=f'ffn_{i}')\n        \n        ffn_out = ffn(x_norm)\n        x = tf.keras.layers.Add(name=f'add_ffn_{i}')([x, ffn_out])\n    \n    # Final LayerNorm\n    x = tf.keras.layers.LayerNormalization(epsilon=1e-6, name='final_ln')(x)  # ADDED\n    eeg_emb = tf.keras.layers.GlobalAveragePooling1D(name='eeg_pool')(x)\n    \n    # ==================== BANDPOWER STREAM ====================\n    bp_x = tf.keras.layers.BatchNormalization(name='bp_bn')(bp_input)  # ADDED\n    bp_x = tf.keras.layers.Dense(BANDPOWER_HIDDEN_DIM, activation='gelu', name='bp_hidden')(bp_x)\n    bp_x = tf.keras.layers.Dropout(DROPOUT, name='bp_dropout1')(bp_x)  # ADDED\n    bp_emb = tf.keras.layers.Dense(BANDPOWER_OUTPUT_DIM, activation='gelu', name='bp_output')(bp_x)\n    bp_emb = tf.keras.layers.Dropout(DROPOUT, name='bp_dropout2')(bp_emb)  # ADDED\n    \n    # ==================== TASK STREAM ====================\n    task_emb = tf.keras.layers.Embedding(NUM_TASKS, TASK_EMBEDDING_DIM, name='task_emb')(task_input)\n    task_emb = tf.keras.layers.Flatten(name='task_flatten')(task_emb)\n    task_emb = tf.keras.layers.Dropout(DROPOUT, name='task_dropout')(task_emb)  # ADDED\n    \n    # ==================== FUSION ====================\n    fused = tf.keras.layers.Concatenate(name='fusion')([eeg_emb, bp_emb, task_emb])\n    fused = tf.keras.layers.BatchNormalization(name='fusion_bn')(fused)  # ADDED\n    fused = tf.keras.layers.Dropout(DROPOUT, name='fusion_dropout')(fused)  # ADDED\n    \n    # ==================== MULTI-TASK HEADS ====================\n    out_channel = tf.keras.layers.Dense(num_output_channels, name='channel')(fused)\n    out_region = tf.keras.layers.Dense(NUM_OUTPUT_REGIONS, name='region')(fused)\n    out_band = tf.keras.layers.Dense(NUM_OUTPUT_BANDS, name='band')(fused)\n    out_state = tf.keras.layers.Dense(NUM_OUTPUT_STATES, name='state')(fused)\n    \n    model = tf.keras.Model(\n        inputs=[eeg_input, bp_input, task_input],\n        outputs={\n            'channel': out_channel,\n            'region': out_region,\n            'band': out_band,\n            'state': out_state\n        },\n        name='CogniVue_Transformer'\n    )\n    \n    return model\n\nprint(\"‚úÖ Improved model architecture defined\")","metadata":{"execution":{"iopub.status.busy":"2025-12-30T10:05:42.326091Z","iopub.execute_input":"2025-12-30T10:05:42.326440Z","iopub.status.idle":"2025-12-30T10:05:42.343344Z","shell.execute_reply.started":"2025-12-30T10:05:42.326412Z","shell.execute_reply":"2025-12-30T10:05:42.342489Z"},"papermill":{"duration":0.016408,"end_time":"2025-12-29T22:10:50.793886","exception":false,"start_time":"2025-12-29T22:10:50.777478","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Improved model architecture defined\n","output_type":"stream"}],"execution_count":2},{"id":"1e8c035f","cell_type":"markdown","source":"##  6. Learning Rate Schedule","metadata":{"papermill":{"duration":0.003781,"end_time":"2025-12-29T22:10:50.801496","exception":false,"start_time":"2025-12-29T22:10:50.797715","status":"completed"},"tags":[]}},{"id":"bda54f7b","cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\nclass WarmupCosineDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, initial_learning_rate, warmup_steps, total_steps):\n        super().__init__()\n        self.initial_learning_rate = initial_learning_rate\n        self.warmup_steps = warmup_steps\n        self.total_steps = total_steps\n    \n    def __call__(self, step):\n        step = tf.cast(step, tf.float32)\n        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n        total_steps = tf.cast(self.total_steps, tf.float32)\n        \n        warmup_lr = (step / warmup_steps) * self.initial_learning_rate\n        \n        decay_steps = total_steps - warmup_steps\n        decay_step = step - warmup_steps\n        cosine_decay = 0.5 * (1 + tf.cos(tf.constant(np.pi) * decay_step / decay_steps))\n        decay_lr = self.initial_learning_rate * cosine_decay\n        \n        return tf.cond(\n            step < warmup_steps,\n            lambda: warmup_lr,\n            lambda: decay_lr\n        )\n    \n    def get_config(self):\n        return {\n            \"initial_learning_rate\": self.initial_learning_rate,\n            \"warmup_steps\": self.warmup_steps,\n            \"total_steps\": self.total_steps,\n        }\n\nprint(\"LR schedule defined\")","metadata":{"execution":{"iopub.status.busy":"2025-12-30T10:05:42.344797Z","iopub.execute_input":"2025-12-30T10:05:42.345026Z","iopub.status.idle":"2025-12-30T10:05:42.365451Z","shell.execute_reply.started":"2025-12-30T10:05:42.345006Z","shell.execute_reply":"2025-12-30T10:05:42.364324Z"},"papermill":{"duration":0.012687,"end_time":"2025-12-29T22:10:50.817910","exception":false,"start_time":"2025-12-29T22:10:50.805223","status":"completed"},"tags":[],"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_101/1146351625.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mWarmupCosineDecay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateSchedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_learning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_learning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarmup_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"],"ename":"NameError","evalue":"name 'tf' is not defined","output_type":"error"}],"execution_count":3},{"id":"6df5c1af","cell_type":"markdown","source":"##  7. Data Pipeline & Callbacks","metadata":{"papermill":{"duration":0.003747,"end_time":"2025-12-29T22:10:50.825521","exception":false,"start_time":"2025-12-29T22:10:50.821774","status":"completed"},"tags":[]}},{"id":"da70e48f","cell_type":"code","source":"import tensorflow as tf\nimport time\n\ndef augment_eeg(eeg, training=True):\n    \"\"\"Apply data augmentation to EEG signals during training\"\"\"\n    if not training:\n        return eeg\n    \n    # Random noise addition (5% of samples)\n    if tf.random.uniform([]) < 0.05:\n        noise = tf.random.normal(tf.shape(eeg), mean=0.0, stddev=0.02)\n        eeg = eeg + noise\n    \n    # Random amplitude scaling (10% of samples)\n    if tf.random.uniform([]) < 0.1:\n        scale = tf.random.uniform([], minval=0.95, maxval=1.05)\n        eeg = eeg * scale\n    \n    return eeg\n\n\ndef create_tf_dataset(X, y, is_train=True):\n    \"\"\"Create TF dataset with augmentation and improved batching\"\"\"\n    dataset = tf.data.Dataset.from_tensor_slices((\n        {'eeg': X[0], 'bp': X[1], 'task': X[2]},\n        {'channel': y[0], 'region': y[1], 'band': y[2], 'state': y[3]}\n    ))\n    \n    if is_train:\n        # Shuffle with larger buffer\n        dataset = dataset.shuffle(buffer_size=min(50000, len(X[0])))\n        \n        # Apply augmentation\n        def augment_fn(inputs, labels):\n            inputs['eeg'] = augment_eeg(inputs['eeg'], training=True)\n            return inputs, labels\n        \n        dataset = dataset.map(augment_fn, num_parallel_calls=tf.data.AUTOTUNE)\n    \n    # Batch and prefetch\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    \n    return dataset\n\n\nclass PeriodicCheckpoint(tf.keras.callbacks.Callback):\n    def __init__(self, save_freq=5):\n        super().__init__()\n        self.save_freq = save_freq\n    \n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch + 1) % self.save_freq == 0:\n            filepath = os.path.join(CHECKPOINT_DIR, f\"checkpoint_epoch_{epoch+1:03d}.keras\")\n            self.model.save(filepath)\n            print(f\"\\n   Saved checkpoint: {os.path.basename(filepath)}\")\n\n\nclass LearningRateLogger(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        lr = self.model.optimizer.learning_rate\n        if hasattr(lr, '__call__'):\n            lr_value = lr(self.model.optimizer.iterations)\n        else:\n            lr_value = lr\n        lr_float = float(tf.keras.backend.get_value(lr_value))\n        if logs is not None:\n            logs['learning_rate'] = lr_float\n        print(f\"\\n   LR = {lr_float:.6f}\")\n\n\nclass ProgressLogger(tf.keras.callbacks.Callback):\n    def __init__(self):\n        super().__init__()\n        self.epoch_start = None\n    \n    def on_epoch_begin(self, epoch, logs=None):\n        self.epoch_start = time.time()\n        print(f\"\\n{'='*70}\")\n        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n        print(f\"{'='*70}\")\n    \n    def on_epoch_end(self, epoch, logs=None):\n        elapsed = time.time() - self.epoch_start\n        print(f\"\\nEpoch {epoch+1} done in {elapsed:.1f}s\")\n        if logs:\n            print(f\"   Loss: {logs.get('loss', 0):.4f} | Val Loss: {logs.get('val_loss', 0):.4f}\")\n            print(f\"   Region Acc: {logs.get('region_accuracy', 0):.4f} | Val: {logs.get('val_region_accuracy', 0):.4f}\")\n            \n            # Calculate gap\n            gap = logs.get('loss', 0) - logs.get('val_loss', 0)\n            if gap < -0.3:\n                print(f\"   WARNING: Overfitting detected (gap: {gap:.4f})\")\n        print(f\"{'='*70}\\n\")\n\n\nclass AdaptiveLRCallback(tf.keras.callbacks.Callback):\n    \"\"\"Reduce LR when validation loss plateaus\"\"\"\n    def __init__(self, patience=5, factor=0.5, min_lr=1e-6):\n        super().__init__()\n        self.patience = patience\n        self.factor = factor\n        self.min_lr = min_lr\n        self.best_val_loss = float('inf')\n        self.wait = 0\n    \n    def on_epoch_end(self, epoch, logs=None):\n        current_val_loss = logs.get('val_loss')\n        if current_val_loss < self.best_val_loss:\n            self.best_val_loss = current_val_loss\n            self.wait = 0\n        else:\n            self.wait += 1\n            if self.wait >= self.patience:\n                old_lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n                if old_lr > self.min_lr:\n                    new_lr = max(old_lr * self.factor, self.min_lr)\n                    tf.keras.backend.set_value(self.model.optimizer.learning_rate, new_lr)\n                    print(f\"\\n   Reducing LR: {old_lr:.6f} -> {new_lr:.6f}\")\n                    self.wait = 0\n\n\nprint(\"Pipeline & callbacks defined\")","metadata":{"execution":{"iopub.status.busy":"2025-12-30T10:05:42.366056Z","iopub.status.idle":"2025-12-30T10:05:42.366393Z","shell.execute_reply.started":"2025-12-30T10:05:42.366229Z","shell.execute_reply":"2025-12-30T10:05:42.366248Z"},"papermill":{"duration":0.016985,"end_time":"2025-12-29T22:10:50.846441","exception":false,"start_time":"2025-12-29T22:10:50.829456","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"91b77a03","cell_type":"markdown","source":"##  8. Main Training Function","metadata":{"papermill":{"duration":0.003705,"end_time":"2025-12-29T22:10:50.854261","exception":false,"start_time":"2025-12-29T22:10:50.850556","status":"completed"},"tags":[]}},{"id":"46aff76b","cell_type":"code","source":"from datetime import datetime\nimport numpy as np\n\ndef train_cognivue():\n    print(\"\\n\" + \"=\"*70)\n    print(\"CogniVue Training Pipeline (IMPROVED)\")\n    print(\"=\"*70)\n    \n    # Load ONLY training data\n    print(\"\\nLoading data...\")\n    train_result = load_preprocessed_data('train')\n    \n    if train_result is None:\n        print(\"\\nData loading failed!\")\n        return None\n    \n    train_data, train_labels, train_meta = train_result\n    \n    # Split train/val\n    print(\"\\nSplitting data into train/val...\")\n    num_samples = len(train_data[0])\n    indices = np.arange(num_samples)\n    np.random.seed(42)\n    np.random.shuffle(indices)\n    \n    split_idx = int(0.8 * num_samples)\n    train_idx = indices[:split_idx]\n    val_idx = indices[split_idx:]\n    \n    train_X = (train_data[0][train_idx], train_data[1][train_idx], train_data[2][train_idx])\n    val_X = (train_data[0][val_idx], train_data[1][val_idx], train_data[2][val_idx])\n    train_y = (train_labels[0][train_idx], train_labels[1][train_idx], \n               train_labels[2][train_idx], train_labels[3][train_idx])\n    val_y = (train_labels[0][val_idx], train_labels[1][val_idx], \n             train_labels[2][val_idx], train_labels[3][val_idx])\n    \n    print(f\"   Train samples: {len(train_idx):,}\")\n    print(f\"   Val samples: {len(val_idx):,}\")\n    \n    # Get dimensions\n    NUM_CHANNELS = train_meta['num_channels']\n    BANDPOWER_INPUT_DIM = train_meta['bandpower_dim']\n    NUM_OUTPUT_CHANNELS = train_labels[0].max() + 1\n    \n    print(f\"\\nModel dimensions:\")\n    print(f\"   Input channels: {NUM_CHANNELS}\")\n    print(f\"   Bandpower dim: {BANDPOWER_INPUT_DIM}\")\n    print(f\"   Output channels: {NUM_OUTPUT_CHANNELS}\")\n    \n    # Create datasets\n    print(f\"\\nCreating TF datasets...\")\n    train_ds = create_tf_dataset(train_X, train_y, is_train=True)\n    val_ds = create_tf_dataset(val_X, val_y, is_train=False)\n    \n    steps_per_epoch = len(train_idx) // BATCH_SIZE\n    total_steps = steps_per_epoch * EPOCHS\n    warmup_steps = steps_per_epoch * WARMUP_EPOCHS\n    \n    print(f\"   Steps/epoch: {steps_per_epoch:,}\")\n    print(f\"   Total steps: {total_steps:,}\")\n    \n    # Build model\n    print(f\"\\nBuilding model...\")\n    \n    with strategy.scope():\n        model = create_model(NUM_CHANNELS, BANDPOWER_INPUT_DIM, NUM_OUTPUT_CHANNELS)\n        print(f\"   Parameters: {model.count_params():,}\")\n        \n        lr_schedule = WarmupCosineDecay(INITIAL_LR, warmup_steps, total_steps)\n        \n        optimizer = tf.keras.optimizers.AdamW(\n            learning_rate=lr_schedule,\n            weight_decay=WEIGHT_DECAY,\n            clipnorm=GRADIENT_CLIP_NORM\n        )\n        \n        # IMPROVED: Balanced loss weights\n        loss_weights = {\n            'channel': 0.35,\n            'region': 0.40,\n            'band': 0.15,\n            'state': 0.10\n        }\n        \n        # IMPROVED: Add label smoothing\n        model.compile(\n            optimizer=optimizer,\n            loss={\n                'channel': tf.keras.losses.SparseCategoricalCrossentropy(\n                    from_logits=True, label_smoothing=0.1),\n                'region': tf.keras.losses.SparseCategoricalCrossentropy(\n                    from_logits=True, label_smoothing=0.1),\n                'band': tf.keras.losses.SparseCategoricalCrossentropy(\n                    from_logits=True, label_smoothing=0.1),\n                'state': tf.keras.losses.SparseCategoricalCrossentropy(\n                    from_logits=True, label_smoothing=0.1)\n            },\n            loss_weights=loss_weights,\n            metrics={\n                'channel': ['accuracy'],\n                'region': ['accuracy'],\n                'band': ['accuracy'],\n                'state': ['accuracy']\n            }\n        )\n        \n        print(f\"   Compiled with label smoothing\")\n    \n    # Callbacks\n    callbacks = [\n        ProgressLogger(),\n        LearningRateLogger(),\n        tf.keras.callbacks.ModelCheckpoint(\n            filepath=os.path.join(CHECKPOINT_DIR, 'best_model.keras'),\n            monitor='val_loss',\n            save_best_only=True,\n            verbose=1\n        ),\n        PeriodicCheckpoint(save_freq=SAVE_CHECKPOINT_EVERY),\n        AdaptiveLRCallback(patience=5, factor=0.5, min_lr=1e-6),\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=EARLY_STOPPING_PATIENCE,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        tf.keras.callbacks.TensorBoard(log_dir=LOGS_DIR)\n    ]\n    \n    # Train\n    print(f\"\\nStarting training...\")\n    print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n    \n    try:\n        history = model.fit(\n            train_ds,\n            epochs=EPOCHS,\n            validation_data=val_ds,\n            callbacks=callbacks,\n            verbose=1\n        )\n        \n        print(\"\\n\" + \"=\"*70)\n        print(\"TRAINING COMPLETE!\")\n        print(\"=\"*70)\n        print(f\"\\nSaved to: {CHECKPOINT_DIR}\")\n        \n        model.save(os.path.join(CHECKPOINT_DIR, 'final_model.keras'))\n        print(f\"   - final_model.keras\")\n        print(f\"   - best_model.keras\")\n        \n        return history\n        \n    except KeyboardInterrupt:\n        print(\"\\nTraining interrupted!\")\n        model.save(os.path.join(CHECKPOINT_DIR, 'interrupted.keras'))\n        print(f\"   Saved: interrupted.keras\")\n        return None\n        \n    except Exception as e:\n        print(f\"\\nTraining failed: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None\n\nprint(\"Training function ready\")","metadata":{"execution":{"iopub.status.busy":"2025-12-30T10:05:42.367422Z","iopub.status.idle":"2025-12-30T10:05:42.367748Z","shell.execute_reply.started":"2025-12-30T10:05:42.367607Z","shell.execute_reply":"2025-12-30T10:05:42.367631Z"},"papermill":{"duration":0.020467,"end_time":"2025-12-29T22:10:50.878421","exception":false,"start_time":"2025-12-29T22:10:50.857954","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"8bb7c0fb","cell_type":"markdown","source":"##  9. Run Training","metadata":{"papermill":{"duration":0.003818,"end_time":"2025-12-29T22:10:50.886290","exception":false,"start_time":"2025-12-29T22:10:50.882472","status":"completed"},"tags":[]}},{"id":"2d85058e","cell_type":"code","source":"history = train_cognivue()\n\nif history:\n    print(\"\\n Training Summary:\")\n    print(f\"   Best val_loss: {min(history.history['val_loss']):.4f}\")\n    print(f\"   Final region acc: {history.history['region_accuracy'][-1]:.4f}\")\n    print(f\"\\n Next: Click 'Save Version' to commit checkpoints!\")\nelse:\n    print(\"\\n‚ö†Ô∏è Training did not complete successfully\")","metadata":{"execution":{"iopub.status.busy":"2025-12-30T10:05:42.368918Z","iopub.status.idle":"2025-12-30T10:05:42.369265Z","shell.execute_reply.started":"2025-12-30T10:05:42.369082Z","shell.execute_reply":"2025-12-30T10:05:42.369104Z"},"papermill":{"duration":1871.629458,"end_time":"2025-12-29T22:42:02.519753","exception":false,"start_time":"2025-12-29T22:10:50.890295","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"be99d2a8","cell_type":"markdown","source":"10: Save Training Results & Metrics","metadata":{"papermill":{"duration":0.320172,"end_time":"2025-12-29T22:42:03.242248","exception":false,"start_time":"2025-12-29T22:42:02.922076","status":"completed"},"tags":[]}},{"id":"6d88da2b","cell_type":"code","source":"if history:\n    print(\"\\n Saving training results...\")\n    \n    # Convert history to JSON-serializable format\n    history_dict = {\n        key: [float(val) for val in values] \n        for key, values in history.history.items()\n    }\n    \n    # Save training history\n    history_path = os.path.join(RESULTS_DIR, 'training_history.json')\n    with open(history_path, 'w') as f:\n        json.dump(history_dict, f, indent=2)\n    print(f\"   Saved: training_history.json\")\n    \n    # Get model dimensions from loaded data\n    train_result = load_preprocessed_data('train')\n    if train_result:\n        _, _, train_meta = train_result\n        NUM_CHANNELS_USED = train_meta['num_channels']\n    else:\n        NUM_CHANNELS_USED = \"unknown\"\n    \n    # Save training configuration\n    config = {\n        'model_architecture': {\n            'name': 'CogniVue_Transformer',\n            'num_input_channels': NUM_CHANNELS_USED,\n            'd_model': D_MODEL,\n            'num_layers': NUM_LAYERS,\n            'num_heads': NUM_HEADS,\n            'ff_dim': FF_DIM,\n            'dropout': DROPOUT,\n            'window_size': WINDOW_SIZE_SAMPLES\n        },\n        'training_params': {\n            'epochs_trained': len(history.history['loss']),\n            'total_epochs': EPOCHS,\n            'batch_size': BATCH_SIZE,\n            'initial_lr': INITIAL_LR,\n            'warmup_epochs': WARMUP_EPOCHS,\n            'weight_decay': WEIGHT_DECAY,\n            'gradient_clip_norm': GRADIENT_CLIP_NORM\n        },\n        'output_tasks': {\n            'num_output_channels': NUM_OUTPUT_REGIONS,\n            'num_regions': NUM_OUTPUT_REGIONS,\n            'num_bands': NUM_OUTPUT_BANDS,\n            'num_states': NUM_OUTPUT_STATES\n        },\n        'final_metrics': {\n            'best_val_loss': float(min(history.history['val_loss'])),\n            'final_train_loss': float(history.history['loss'][-1]),\n            'final_val_loss': float(history.history['val_loss'][-1]),\n            'final_region_accuracy': float(history.history['region_accuracy'][-1]),\n            'final_val_region_accuracy': float(history.history['val_region_accuracy'][-1])\n        },\n        'training_info': {\n            'completed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n            'tensorflow_version': tf.__version__,\n            'accelerator': 'TPU' if 'TPU' in str(strategy.__class__) else 'CPU/GPU'\n        }\n    }\n    \n    config_path = os.path.join(RESULTS_DIR, 'training_config.json')\n    with open(config_path, 'w') as f:\n        json.dump(config, f, indent=2)\n    print(f\"   Saved: training_config.json\")\n    \n    # Create a summary markdown file\n    summary_md = f\"\"\"# CogniVue Training Summary\n\n**Training Completed:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n## Model Architecture\n- **Model:** CogniVue Transformer\n- **Input Channels:** {NUM_CHANNELS_USED}\n- **Model Dimension:** {D_MODEL}\n- **Transformer Layers:** {NUM_LAYERS}\n- **Attention Heads:** {NUM_HEADS}\n- **Feedforward Dim:** {FF_DIM}\n- **Dropout:** {DROPOUT}\n\n## Training Configuration\n- **Epochs:** {len(history.history['loss'])}/{EPOCHS}\n- **Batch Size:** {BATCH_SIZE}\n- **Initial LR:** {INITIAL_LR}\n- **Warmup Epochs:** {WARMUP_EPOCHS}\n- **Weight Decay:** {WEIGHT_DECAY}\n\n## Final Performance\n- **Best Val Loss:** {min(history.history['val_loss']):.4f}\n- **Final Train Loss:** {history.history['loss'][-1]:.4f}\n- **Final Val Loss:** {history.history['val_loss'][-1]:.4f}\n- **Final Region Accuracy:** {history.history['region_accuracy'][-1]:.4f}\n- **Final Val Region Accuracy:** {history.history['val_region_accuracy'][-1]:.4f}\n\n## Output Files\n- `checkpoints/best_model.keras` - Best model weights\n- `checkpoints/final_model.keras` - Final model weights\n- `checkpoints/checkpoint_epoch_*.keras` - Periodic checkpoints\n- `results/training_history.json` - Loss and metrics per epoch\n- `results/training_config.json` - Full configuration\n- `logs/` - TensorBoard logs\n\"\"\"\n    \n    summary_path = os.path.join(RESULTS_DIR, 'TRAINING_SUMMARY.md')\n    with open(summary_path, 'w') as f:\n        f.write(summary_md)\n    print(f\"   Saved: TRAINING_SUMMARY.md\")\n    \n    print(\"\\n All results saved!\")\n    print(f\"\\n Saved files:\")\n    print(f\"   {RESULTS_DIR}/\")\n    print(f\"   ‚îú‚îÄ‚îÄ training_history.json\")\n    print(f\"   ‚îú‚îÄ‚îÄ training_config.json\")\n    print(f\"   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\")\n    print(f\"\\n   {CHECKPOINT_DIR}/\")\n    print(f\"   ‚îú‚îÄ‚îÄ best_model.keras\")\n    print(f\"   ‚îú‚îÄ‚îÄ final_model.keras\")\n    print(f\"   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\")\n    \nelse:\n    print(\"\\n‚ö†Ô∏è No training history to save\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2025-12-30T10:05:42.370564Z","iopub.status.idle":"2025-12-30T10:05:42.370892Z","shell.execute_reply.started":"2025-12-30T10:05:42.370724Z","shell.execute_reply":"2025-12-30T10:05:42.370744Z"},"papermill":{"duration":2.272897,"end_time":"2025-12-29T22:42:05.835626","exception":false,"start_time":"2025-12-29T22:42:03.562729","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"2a8aaf35","cell_type":"markdown","source":"11: Package & Download All Outputs","metadata":{"papermill":{"duration":0.347231,"end_time":"2025-12-29T22:42:06.505453","exception":false,"start_time":"2025-12-29T22:42:06.158222","status":"completed"},"tags":[]}},{"id":"96b52581","cell_type":"code","source":"\n# ============================================================\n# Section 11: Package & Download All Outputs\n# ============================================================\n\nimport zipfile\nfrom pathlib import Path\n\nprint(\"\\n Creating download package...\")\nprint(\"=\" * 70)\n\n# Create zip filename with timestamp\ntimestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\nzip_filename = f\"cognivue_training_outputs_{timestamp}.zip\"\nzip_path = os.path.join(WORKING_DIR, zip_filename)\n\ntry:\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        \n        # Add all files from results directory\n        print(\"\\n Adding results...\")\n        if os.path.exists(RESULTS_DIR):\n            for file in os.listdir(RESULTS_DIR):\n                file_path = os.path.join(RESULTS_DIR, file)\n                if os.path.isfile(file_path):\n                    arcname = os.path.join('results', file)\n                    zipf.write(file_path, arcname)\n                    print(f\"   {file}\")\n        \n        # Add all checkpoint files\n        print(\"\\nüîñ Adding checkpoints...\")\n        if os.path.exists(CHECKPOINT_DIR):\n            for file in os.listdir(CHECKPOINT_DIR):\n                file_path = os.path.join(CHECKPOINT_DIR, file)\n                if os.path.isfile(file_path):\n                    arcname = os.path.join('checkpoints', file)\n                    zipf.write(file_path, arcname)\n                    file_size_mb = os.path.getsize(file_path) / (1024 * 1024)\n                    print(f\"   {file} ({file_size_mb:.1f} MB)\")\n        \n        # Add TensorBoard logs (optional - can be large)\n        print(\"\\n Adding TensorBoard logs...\")\n        if os.path.exists(LOGS_DIR):\n            log_count = 0\n            for root, dirs, files in os.walk(LOGS_DIR):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    arcname = os.path.join('logs', os.path.relpath(file_path, LOGS_DIR))\n                    zipf.write(file_path, arcname)\n                    log_count += 1\n            print(f\"   Added {log_count} log files\")\n    \n    # Get final zip size\n    zip_size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\" PACKAGE CREATED SUCCESSFULLY!\")\n    print(\"=\" * 70)\n    print(f\"\\n Zip file: {zip_filename}\")\n    print(f\" Size: {zip_size_mb:.1f} MB\")\n    print(f\" Location: {zip_path}\")\n    \n    print(\"\\n To download:\")\n    print(\"   1. Go to the 'Output' tab (top right)\")\n    print(\"   2. Click 'Save Version' to commit outputs\")\n    print(f\"   3. Download '{zip_filename}'\")\n    print(\"\\n Or click the download icon next to the file in the Output tab\")\n    \n    # List contents\n    print(\"\\n Package contents:\")\n    with zipfile.ZipFile(zip_path, 'r') as zipf:\n        file_list = zipf.namelist()\n        print(f\"   Total files: {len(file_list)}\")\n        print(\"\\n   Structure:\")\n        print(\"   ‚îú‚îÄ‚îÄ results/\")\n        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ training_history.json\")\n        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ training_config.json\")\n        print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ TRAINING_SUMMARY.md\")\n        print(\"   ‚îú‚îÄ‚îÄ checkpoints/\")\n        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ best_model.keras\")\n        print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ final_model.keras\")\n        print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.keras\")\n        print(\"   ‚îî‚îÄ‚îÄ logs/\")\n        print(\"       ‚îî‚îÄ‚îÄ TensorBoard logs\")\n    \n    print(\"\\n\" + \"=\" * 70)\n    \nexcept Exception as e:\n    print(f\"\\n‚ùå Error creating zip: {e}\")\n    import traceback\n    traceback.print_exc()","metadata":{"execution":{"iopub.status.busy":"2025-12-30T10:05:42.429041Z","iopub.execute_input":"2025-12-30T10:05:42.429613Z","iopub.status.idle":"2025-12-30T10:05:42.448084Z","shell.execute_reply.started":"2025-12-30T10:05:42.429583Z","shell.execute_reply":"2025-12-30T10:05:42.446906Z"},"papermill":{"duration":45.377604,"end_time":"2025-12-29T22:42:52.225898","exception":false,"start_time":"2025-12-29T22:42:06.848294","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\n Creating download package...\n======================================================================\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_101/3473237554.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Create zip filename with timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%d_%H%M%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mzip_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"cognivue_training_outputs_{timestamp}.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mzip_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWORKING_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"],"ename":"NameError","evalue":"name 'datetime' is not defined","output_type":"error"}],"execution_count":4},{"id":"59bea89b","cell_type":"code","source":"import os\nprint(os.listdir('/kaggle/working/'))","metadata":{"execution":{"iopub.status.busy":"2025-12-30T10:05:42.448525Z","iopub.status.idle":"2025-12-30T10:05:42.448773Z","shell.execute_reply.started":"2025-12-30T10:05:42.448665Z","shell.execute_reply":"2025-12-30T10:05:42.448678Z"},"papermill":{"duration":0.328944,"end_time":"2025-12-29T22:42:52.878172","exception":false,"start_time":"2025-12-29T22:42:52.549228","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"62e3e904","cell_type":"code","source":"import os\nimport glob\nfrom IPython.display import FileLink, display\n\n# 1. Search for any zip files starting with 'cognivue_training_outputs'\nzip_files = glob.glob('/kaggle/working/cognivue_training_outputs_*.zip')\n\nif zip_files:\n    # 2. Sort by newest (incase there are multiple)\n    latest_zip = max(zip_files, key=os.path.getctime)\n    relative_path = os.path.basename(latest_zip)\n    \n    print(\"=\" * 50)\n    print(f\"‚úÖ LATEST PACKAGE FOUND: {relative_path}\")\n    print(\"Click the link below to download your results:\")\n    print(\"=\" * 50)\n    \n    # 3. Display the dynamic link\n    display(FileLink(relative_path))\nelse:\n    print(\"‚ùå No output zip files found in /kaggle/working/\")\n    print(\"Current directory contents:\", os.listdir('/kaggle/working/'))","metadata":{"execution":{"iopub.status.busy":"2025-12-30T10:05:42.449476Z","iopub.status.idle":"2025-12-30T10:05:42.449760Z","shell.execute_reply.started":"2025-12-30T10:05:42.449644Z","shell.execute_reply":"2025-12-30T10:05:42.449663Z"},"papermill":{"duration":0.335216,"end_time":"2025-12-29T22:42:53.532092","exception":false,"start_time":"2025-12-29T22:42:53.196876","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}